<!doctype html><html lang=en class=no-js> <head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=description content="Albumentations provides a comprehensive, high-performance framework for augmenting images to improve machine learning models. Ideal for computer vision applications, supporting a wide range of augmentations."><link href=https://albumentations.ai/docs/integrations/huggingface/image_classification_albumentations/ rel=canonical><link href=../ rel=prev><link href=../object_detection/ rel=next><link rel=icon href=../../../images/logo.png><meta name=generator content="mkdocs-1.6.1, mkdocs-material-9.6.4"><title>Image classification - Albumentations Documentation</title><link rel=stylesheet href=../../../assets/stylesheets/main.8608ea7d.min.css><link rel=stylesheet href=../../../assets/stylesheets/palette.06af60db.min.css><link rel=preconnect href=https://fonts.gstatic.com crossorigin><link rel=stylesheet href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback"><style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style><link rel=stylesheet href=../../../assets/_mkdocstrings.css><link rel=stylesheet href=../../../css/extra.css><script>__md_scope=new URL("../../..",location),__md_hash=e=>[...e].reduce(((e,_)=>(e<<5)-e+_.charCodeAt(0)),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script><script id=__analytics>function __md_analytics(){function e(){dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],e("js",new Date),e("config","G-DCXRDR9HJ0"),document.addEventListener("DOMContentLoaded",(function(){document.forms.search&&document.forms.search.query.addEventListener("blur",(function(){this.value&&e("event","search",{search_term:this.value})}));document$.subscribe((function(){var t=document.forms.feedback;if(void 0!==t)for(var a of t.querySelectorAll("[type=submit]"))a.addEventListener("click",(function(a){a.preventDefault();var n=document.location.pathname,d=this.getAttribute("data-md-value");e("event","feedback",{page:n,data:d}),t.firstElementChild.disabled=!0;var r=t.querySelector(".md-feedback__note [data-md-value='"+d+"']");r&&(r.hidden=!1)})),t.hidden=!1})),location$.subscribe((function(t){e("config","G-DCXRDR9HJ0",{page_path:t.pathname})}))}));var t=document.createElement("script");t.async=!0,t.src="https://www.googletagmanager.com/gtag/js?id=G-DCXRDR9HJ0",document.getElementById("__analytics").insertAdjacentElement("afterEnd",t)}</script><script>"undefined"!=typeof __md_analytics&&__md_analytics()</script><meta charset=utf-8><meta name=viewport content="width=device-width, initial-scale=1, shrink-to-fit=no"><meta property=og:title content="Albumentations Documentation - Image classification"><meta property=og:description content="Albumentations provides a comprehensive, high-performance framework for augmenting images to improve machine learning models. Ideal for computer vision applications, supporting a wide range of augmentations."><meta property=og:image content=https://albumentations.ai/docs/images/albumentations_card.png><meta property=og:image:type content=image/png><meta property=og:type content=website><meta content=https://albumentations.ai/docs/integrations/huggingface/image_classification_albumentations/ property=og:url><meta name=twitter:card content=summary_large_image><meta name=twitter:site content=@albumentations><meta name=twitter:creator content=@viglovikov><meta name=twitter:title content="Albumentations Documentation - Image classification"><meta name=twitter:description content="Albumentations provides a comprehensive, high-performance framework for augmenting images to improve machine learning models. Ideal for computer vision applications, supporting a wide range of augmentations."><meta name=twitter:image content=https://albumentations.ai/docs/images/albumentations_card.png><meta name=description content="Albumentations provides a comprehensive, high-performance framework for augmenting images to improve machine learning models. Ideal for computer vision applications, supporting a wide range of augmentations."><meta name=keywords content="Albumentations, image augmentation, machine learning, computer vision, data augmentation, image processing, deep learning, AI, artificial intelligence, Python"></head> <body dir=ltr data-md-color-scheme=default data-md-color-primary=white data-md-color-accent=white> <input class=md-toggle data-md-toggle=drawer type=checkbox id=__drawer autocomplete=off> <input class=md-toggle data-md-toggle=search type=checkbox id=__search autocomplete=off> <label class=md-overlay for=__drawer></label> <div data-md-component=skip> <a href=#fine-tuning-for-image-classification-with-transformers class=md-skip> Skip to content </a> </div> <div data-md-component=announce> <aside class=md-banner> <div class="md-banner__inner md-grid md-typeset"> <div class=announce-wrapper> <div id=announce-left> <div class=item> <a class=announce-link target=_blank href=https://github.com/sponsors/albumentations-team> <span class="twemoji twitter"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 496 512"><!-- Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6m-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3m44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9M244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8M97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1m-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7m32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1m-11.4-14.7c-1.6 1-1.6 3.6 0 5.9s4.3 3.3 5.6 2.3c1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2"/></svg> </span> You can now sponsor <strong>Albumentations</strong> </a> </div> <div class=item> <a class=announce-link href=https://twitter.com/albumentations target=_blank> <span class="twemoji twitter"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 512 512"><!-- Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M459.37 151.716c.325 4.548.325 9.097.325 13.645 0 138.72-105.583 298.558-298.558 298.558-59.452 0-114.68-17.219-161.137-47.106 8.447.974 16.568 1.299 25.34 1.299 49.055 0 94.213-16.568 130.274-44.832-46.132-.975-84.792-31.188-98.112-72.772 6.498.974 12.995 1.624 19.818 1.624 9.421 0 18.843-1.3 27.614-3.573-48.081-9.747-84.143-51.98-84.143-102.985v-1.299c13.969 7.797 30.214 12.67 47.431 13.319-28.264-18.843-46.781-51.005-46.781-87.391 0-19.492 5.197-37.36 14.294-52.954 51.655 63.675 129.3 105.258 216.365 109.807-1.624-7.797-2.599-15.918-2.599-24.04 0-57.828 46.782-104.934 104.934-104.934 30.213 0 57.502 12.67 76.67 33.137 23.715-4.548 46.456-13.32 66.599-25.34-7.798 24.366-24.366 44.833-46.132 57.827 21.117-2.273 41.584-8.122 60.426-16.243-14.292 20.791-32.161 39.308-52.628 54.253"/></svg> </span> Follow <strong>@albumentations</strong> on <strong>Twitter</strong> to stay updated </a> </div> <div class=item> <a class=announce-link href=https://www.linkedin.com/company/100504475 target=_blank> <span class="twemoji linkedin"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 448 512"><!-- Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M416 32H31.9C14.3 32 0 46.5 0 64.3v383.4C0 465.5 14.3 480 31.9 480H416c17.6 0 32-14.5 32-32.3V64.3c0-17.8-14.4-32.3-32-32.3M135.4 416H69V202.2h66.5V416zm-33.2-243c-21.3 0-38.5-17.3-38.5-38.5S80.9 96 102.2 96c21.2 0 38.5 17.3 38.5 38.5 0 21.3-17.2 38.5-38.5 38.5m282.1 243h-66.4V312c0-24.8-.5-56.7-34.5-56.7-34.6 0-39.9 27-39.9 54.9V416h-66.4V202.2h63.7v29.2h.9c8.9-16.8 30.6-34.5 62.9-34.5 67.2 0 79.7 44.3 79.7 101.9z"/></svg> </span> Follow <strong>@albumentations</strong> on <strong>LinkedIn</strong> to stay updated </a> </div> </div> </div> </div> </aside> </div> <header class=md-header data-md-component=header> <nav class="md-header__inner md-grid" aria-label=header.title> <a href=../../.. title="Albumentations Documentation" class="md-header__button md-logo" aria-label="Albumentations Documentation" data-md-component=logo> <img src=../../../images/logo.png alt=logo> </a> <label class="md-header__button md-icon" for=__drawer> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M3 6h18v2H3zm0 5h18v2H3zm0 5h18v2H3z"/></svg> </label> <div class=md-header__title data-md-component=header-title> </div> <div class=md-header-nav__title> <div class=header-menu-item> <a href=https://albumentations.ai>Home</a> </div> <div class="header-menu-item header-menu-item-selected"> <a href=https://albumentations.ai/docs/ >Documentation</a> </div> <div class="header-menu-item header-large-menu-item"> <a href=https://explore.albumentations.ai target=_blank>Explore</a> </div> <div class="header-menu-item header-large-menu-item"> <a href=https://albumentations.ai/people>People</a> </div> </div> <div class=md-search data-md-component=search role=dialog> <label class=md-search__overlay for=__search></label> <div class=md-search__inner role=search> <form class=md-search__form name=search> <input type=text class=md-search__input name=query aria-label=Search placeholder=Search autocapitalize=off autocorrect=off autocomplete=off spellcheck=false data-md-component=search-query required> <label class="md-search__icon md-icon" for=__search> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg> </label> <nav class=md-search__options aria-label=Search> <a href=javascript:void(0) class="md-search__icon md-icon" title=Share aria-label=Share data-clipboard data-clipboard-text data-md-component=search-share tabindex=-1> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M18 16.08c-.76 0-1.44.3-1.96.77L8.91 12.7c.05-.23.09-.46.09-.7s-.04-.47-.09-.7l7.05-4.11c.54.5 1.25.81 2.04.81a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3c0 .24.04.47.09.7L8.04 9.81C7.5 9.31 6.79 9 6 9a3 3 0 0 0-3 3 3 3 0 0 0 3 3c.79 0 1.5-.31 2.04-.81l7.12 4.15c-.05.21-.08.43-.08.66 0 1.61 1.31 2.91 2.92 2.91s2.92-1.3 2.92-2.91A2.92 2.92 0 0 0 18 16.08"/></svg> </a> <button type=reset class="md-search__icon md-icon" title=Clear aria-label=Clear tabindex=-1> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"/></svg> </button> </nav> <div class=md-search__suggest data-md-component=search-suggest></div> </form> <div class=md-search__output> <div class=md-search__scrollwrap tabindex=0 data-md-scrollfix> <div class=md-search-result data-md-component=search-result> <div class=md-search-result__meta> Initializing search </div> <ol class=md-search-result__list role=presentation></ol> </div> </div> </div> </div> </div> <div class=md-header__source> <a href=https://github.com/albumentations-team/albumentations title="Go to repository" class=md-source data-md-component=source> <div class="md-source__icon md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 496 512"><!-- Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6m-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3m44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9M244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8M97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1m-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7m32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1m-11.4-14.7c-1.6 1-1.6 3.6 0 5.9s4.3 3.3 5.6 2.3c1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2"/></svg> </div> <div class=md-source__repository> albumentations </div> </a> </div> </nav> </header> <div class=md-container data-md-component=container> <main class=md-main data-md-component=main> <div class="md-main__inner md-grid"> <div class="md-sidebar md-sidebar--primary" data-md-component=sidebar data-md-type=navigation> <div class=md-sidebar__scrollwrap> <div class=md-sidebar__inner> <nav class="md-nav md-nav--primary md-nav--integrated" aria-label=Navigation data-md-level=0> <label class=md-nav__title for=__drawer> <a href=../../.. title="Albumentations Documentation" class="md-nav__button md-logo" aria-label="Albumentations Documentation" data-md-component=logo> <img src=../../../images/logo.png alt=logo> </a> Albumentations Documentation </label> <div class=md-nav__source> <a href=https://github.com/albumentations-team/albumentations title="Go to repository" class=md-source data-md-component=source> <div class="md-source__icon md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 496 512"><!-- Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6m-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3m44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9M244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8M97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1m-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7m32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1m-11.4-14.7c-1.6 1-1.6 3.6 0 5.9s4.3 3.3 5.6 2.3c1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2"/></svg> </div> <div class=md-source__repository> albumentations </div> </a> </div> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../.. class=md-nav__link> <span class=md-ellipsis> Documentation </span> </a> </li> <li class=md-nav__item> <a href=../../../benchmarking_results/ class=md-nav__link> <span class=md-ellipsis> Benchmarking Results </span> </a> </li> <li class="md-nav__item md-nav__item--section md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_3> <label class=md-nav__link for=__nav_3 id=__nav_3_label tabindex> <span class=md-ellipsis> Introduction </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=1 aria-labelledby=__nav_3_label aria-expanded=false> <label class=md-nav__title for=__nav_3> <span class="md-nav__icon md-icon"></span> Introduction </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../../introduction/image_augmentation/ class=md-nav__link> <span class=md-ellipsis> What is image augmentation </span> </a> </li> <li class=md-nav__item> <a href=../../../introduction/why_you_need_a_dedicated_library_for_image_augmentation/ class=md-nav__link> <span class=md-ellipsis> Why you need a dedicated library </span> </a> </li> <li class=md-nav__item> <a href=../../../introduction/why_albumentations/ class=md-nav__link> <span class=md-ellipsis> Why Albumentations </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--section md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_4> <label class=md-nav__link for=__nav_4 id=__nav_4_label tabindex> <span class=md-ellipsis> Getting started </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=1 aria-labelledby=__nav_4_label aria-expanded=false> <label class=md-nav__title for=__nav_4> <span class="md-nav__icon md-icon"></span> Getting started </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../../getting_started/installation/ class=md-nav__link> <span class=md-ellipsis> Installation </span> </a> </li> <li class=md-nav__item> <a href=../../../getting_started/image_augmentation/ class=md-nav__link> <span class=md-ellipsis> Image augmentation for classification </span> </a> </li> <li class=md-nav__item> <a href=../../../getting_started/mask_augmentation/ class=md-nav__link> <span class=md-ellipsis> Mask augmentation for segmentation </span> </a> </li> <li class=md-nav__item> <a href=../../../getting_started/bounding_boxes_augmentation/ class=md-nav__link> <span class=md-ellipsis> Bounding boxes augmentation for object detection </span> </a> </li> <li class=md-nav__item> <a href=../../../getting_started/keypoints_augmentation/ class=md-nav__link> <span class=md-ellipsis> Keypoints augmentation </span> </a> </li> <li class=md-nav__item> <a href=../../../getting_started/simultaneous_augmentation/ class=md-nav__link> <span class=md-ellipsis> Simultaneous augmentation of multiple targets: masks, bounding boxes, keypoints </span> </a> </li> <li class=md-nav__item> <a href=../../../getting_started/transforms_and_targets/ class=md-nav__link> <span class=md-ellipsis> A list of transforms and their supported targets </span> </a> </li> <li class=md-nav__item> <a href=../../../getting_started/augmentation_mapping/ class=md-nav__link> <span class=md-ellipsis> Transform Library Comparison Guide </span> </a> </li> <li class=md-nav__item> <a href=../../../getting_started/setting_probabilities/ class=md-nav__link> <span class=md-ellipsis> Setting probabilities for transforms </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--section md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_5> <div class="md-nav__link md-nav__container"> <a href=../../../examples/ class="md-nav__link "> <span class=md-ellipsis> Examples </span> </a> </div> <nav class=md-nav data-md-level=1 aria-labelledby=__nav_5_label aria-expanded=false> <label class=md-nav__title for=__nav_5> <span class="md-nav__icon md-icon"></span> Examples </label> <ul class=md-nav__list data-md-scrollfix> </ul> </nav> </li> <li class=md-nav__item> <a href=../../../faq/ class=md-nav__link> <span class=md-ellipsis> FAQ </span> </a> </li> <li class="md-nav__item md-nav__item--section md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_7> <label class=md-nav__link for=__nav_7 id=__nav_7_label tabindex> <span class=md-ellipsis> External resources </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=1 aria-labelledby=__nav_7_label aria-expanded=false> <label class=md-nav__title for=__nav_7> <span class="md-nav__icon md-icon"></span> External resources </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../../external_resources/online_courses/ class=md-nav__link> <span class=md-ellipsis> Online classes that cover Albumentations </span> </a> </li> <li class=md-nav__item> <a href=../../../external_resources/blog_posts_podcasts_talks/ class=md-nav__link> <span class=md-ellipsis> Blog posts, podcasts, talks, and videos about Albumentations </span> </a> </li> <li class=md-nav__item> <a href=../../../external_resources/books/ class=md-nav__link> <span class=md-ellipsis> Books that mention Albumentations </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--active md-nav__item--section md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_8 checked> <label class=md-nav__link for=__nav_8 id=__nav_8_label tabindex> <span class=md-ellipsis> Integrations </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=1 aria-labelledby=__nav_8_label aria-expanded=true> <label class=md-nav__title for=__nav_8> <span class="md-nav__icon md-icon"></span> Integrations </label> <ul class=md-nav__list data-md-scrollfix> <li class="md-nav__item md-nav__item--active md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_8_1 checked> <div class="md-nav__link md-nav__container"> <a href=../ class="md-nav__link "> <span class=md-ellipsis> HuggingFace </span> </a> <label class="md-nav__link " for=__nav_8_1 id=__nav_8_1_label tabindex=0> <span class="md-nav__icon md-icon"></span> </label> </div> <nav class=md-nav data-md-level=2 aria-labelledby=__nav_8_1_label aria-expanded=true> <label class=md-nav__title for=__nav_8_1> <span class="md-nav__icon md-icon"></span> HuggingFace </label> <ul class=md-nav__list data-md-scrollfix> <li class="md-nav__item md-nav__item--active"> <input class="md-nav__toggle md-toggle" type=checkbox id=__toc> <label class="md-nav__link md-nav__link--active" for=__toc> <span class=md-ellipsis> Image classification </span> <span class="md-nav__icon md-icon"></span> </label> <a href=./ class="md-nav__link md-nav__link--active"> <span class=md-ellipsis> Image classification </span> </a> <nav class="md-nav md-nav--secondary" aria-label="Table of contents"> <label class=md-nav__title for=__toc> <span class="md-nav__icon md-icon"></span> Table of contents </label> <ul class=md-nav__list data-md-component=toc data-md-scrollfix> <li class=md-nav__item> <a href=#imagefolder-feature class=md-nav__link> <span class=md-ellipsis> ImageFolder feature </span> </a> </li> <li class=md-nav__item> <a href=#any-model class=md-nav__link> <span class=md-ellipsis> Any model </span> </a> </li> <li class=md-nav__item> <a href=#albumentations class=md-nav__link> <span class=md-ellipsis> Albumentations </span> </a> </li> <li class=md-nav__item> <a href=#fine-tuning-a-model-on-an-image-classification-task class=md-nav__link> <span class=md-ellipsis> Fine-tuning a model on an image classification task </span> </a> <nav class=md-nav aria-label="Fine-tuning a model on an image classification task"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#loading-the-dataset class=md-nav__link> <span class=md-ellipsis> Loading the dataset </span> </a> </li> <li class=md-nav__item> <a href=#preprocessing-the-data class=md-nav__link> <span class=md-ellipsis> Preprocessing the data </span> </a> </li> <li class=md-nav__item> <a href=#training-the-model class=md-nav__link> <span class=md-ellipsis> Training the model </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#inference class=md-nav__link> <span class=md-ellipsis> Inference </span> </a> </li> <li class=md-nav__item> <a href=#pipeline-api class=md-nav__link> <span class=md-ellipsis> Pipeline API </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=../object_detection/ class=md-nav__link> <span class=md-ellipsis> Object Detection </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--pruned md-nav__item--nested"> <a href=../../roboflow/train-rt-detr-on-custom-dataset-with-transformers/ class=md-nav__link> <span class=md-ellipsis> Roboflow </span> <span class="md-nav__icon md-icon"></span> </a> </li> <li class=md-nav__item> <a href=../../fiftyone/ class=md-nav__link> <span class=md-ellipsis> Voxel51 </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=../../../frameworks_and_libraries/ class=md-nav__link> <span class=md-ellipsis> Frameworks and libraries that use Albumentations </span> </a> </li> <li class="md-nav__item md-nav__item--section md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_10> <div class="md-nav__link md-nav__container"> <a href=../../../api_reference/ class="md-nav__link "> <span class=md-ellipsis> API Reference </span> </a> <label class="md-nav__link " for=__nav_10 id=__nav_10_label tabindex> <span class="md-nav__icon md-icon"></span> </label> </div> <nav class=md-nav data-md-level=1 aria-labelledby=__nav_10_label aria-expanded=false> <label class=md-nav__title for=__nav_10> <span class="md-nav__icon md-icon"></span> API Reference </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../../api_reference/full_reference/ class=md-nav__link> <span class=md-ellipsis> Full API Reference </span> </a> </li> <li class="md-nav__item md-nav__item--pruned md-nav__item--nested"> <a href=../../../api_reference/core/ class=md-nav__link> <span class=md-ellipsis> Core API </span> <span class="md-nav__icon md-icon"></span> </a> </li> <li class="md-nav__item md-nav__item--pruned md-nav__item--nested"> <a href=../../../api_reference/augmentations/ class=md-nav__link> <span class=md-ellipsis> Augmentations </span> <span class="md-nav__icon md-icon"></span> </a> </li> <li class="md-nav__item md-nav__item--pruned md-nav__item--nested"> <a href=../../../api_reference/pytorch/ class=md-nav__link> <span class=md-ellipsis> PyTorch Helpers </span> <span class="md-nav__icon md-icon"></span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=../../../CONTRIBUTING/ class=md-nav__link> <span class=md-ellipsis> Contributing </span> </a> </li> <li class="md-nav__item md-nav__item--section md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_12> <label class=md-nav__link for=__nav_12 id=__nav_12_label tabindex> <span class=md-ellipsis> Contributing </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=1 aria-labelledby=__nav_12_label aria-expanded=false> <label class=md-nav__title for=__nav_12> <span class="md-nav__icon md-icon"></span> Contributing </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../../contributing/coding_guidelines/ class=md-nav__link> <span class=md-ellipsis> Coding Guidelines </span> </a> </li> <li class=md-nav__item> <a href=../../../contributing/environment_setup/ class=md-nav__link> <span class=md-ellipsis> Environment Setup </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--section md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_13> <div class="md-nav__link md-nav__container"> <a href=../../../autoalbument/ class="md-nav__link "> <span class=md-ellipsis> AutoAlbument </span> </a> <label class="md-nav__link " for=__nav_13 id=__nav_13_label tabindex> <span class="md-nav__icon md-icon"></span> </label> </div> <nav class=md-nav data-md-level=1 aria-labelledby=__nav_13_label aria-expanded=false> <label class=md-nav__title for=__nav_13> <span class="md-nav__icon md-icon"></span> AutoAlbument </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../../autoalbument/benchmarks/ class=md-nav__link> <span class=md-ellipsis> Benchmarks and a comparison with baseline augmentation strategies </span> </a> </li> <li class=md-nav__item> <a href=../../../autoalbument/installation/ class=md-nav__link> <span class=md-ellipsis> Installation </span> </a> </li> <li class=md-nav__item> <a href=../../../autoalbument/how_to_use/ class=md-nav__link> <span class=md-ellipsis> How to use AutoAlbument </span> </a> </li> <li class=md-nav__item> <a href=../../../autoalbument/docker/ class=md-nav__link> <span class=md-ellipsis> How to use an AutoAlbument Docker image </span> </a> </li> <li class=md-nav__item> <a href=../../../autoalbument/custom_model/ class=md-nav__link> <span class=md-ellipsis> How to use a custom classification or semantic segmentation model </span> </a> </li> <li class=md-nav__item> <a href=../../../autoalbument/metrics/ class=md-nav__link> <span class=md-ellipsis> Metrics and their meaning </span> </a> </li> <li class=md-nav__item> <a href=../../../autoalbument/tuning_parameters/ class=md-nav__link> <span class=md-ellipsis> Tuning the search parameters </span> </a> </li> <li class="md-nav__item md-nav__item--pruned md-nav__item--nested"> <a href=../../../autoalbument/examples/list/ class=md-nav__link> <span class=md-ellipsis> Examples </span> <span class="md-nav__icon md-icon"></span> </a> </li> <li class=md-nav__item> <a href=../../../autoalbument/search_algorithms/ class=md-nav__link> <span class=md-ellipsis> Search algorithms </span> </a> </li> <li class=md-nav__item> <a href=../../../autoalbument/faq/ class=md-nav__link> <span class=md-ellipsis> FAQ </span> </a> </li> </ul> </nav> </li> </ul> </nav> </div> </div> </div> <div class=md-content data-md-component=content> <article class="md-content__inner md-typeset"> <style>
  .highlight-ipynb {
    font-size: 0.7rem;
  }

  .jupyter-wrapper .jp-MarkdownOutput.jp-RenderedHTMLCommon {
    font-size: 0.8rem;
  }
</style> <a href=https://github.com/albumentations-team/albumentations/edit/master/docs/src/docs/integrations/huggingface/image_classification_albumentations.md title=edit.link.title class="md-content__button md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M20.71 7.04c.39-.39.39-1.04 0-1.41l-2.34-2.34c-.37-.39-1.02-.39-1.41 0l-1.84 1.83 3.75 3.75M3 17.25V21h3.75L17.81 9.93l-3.75-3.75z"/></svg> </a> <h1 id=fine-tuning-for-image-classification-with-transformers><strong>Fine-tuning for Image Classification with 🤗 Transformers</strong><a class=headerlink href=#fine-tuning-for-image-classification-with-transformers title="Permanent link">&para;</a></h1> <p>This notebook shows how to fine-tune any pretrained Vision model for Image Classification on a custom dataset. The idea is to add a randomly initialized classification head on top of a pre-trained encoder, and fine-tune the model altogether on a labeled dataset.</p> <h2 id=imagefolder-feature>ImageFolder feature<a class=headerlink href=#imagefolder-feature title="Permanent link">&para;</a></h2> <p>This notebook leverages the <a href=https://huggingface.co/docs/datasets/v2.0.0/en/image_process#imagefolder>ImageFolder</a> feature to easily run the notebook on a custom dataset (namely, <a href=https://github.com/phelber/EuroSAT>EuroSAT</a> in this tutorial). You can either load a <code>Dataset</code> from local folders or from local/remote files, like zip or tar.</p> <h2 id=any-model>Any model<a class=headerlink href=#any-model title="Permanent link">&para;</a></h2> <p>This notebook is built to run on any image classification dataset with any vision model checkpoint from the <a href=https://huggingface.co/ >Model Hub</a> as long as that model has a version with a Image Classification head, such as: * <a href=https://huggingface.co/docs/transformers/model_doc/vit#transformers.ViTForImageClassification>ViT</a> * <a href=https://huggingface.co/docs/transformers/model_doc/swin#transformers.SwinForImageClassification>Swin Transformer</a> * <a href=https://huggingface.co/docs/transformers/master/en/model_doc/convnext#transformers.ConvNextForImageClassification>ConvNeXT</a></p> <ul> <li>in short, any model supported by <a href=https://huggingface.co/docs/transformers/model_doc/auto#transformers.AutoModelForImageClassification>AutoModelForImageClassification</a>.</li> </ul> <h2 id=albumentations>Albumentations<a class=headerlink href=#albumentations title="Permanent link">&para;</a></h2> <p>In this notebook, we are going to leverage the <a href=https://albumentations.ai/docs/ >Albumentations</a> library for data augmentation. Note that we have other versions of this notebook available as well with other libraries including:</p> <ul> <li><a href=https://github.com/huggingface/notebooks/blob/main/examples/image_classification.ipynb>Torchvision's Transforms</a></li> <li><a href=https://github.com/huggingface/notebooks/blob/main/examples/image_classification_kornia.ipynb>Kornia</a></li> <li><a href=https://github.com/huggingface/notebooks/blob/main/examples/image_classification_imgaug.ipynb>imgaug</a>. </li> </ul> <hr> <p>Depending on the model and the GPU you are using, you might need to adjust the batch size to avoid out-of-memory errors. Set those two parameters, then the rest of the notebook should run smoothly.</p> <p>In this notebook, we'll fine-tune from the <a href=https://huggingface.co/facebook/convnext-tiny-224>https://huggingface.co/facebook/convnext-tiny-224</a> checkpoint, but note that there are many, many more available on the hub.</p> <div class="language-python highlight"><span class=filename>Python</span><pre><span></span><code><span id=__span-0-1><a id=__codelineno-0-1 name=__codelineno-0-1></a><a href=#__codelineno-0-1><span class=linenos data-linenos="1 "></span></a><span class=n>model_checkpoint</span> <span class=o>=</span> <span class=s2>&quot;facebook/convnext-tiny-224&quot;</span> <span class=c1># pre-trained model from which to fine-tune</span>
</span><span id=__span-0-2><a id=__codelineno-0-2 name=__codelineno-0-2></a><a href=#__codelineno-0-2><span class=linenos data-linenos="2 "></span></a><span class=n>batch_size</span> <span class=o>=</span> <span class=mi>32</span> <span class=c1># batch size for training and evaluation</span>
</span></code></pre></div> <p>Before we start, let's install the <code>datasets</code>, <code>transformers</code> and <code>albumentations</code> libraries.</p> <div class="language-python highlight"><span class=filename>Python</span><pre><span></span><code><span id=__span-1-1><a id=__codelineno-1-1 name=__codelineno-1-1></a><a href=#__codelineno-1-1><span class=linenos data-linenos="1 "></span></a><span class=err>!</span><span class=n>pip</span> <span class=n>install</span> <span class=o>-</span><span class=n>q</span> <span class=n>datasets</span> <span class=n>transformers</span>
</span></code></pre></div> <div class=codehilite><pre><span></span><code><span class=err></span><span class=p>[</span><span class=nx>K</span><span class=w>     </span><span class=o>|</span><span class=err>████████████████████████████████</span><span class=o>|</span><span class=w> </span><span class=mi>325</span><span class=w> </span><span class=nx>kB</span><span class=w> </span><span class="m m-Double">8.7</span><span class=w> </span><span class=nx>MB</span><span class=o>/</span><span class=nx>s</span><span class=w> </span>
<span class=err></span><span class=p>[</span><span class=nx>K</span><span class=w>     </span><span class=o>|</span><span class=err>████████████████████████████████</span><span class=o>|</span><span class=w> </span><span class="m m-Double">4.0</span><span class=w> </span><span class=nx>MB</span><span class=w> </span><span class="m m-Double">67.0</span><span class=w> </span><span class=nx>MB</span><span class=o>/</span><span class=nx>s</span><span class=w> </span>
<span class=err></span><span class=p>[</span><span class=nx>K</span><span class=w>     </span><span class=o>|</span><span class=err>████████████████████████████████</span><span class=o>|</span><span class=w> </span><span class=mi>77</span><span class=w> </span><span class=nx>kB</span><span class=w> </span><span class="m m-Double">8.1</span><span class=w> </span><span class=nx>MB</span><span class=o>/</span><span class=nx>s</span><span class=w> </span>
<span class=err></span><span class=p>[</span><span class=nx>K</span><span class=w>     </span><span class=o>|</span><span class=err>████████████████████████████████</span><span class=o>|</span><span class=w> </span><span class="m m-Double">1.1</span><span class=w> </span><span class=nx>MB</span><span class=w> </span><span class="m m-Double">48.8</span><span class=w> </span><span class=nx>MB</span><span class=o>/</span><span class=nx>s</span><span class=w> </span>
<span class=err></span><span class=p>[</span><span class=nx>K</span><span class=w>     </span><span class=o>|</span><span class=err>████████████████████████████████</span><span class=o>|</span><span class=w> </span><span class=mi>136</span><span class=w> </span><span class=nx>kB</span><span class=w> </span><span class="m m-Double">72.0</span><span class=w> </span><span class=nx>MB</span><span class=o>/</span><span class=nx>s</span><span class=w> </span>
<span class=err></span><span class=p>[</span><span class=nx>K</span><span class=w>     </span><span class=o>|</span><span class=err>████████████████████████████████</span><span class=o>|</span><span class=w> </span><span class=mi>212</span><span class=w> </span><span class=nx>kB</span><span class=w> </span><span class="m m-Double">72.9</span><span class=w> </span><span class=nx>MB</span><span class=o>/</span><span class=nx>s</span><span class=w> </span>
<span class=err></span><span class=p>[</span><span class=nx>K</span><span class=w>     </span><span class=o>|</span><span class=err>████████████████████████████████</span><span class=o>|</span><span class=w> </span><span class=mi>127</span><span class=w> </span><span class=nx>kB</span><span class=w> </span><span class="m m-Double">75.0</span><span class=w> </span><span class=nx>MB</span><span class=o>/</span><span class=nx>s</span><span class=w> </span>
<span class=err></span><span class=p>[</span><span class=nx>K</span><span class=w>     </span><span class=o>|</span><span class=err>████████████████████████████████</span><span class=o>|</span><span class=w> </span><span class=mi>895</span><span class=w> </span><span class=nx>kB</span><span class=w> </span><span class="m m-Double">67.3</span><span class=w> </span><span class=nx>MB</span><span class=o>/</span><span class=nx>s</span><span class=w> </span>
<span class=err></span><span class=p>[</span><span class=nx>K</span><span class=w>     </span><span class=o>|</span><span class=err>████████████████████████████████</span><span class=o>|</span><span class=w> </span><span class="m m-Double">6.5</span><span class=w> </span><span class=nx>MB</span><span class=w> </span><span class="m m-Double">56.3</span><span class=w> </span><span class=nx>MB</span><span class=o>/</span><span class=nx>s</span><span class=w> </span>
<span class=err></span><span class=p>[</span><span class=nx>K</span><span class=w>     </span><span class=o>|</span><span class=err>████████████████████████████████</span><span class=o>|</span><span class=w> </span><span class=mi>596</span><span class=w> </span><span class=nx>kB</span><span class=w> </span><span class="m m-Double">76.4</span><span class=w> </span><span class=nx>MB</span><span class=o>/</span><span class=nx>s</span><span class=w> </span>
<span class=err></span><span class=p>[</span><span class=nx>K</span><span class=w>     </span><span class=o>|</span><span class=err>████████████████████████████████</span><span class=o>|</span><span class=w> </span><span class=mi>144</span><span class=w> </span><span class=nx>kB</span><span class=w> </span><span class="m m-Double">76.3</span><span class=w> </span><span class=nx>MB</span><span class=o>/</span><span class=nx>s</span><span class=w> </span>
<span class=err></span><span class=p>[</span><span class=nx>K</span><span class=w>     </span><span class=o>|</span><span class=err>████████████████████████████████</span><span class=o>|</span><span class=w> </span><span class=mi>94</span><span class=w> </span><span class=nx>kB</span><span class=w> </span><span class="m m-Double">3.3</span><span class=w> </span><span class=nx>MB</span><span class=o>/</span><span class=nx>s</span><span class=w> </span>
<span class=err></span><span class=p>[</span><span class=nx>K</span><span class=w>     </span><span class=o>|</span><span class=err>████████████████████████████████</span><span class=o>|</span><span class=w> </span><span class=mi>271</span><span class=w> </span><span class=nx>kB</span><span class=w> </span><span class="m m-Double">77.3</span><span class=w> </span><span class=nx>MB</span><span class=o>/</span><span class=nx>s</span><span class=w> </span>
<span class=err></span><span class=p>[</span><span class=mi>31</span><span class=nx>mERROR</span><span class=p>:</span><span class=w> </span><span class=nx>pip</span><span class=err>&#39;</span><span class=nx>s</span><span class=w> </span><span class=nx>dependency</span><span class=w> </span><span class=nx>resolver</span><span class=w> </span><span class=nx>does</span><span class=w> </span><span class=k>not</span><span class=w> </span><span class=nx>currently</span><span class=w> </span><span class=nx>take</span><span class=w> </span><span class=nx>into</span><span class=w> </span><span class=nx>account</span><span class=w> </span><span class=nx>all</span><span class=w> </span><span class=nx>the</span><span class=w> </span><span class=nx>packages</span><span class=w> </span><span class=nx>that</span><span class=w> </span><span class=nx>are</span><span class=w> </span><span class=nx>installed</span><span class=p>.</span><span class=w> </span><span class=nx>This</span><span class=w> </span><span class=nx>behaviour</span><span class=w> </span><span class=k>is</span><span class=w> </span><span class=nx>the</span><span class=w> </span><span class=nx>source</span><span class=w> </span><span class=nx>of</span><span class=w> </span><span class=nx>the</span><span class=w> </span><span class=nx>following</span><span class=w> </span><span class=nx>dependency</span><span class=w> </span><span class=nx>conflicts</span><span class=p>.</span>
<span class=nx>datascience</span><span class=w> </span><span class="m m-Double">0.10.6</span><span class=w> </span><span class=nx>requires</span><span class=w> </span><span class=nx>folium</span><span class=o>==</span><span class="m m-Double">0.2.1</span><span class=p>,</span><span class=w> </span><span class=nx>but</span><span class=w> </span><span class=nx>you</span><span class=w> </span><span class=nx>have</span><span class=w> </span><span class=nx>folium</span><span class=w> </span><span class="m m-Double">0.8.3</span><span class=w> </span><span class=nx>which</span><span class=w> </span><span class=k>is</span><span class=w> </span><span class=nx>incompatible</span><span class=p>.</span><span class=err></span><span class=p>[</span><span class=mi>0</span><span class=nx>m</span>
<span class=err></span><span class=p>[?</span><span class=mi>25</span><span class=nx>h</span>
</code></pre></div> <div class="language-python highlight"><span class=filename>Python</span><pre><span></span><code><span id=__span-2-1><a id=__codelineno-2-1 name=__codelineno-2-1></a><a href=#__codelineno-2-1><span class=linenos data-linenos="1 "></span></a><span class=err>!</span><span class=n>pip</span> <span class=n>install</span> <span class=o>-</span><span class=n>q</span> <span class=n>albumentations</span>
</span></code></pre></div> <div class=codehilite><pre><span></span><code>[?25l
</code></pre></div> <p>[K |▌ | 10 kB 26.1 MB/s eta 0:00:01 [K |█ | 20 kB 27.6 MB/s eta 0:00:01 [K |█▋ | 30 kB 11.8 MB/s eta 0:00:01 [K |██ | 40 kB 8.9 MB/s eta 0:00:01 [K |██▋ | 51 kB 6.7 MB/s eta 0:00:01 [K |███▏ | 61 kB 7.9 MB/s eta 0:00:01 [K |███▋ | 71 kB 8.0 MB/s eta 0:00:01 [K |████▏ | 81 kB 7.4 MB/s eta 0:00:01 [K |████▊ | 92 kB 8.2 MB/s eta 0:00:01 [K |█████▏ | 102 kB 8.4 MB/s eta 0:00:01 [K |█████▊ | 112 kB 8.4 MB/s eta 0:00:01 [K |██████▎ | 122 kB 8.4 MB/s eta 0:00:01 [K |██████▊ | 133 kB 8.4 MB/s eta 0:00:01 [K |███████▎ | 143 kB 8.4 MB/s eta 0:00:01 [K |███████▉ | 153 kB 8.4 MB/s eta 0:00:01 [K |████████▎ | 163 kB 8.4 MB/s eta 0:00:01 [K |████████▉ | 174 kB 8.4 MB/s eta 0:00:01 [K |█████████▍ | 184 kB 8.4 MB/s eta 0:00:01 [K |█████████▉ | 194 kB 8.4 MB/s eta 0:00:01 [K |██████████▍ | 204 kB 8.4 MB/s eta 0:00:01 [K |███████████ | 215 kB 8.4 MB/s eta 0:00:01 [K |███████████▍ | 225 kB 8.4 MB/s eta 0:00:01 [K |████████████ | 235 kB 8.4 MB/s eta 0:00:01 [K |████████████▌ | 245 kB 8.4 MB/s eta 0:00:01 [K |█████████████ | 256 kB 8.4 MB/s eta 0:00:01 [K |█████████████▌ | 266 kB 8.4 MB/s eta 0:00:01 [K |██████████████ | 276 kB 8.4 MB/s eta 0:00:01 [K |██████████████▌ | 286 kB 8.4 MB/s eta 0:00:01 [K |███████████████ | 296 kB 8.4 MB/s eta 0:00:01 [K |███████████████▋ | 307 kB 8.4 MB/s eta 0:00:01 [K |████████████████ | 317 kB 8.4 MB/s eta 0:00:01 [K |████████████████▋ | 327 kB 8.4 MB/s eta 0:00:01 [K |█████████████████▏ | 337 kB 8.4 MB/s eta 0:00:01 [K |█████████████████▋ | 348 kB 8.4 MB/s eta 0:00:01 [K |██████████████████▏ | 358 kB 8.4 MB/s eta 0:00:01 [K |██████████████████▊ | 368 kB 8.4 MB/s eta 0:00:01 [K |███████████████████▏ | 378 kB 8.4 MB/s eta 0:00:01 [K |███████████████████▊ | 389 kB 8.4 MB/s eta 0:00:01 [K |████████████████████▎ | 399 kB 8.4 MB/s eta 0:00:01 [K |████████████████████▊ | 409 kB 8.4 MB/s eta 0:00:01 [K |█████████████████████▎ | 419 kB 8.4 MB/s eta 0:00:01 [K |█████████████████████▉ | 430 kB 8.4 MB/s eta 0:00:01 [K |██████████████████████▎ | 440 kB 8.4 MB/s eta 0:00:01 [K |██████████████████████▉ | 450 kB 8.4 MB/s eta 0:00:01 [K |███████████████████████▍ | 460 kB 8.4 MB/s eta 0:00:01 [K |███████████████████████▉ | 471 kB 8.4 MB/s eta 0:00:01 [K |████████████████████████▍ | 481 kB 8.4 MB/s eta 0:00:01 [K |█████████████████████████ | 491 kB 8.4 MB/s eta 0:00:01 [K |█████████████████████████▍ | 501 kB 8.4 MB/s eta 0:00:01 [K |██████████████████████████ | 512 kB 8.4 MB/s eta 0:00:01 [K |██████████████████████████▌ | 522 kB 8.4 MB/s eta 0:00:01 [K |███████████████████████████ | 532 kB 8.4 MB/s eta 0:00:01 [K |███████████████████████████▌ | 542 kB 8.4 MB/s eta 0:00:01 [K |████████████████████████████ | 552 kB 8.4 MB/s eta 0:00:01 [K |████████████████████████████▌ | 563 kB 8.4 MB/s eta 0:00:01 [K |█████████████████████████████ | 573 kB 8.4 MB/s eta 0:00:01 [K |█████████████████████████████▋ | 583 kB 8.4 MB/s eta 0:00:01 [K |██████████████████████████████ | 593 kB 8.4 MB/s eta 0:00:01 [K |██████████████████████████████▋ | 604 kB 8.4 MB/s eta 0:00:01 [K |███████████████████████████████▏| 614 kB 8.4 MB/s eta 0:00:01 [K |███████████████████████████████▋| 624 kB 8.4 MB/s eta 0:00:01 [K |████████████████████████████████| 631 kB 8.4 MB/s [?25h Building wheel for imgaug (setup.py) ... [?25l[?25hdone</p> <p>If you're opening this notebook locally, make sure your environment has an install from the last version of those libraries.</p> <p>To be able to share your model with the community and generate results like the one shown in the picture below via the inference API, there are a few more steps to follow.</p> <p>First you have to store your authentication token from the Hugging Face website (sign up <a href=https://huggingface.co/join>here</a> if you haven't already!) then execute the following cell and input your token:</p> <div class="language-python highlight"><span class=filename>Python</span><pre><span></span><code><span id=__span-3-1><a id=__codelineno-3-1 name=__codelineno-3-1></a><a href=#__codelineno-3-1><span class=linenos data-linenos="1 "></span></a><span class=kn>from</span><span class=w> </span><span class=nn>huggingface_hub</span><span class=w> </span><span class=kn>import</span> <span class=n>notebook_login</span>
</span><span id=__span-3-2><a id=__codelineno-3-2 name=__codelineno-3-2></a><a href=#__codelineno-3-2><span class=linenos data-linenos="2 "></span></a>
</span><span id=__span-3-3><a id=__codelineno-3-3 name=__codelineno-3-3></a><a href=#__codelineno-3-3><span class=linenos data-linenos="3 "></span></a><span class=n>notebook_login</span><span class=p>()</span>
</span></code></pre></div> <div class=codehilite><pre><span></span><code>Login successful
Your token has been saved to /root/.huggingface/token
[1m[31mAuthenticated through git-credential store but this isn&#39;t the helper defined on your machine.
You might have to re-authenticate when pushing to the Hugging Face Hub. Run the following command in your terminal in case you want to set this credential helper as the default

git config --global credential.helper store[0m
</code></pre></div> <p>Then you need to install Git-LFS to upload your model checkpoints:</p> <div class="language-python highlight"><span class=filename>Python</span><pre><span></span><code><span id=__span-4-1><a id=__codelineno-4-1 name=__codelineno-4-1></a><a href=#__codelineno-4-1><span class=linenos data-linenos="1 "></span></a><span class=o>%%</span><span class=n>capture</span>
</span><span id=__span-4-2><a id=__codelineno-4-2 name=__codelineno-4-2></a><a href=#__codelineno-4-2><span class=linenos data-linenos="2 "></span></a><span class=err>!</span><span class=n>sudo</span> <span class=n>apt</span> <span class=o>-</span><span class=n>qq</span> <span class=n>install</span> <span class=n>git</span><span class=o>-</span><span class=n>lfs</span>
</span><span id=__span-4-3><a id=__codelineno-4-3 name=__codelineno-4-3></a><a href=#__codelineno-4-3><span class=linenos data-linenos="3 "></span></a><span class=err>!</span><span class=n>git</span> <span class=n>config</span> <span class=o>--</span><span class=k>global</span> <span class=n>credential</span><span class=o>.</span><span class=n>helper</span> <span class=n>store</span>
</span></code></pre></div> <p>We also quickly upload some telemetry - this tells us which examples and software versions are getting used so we know where to prioritize our maintenance efforts. We don't collect (or care about) any personally identifiable information, but if you'd prefer not to be counted, feel free to skip this step or delete this cell entirely.</p> <div class="language-python highlight"><span class=filename>Python</span><pre><span></span><code><span id=__span-5-1><a id=__codelineno-5-1 name=__codelineno-5-1></a><a href=#__codelineno-5-1><span class=linenos data-linenos="1 "></span></a><span class=kn>from</span><span class=w> </span><span class=nn>transformers.utils</span><span class=w> </span><span class=kn>import</span> <span class=n>send_example_telemetry</span>
</span><span id=__span-5-2><a id=__codelineno-5-2 name=__codelineno-5-2></a><a href=#__codelineno-5-2><span class=linenos data-linenos="2 "></span></a>
</span><span id=__span-5-3><a id=__codelineno-5-3 name=__codelineno-5-3></a><a href=#__codelineno-5-3><span class=linenos data-linenos="3 "></span></a><span class=n>send_example_telemetry</span><span class=p>(</span><span class=s2>&quot;image_classification_albumentations_notebook&quot;</span><span class=p>,</span> <span class=n>framework</span><span class=o>=</span><span class=s2>&quot;pytorch&quot;</span><span class=p>)</span>
</span></code></pre></div> <h2 id=fine-tuning-a-model-on-an-image-classification-task>Fine-tuning a model on an image classification task<a class=headerlink href=#fine-tuning-a-model-on-an-image-classification-task title="Permanent link">&para;</a></h2> <p>In this notebook, we will see how to fine-tune one of the <a href=https://github.com/huggingface/transformers>🤗 Transformers</a> vision models on an Image Classification dataset.</p> <p>Given an image, the goal is to predict an appropriate class for it, like "tiger". The screenshot below is taken from a <a href=https://huggingface.co/google/vit-base-patch16-224>ViT fine-tuned on ImageNet-1k</a> - try out the inference widget!</p> <p><img src=https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/tiger_image.png alt=drawing width=600></p> <h3 id=loading-the-dataset>Loading the dataset<a class=headerlink href=#loading-the-dataset title="Permanent link">&para;</a></h3> <p>We will use the <a href=https://github.com/huggingface/datasets>🤗 Datasets</a> library's <a href=https://huggingface.co/docs/datasets/v2.0.0/en/image_process#imagefolder>ImageFolder</a> feature to download our custom dataset into a DatasetDict.</p> <p>In this case, the EuroSAT dataset is hosted remotely, so we provide the <code>data_files</code> argument. Alternatively, if you have local folders with images, you can load them using the <code>data_dir</code> argument. </p> <div class="language-python highlight"><span class=filename>Python</span><pre><span></span><code><span id=__span-6-1><a id=__codelineno-6-1 name=__codelineno-6-1></a><a href=#__codelineno-6-1><span class=linenos data-linenos=" 1 "></span></a><span class=kn>from</span><span class=w> </span><span class=nn>datasets</span><span class=w> </span><span class=kn>import</span> <span class=n>load_dataset</span> 
</span><span id=__span-6-2><a id=__codelineno-6-2 name=__codelineno-6-2></a><a href=#__codelineno-6-2><span class=linenos data-linenos=" 2 "></span></a>
</span><span id=__span-6-3><a id=__codelineno-6-3 name=__codelineno-6-3></a><a href=#__codelineno-6-3><span class=linenos data-linenos=" 3 "></span></a><span class=c1># load a custom dataset from local/remote files using the ImageFolder feature</span>
</span><span id=__span-6-4><a id=__codelineno-6-4 name=__codelineno-6-4></a><a href=#__codelineno-6-4><span class=linenos data-linenos=" 4 "></span></a>
</span><span id=__span-6-5><a id=__codelineno-6-5 name=__codelineno-6-5></a><a href=#__codelineno-6-5><span class=linenos data-linenos=" 5 "></span></a><span class=c1># option 1: local/remote files (supporting the following formats: tar, gzip, zip, xz, rar, zstd)</span>
</span><span id=__span-6-6><a id=__codelineno-6-6 name=__codelineno-6-6></a><a href=#__codelineno-6-6><span class=linenos data-linenos=" 6 "></span></a><span class=n>dataset</span> <span class=o>=</span> <span class=n>load_dataset</span><span class=p>(</span><span class=s2>&quot;imagefolder&quot;</span><span class=p>,</span> <span class=n>data_files</span><span class=o>=</span><span class=s2>&quot;https://madm.dfki.de/files/sentinel/EuroSAT.zip&quot;</span><span class=p>)</span>
</span><span id=__span-6-7><a id=__codelineno-6-7 name=__codelineno-6-7></a><a href=#__codelineno-6-7><span class=linenos data-linenos=" 7 "></span></a>
</span><span id=__span-6-8><a id=__codelineno-6-8 name=__codelineno-6-8></a><a href=#__codelineno-6-8><span class=linenos data-linenos=" 8 "></span></a><span class=c1># note that you can also provide several splits:</span>
</span><span id=__span-6-9><a id=__codelineno-6-9 name=__codelineno-6-9></a><a href=#__codelineno-6-9><span class=linenos data-linenos=" 9 "></span></a><span class=c1># dataset = load_dataset(&quot;imagefolder&quot;, data_files={&quot;train&quot;: [&quot;path/to/file1&quot;, &quot;path/to/file2&quot;], &quot;test&quot;: [&quot;path/to/file3&quot;, &quot;path/to/file4&quot;]})</span>
</span><span id=__span-6-10><a id=__codelineno-6-10 name=__codelineno-6-10></a><a href=#__codelineno-6-10><span class=linenos data-linenos="10 "></span></a>
</span><span id=__span-6-11><a id=__codelineno-6-11 name=__codelineno-6-11></a><a href=#__codelineno-6-11><span class=linenos data-linenos="11 "></span></a><span class=c1># note that you can push your dataset to the hub very easily (and reload afterwards using load_dataset)!</span>
</span><span id=__span-6-12><a id=__codelineno-6-12 name=__codelineno-6-12></a><a href=#__codelineno-6-12><span class=linenos data-linenos="12 "></span></a><span class=c1># dataset.push_to_hub(&quot;nielsr/eurosat&quot;)</span>
</span><span id=__span-6-13><a id=__codelineno-6-13 name=__codelineno-6-13></a><a href=#__codelineno-6-13><span class=linenos data-linenos="13 "></span></a><span class=c1># dataset.push_to_hub(&quot;nielsr/eurosat&quot;, private=True)</span>
</span><span id=__span-6-14><a id=__codelineno-6-14 name=__codelineno-6-14></a><a href=#__codelineno-6-14><span class=linenos data-linenos="14 "></span></a>
</span><span id=__span-6-15><a id=__codelineno-6-15 name=__codelineno-6-15></a><a href=#__codelineno-6-15><span class=linenos data-linenos="15 "></span></a><span class=c1># option 2: local folder</span>
</span><span id=__span-6-16><a id=__codelineno-6-16 name=__codelineno-6-16></a><a href=#__codelineno-6-16><span class=linenos data-linenos="16 "></span></a><span class=c1># dataset = load_dataset(&quot;imagefolder&quot;, data_dir=&quot;path_to_folder&quot;)</span>
</span><span id=__span-6-17><a id=__codelineno-6-17 name=__codelineno-6-17></a><a href=#__codelineno-6-17><span class=linenos data-linenos="17 "></span></a>
</span><span id=__span-6-18><a id=__codelineno-6-18 name=__codelineno-6-18></a><a href=#__codelineno-6-18><span class=linenos data-linenos="18 "></span></a><span class=c1># option 3: just load any existing dataset from the hub ...</span>
</span><span id=__span-6-19><a id=__codelineno-6-19 name=__codelineno-6-19></a><a href=#__codelineno-6-19><span class=linenos data-linenos="19 "></span></a><span class=c1># dataset = load_dataset(&quot;cifar10&quot;)</span>
</span></code></pre></div> <div class=codehilite><pre><span></span><code><span class=n>Using</span><span class=w> </span><span class=n>custom</span><span class=w> </span><span class=n>data</span><span class=w> </span><span class=n>configuration</span><span class=w> </span><span class=n>default</span><span class=o>-</span><span class=mf>0537267e6</span><span class=n>f812d56</span>


<span class=n>Downloading</span><span class=w> </span><span class=ow>and</span><span class=w> </span><span class=n>preparing</span><span class=w> </span><span class=n>dataset</span><span class=w> </span><span class=n>image_folder</span><span class=o>/</span><span class=n>default</span><span class=w> </span><span class=n>to</span><span class=w> </span><span class=o>/</span><span class=n>root</span><span class=o>/.</span><span class=n>cache</span><span class=o>/</span><span class=n>huggingface</span><span class=o>/</span><span class=n>datasets</span><span class=o>/</span><span class=n>image_folder</span><span class=o>/</span><span class=n>default</span><span class=o>-</span><span class=mf>0537267e6</span><span class=n>f812d56</span><span class=o>/</span><span class=mf>0.0</span><span class=o>.</span><span class=mi>0</span><span class=o>/</span><span class=n>ee92df8e96c6907f3c851a987be3fd03d4b93b247e727b69a8e23ac94392a091</span><span class=o>...</span>



<span class=n>Downloading</span><span class=w> </span><span class=n>data</span><span class=w> </span><span class=n>files</span><span class=p>:</span><span class=w> </span><span class=mi>0</span><span class=n>it</span><span class=w> </span><span class=p>[</span><span class=mi>00</span><span class=p>:</span><span class=mi>00</span><span class=p>,</span><span class=w> </span><span class=err>?</span><span class=n>it</span><span class=o>/</span><span class=n>s</span><span class=p>]</span>



<span class=n>Downloading</span><span class=w> </span><span class=n>data</span><span class=w> </span><span class=n>files</span><span class=p>:</span><span class=w>   </span><span class=mi>0</span><span class=o>%|</span><span class=w>          </span><span class=o>|</span><span class=w> </span><span class=mi>0</span><span class=o>/</span><span class=mi>1</span><span class=w> </span><span class=p>[</span><span class=mi>00</span><span class=p>:</span><span class=mi>00</span><span class=o>&lt;</span><span class=err>?</span><span class=p>,</span><span class=w> </span><span class=err>?</span><span class=n>it</span><span class=o>/</span><span class=n>s</span><span class=p>]</span>



<span class=n>Downloading</span><span class=w> </span><span class=n>data</span><span class=p>:</span><span class=w>   </span><span class=mi>0</span><span class=o>%|</span><span class=w>          </span><span class=o>|</span><span class=w> </span><span class=mf>0.00</span><span class=o>/</span><span class=mf>94.3</span><span class=n>M</span><span class=w> </span><span class=p>[</span><span class=mi>00</span><span class=p>:</span><span class=mi>00</span><span class=o>&lt;</span><span class=err>?</span><span class=p>,</span><span class=w> </span><span class=err>?</span><span class=n>B</span><span class=o>/</span><span class=n>s</span><span class=p>]</span>



<span class=n>Extracting</span><span class=w> </span><span class=n>data</span><span class=w> </span><span class=n>files</span><span class=p>:</span><span class=w>   </span><span class=mi>0</span><span class=o>%|</span><span class=w>          </span><span class=o>|</span><span class=w> </span><span class=mi>0</span><span class=o>/</span><span class=mi>1</span><span class=w> </span><span class=p>[</span><span class=mi>00</span><span class=p>:</span><span class=mi>00</span><span class=o>&lt;</span><span class=err>?</span><span class=p>,</span><span class=w> </span><span class=err>?</span><span class=n>it</span><span class=o>/</span><span class=n>s</span><span class=p>]</span>



<span class=n>Generating</span><span class=w> </span><span class=n>train</span><span class=w> </span><span class=n>split</span><span class=p>:</span><span class=w> </span><span class=mi>0</span><span class=w> </span><span class=n>examples</span><span class=w> </span><span class=p>[</span><span class=mi>00</span><span class=p>:</span><span class=mi>00</span><span class=p>,</span><span class=w> </span><span class=err>?</span><span class=w> </span><span class=n>examples</span><span class=o>/</span><span class=n>s</span><span class=p>]</span>


<span class=n>Dataset</span><span class=w> </span><span class=n>image_folder</span><span class=w> </span><span class=n>downloaded</span><span class=w> </span><span class=ow>and</span><span class=w> </span><span class=n>prepared</span><span class=w> </span><span class=n>to</span><span class=w> </span><span class=o>/</span><span class=n>root</span><span class=o>/.</span><span class=n>cache</span><span class=o>/</span><span class=n>huggingface</span><span class=o>/</span><span class=n>datasets</span><span class=o>/</span><span class=n>image_folder</span><span class=o>/</span><span class=n>default</span><span class=o>-</span><span class=mf>0537267e6</span><span class=n>f812d56</span><span class=o>/</span><span class=mf>0.0</span><span class=o>.</span><span class=mi>0</span><span class=o>/</span><span class=n>ee92df8e96c6907f3c851a987be3fd03d4b93b247e727b69a8e23ac94392a091</span><span class=o>.</span><span class=w> </span><span class=n>Subsequent</span><span class=w> </span><span class=n>calls</span><span class=w> </span><span class=n>will</span><span class=w> </span><span class=n>reuse</span><span class=w> </span><span class=n>this</span><span class=w> </span><span class=n>data</span><span class=o>.</span>



<span class=w>  </span><span class=mi>0</span><span class=o>%|</span><span class=w>          </span><span class=o>|</span><span class=w> </span><span class=mi>0</span><span class=o>/</span><span class=mi>1</span><span class=w> </span><span class=p>[</span><span class=mi>00</span><span class=p>:</span><span class=mi>00</span><span class=o>&lt;</span><span class=err>?</span><span class=p>,</span><span class=w> </span><span class=err>?</span><span class=n>it</span><span class=o>/</span><span class=n>s</span><span class=p>]</span>
</code></pre></div> <p>Let us also load the Accuracy metric, which we'll use to evaluate our model both during and after training.</p> <div class="language-python highlight"><span class=filename>Python</span><pre><span></span><code><span id=__span-7-1><a id=__codelineno-7-1 name=__codelineno-7-1></a><a href=#__codelineno-7-1><span class=linenos data-linenos="1 "></span></a><span class=kn>from</span><span class=w> </span><span class=nn>datasets</span><span class=w> </span><span class=kn>import</span> <span class=n>load_metric</span>
</span><span id=__span-7-2><a id=__codelineno-7-2 name=__codelineno-7-2></a><a href=#__codelineno-7-2><span class=linenos data-linenos="2 "></span></a>
</span><span id=__span-7-3><a id=__codelineno-7-3 name=__codelineno-7-3></a><a href=#__codelineno-7-3><span class=linenos data-linenos="3 "></span></a><span class=n>metric</span> <span class=o>=</span> <span class=n>load_metric</span><span class=p>(</span><span class=s2>&quot;accuracy&quot;</span><span class=p>)</span>
</span></code></pre></div> <div class=codehilite><pre><span></span><code><span class=n>Downloading</span><span class=w> </span><span class=n>builder</span><span class=w> </span><span class=n>script</span><span class=p>:</span><span class=w>   </span><span class=mi>0</span><span class=o>%|</span><span class=w>          </span><span class=o>|</span><span class=w> </span><span class=mf>0.00</span><span class=o>/</span><span class=mf>1.41</span><span class=n>k</span><span class=w> </span><span class=p>[</span><span class=mi>00</span><span class=p>:</span><span class=mi>00</span><span class=o>&lt;</span><span class=err>?</span><span class=p>,</span><span class=w> </span><span class=err>?</span><span class=n>B</span><span class=o>/</span><span class=n>s</span><span class=p>]</span>
</code></pre></div> <p>The <code>dataset</code> object itself is a <a href=https://huggingface.co/docs/datasets/package_reference/main_classes.html#datasetdict><code>DatasetDict</code></a>, which contains one key per split (in this case, only "train" for a training split).</p> <div class="language-python highlight"><span class=filename>Python</span><pre><span></span><code><span id=__span-8-1><a id=__codelineno-8-1 name=__codelineno-8-1></a><a href=#__codelineno-8-1><span class=linenos data-linenos="1 "></span></a><span class=n>dataset</span>
</span></code></pre></div> <div class=codehilite><pre><span></span><code>DatasetDict({
    train: Dataset({
        features: [&#39;image&#39;, &#39;label&#39;],
        num_rows: 27000
    })
})
</code></pre></div> <p>To access an actual element, you need to select a split first, then give an index:</p> <div class="language-python highlight"><span class=filename>Python</span><pre><span></span><code><span id=__span-9-1><a id=__codelineno-9-1 name=__codelineno-9-1></a><a href=#__codelineno-9-1><span class=linenos data-linenos="1 "></span></a><span class=n>example</span> <span class=o>=</span> <span class=n>dataset</span><span class=p>[</span><span class=s2>&quot;train&quot;</span><span class=p>][</span><span class=mi>10</span><span class=p>]</span>
</span><span id=__span-9-2><a id=__codelineno-9-2 name=__codelineno-9-2></a><a href=#__codelineno-9-2><span class=linenos data-linenos="2 "></span></a><span class=n>example</span>
</span></code></pre></div> <div class=codehilite><pre><span></span><code>{&#39;image&#39;: &lt;PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=64x64 at 0x7FD62DA6B2D0&gt;,
 &#39;label&#39;: 2}
</code></pre></div> <p>Each example consists of an image and a corresponding label. We can also verify this by checking the features of the dataset:</p> <div class="language-python highlight"><span class=filename>Python</span><pre><span></span><code><span id=__span-10-1><a id=__codelineno-10-1 name=__codelineno-10-1></a><a href=#__codelineno-10-1><span class=linenos data-linenos="1 "></span></a><span class=n>dataset</span><span class=p>[</span><span class=s2>&quot;train&quot;</span><span class=p>]</span><span class=o>.</span><span class=n>features</span>
</span></code></pre></div> <div class=codehilite><pre><span></span><code>{&#39;image&#39;: Image(decode=True, id=None),
 &#39;label&#39;: ClassLabel(num_classes=10, names=[&#39;AnnualCrop&#39;, &#39;Forest&#39;, &#39;HerbaceousVegetation&#39;, &#39;Highway&#39;, &#39;Industrial&#39;, &#39;Pasture&#39;, &#39;PermanentCrop&#39;, &#39;Residential&#39;, &#39;River&#39;, &#39;SeaLake&#39;], id=None)}
</code></pre></div> <p>The cool thing is that we can directly view the image (as the 'image' field is an <a href=https://huggingface.co/docs/datasets/package_reference/main_classes.html#datasets.Image>Image feature</a>), as follows:</p> <div class="language-python highlight"><span class=filename>Python</span><pre><span></span><code><span id=__span-11-1><a id=__codelineno-11-1 name=__codelineno-11-1></a><a href=#__codelineno-11-1><span class=linenos data-linenos="1 "></span></a><span class=n>example</span><span class=p>[</span><span class=s1>&#39;image&#39;</span><span class=p>]</span>
</span></code></pre></div> <p><img alt=png src=/workspace/docs/src/docs/integrations/huggingface/image_classification_albumentations_26_0.png></p> <p>Let's make it a little bigger as the images in the EuroSAT dataset are of low resolution (64x64 pixels):</p> <div class="language-python highlight"><span class=filename>Python</span><pre><span></span><code><span id=__span-12-1><a id=__codelineno-12-1 name=__codelineno-12-1></a><a href=#__codelineno-12-1><span class=linenos data-linenos="1 "></span></a><span class=n>example</span><span class=p>[</span><span class=s1>&#39;image&#39;</span><span class=p>]</span><span class=o>.</span><span class=n>resize</span><span class=p>((</span><span class=mi>200</span><span class=p>,</span> <span class=mi>200</span><span class=p>))</span>
</span></code></pre></div> <p><img alt=png src=/workspace/docs/src/docs/integrations/huggingface/image_classification_albumentations_28_0.png></p> <p>Let's check the corresponding label:</p> <div class="language-python highlight"><span class=filename>Python</span><pre><span></span><code><span id=__span-13-1><a id=__codelineno-13-1 name=__codelineno-13-1></a><a href=#__codelineno-13-1><span class=linenos data-linenos="1 "></span></a><span class=n>example</span><span class=p>[</span><span class=s1>&#39;label&#39;</span><span class=p>]</span>
</span></code></pre></div> <div class=codehilite><pre><span></span><code><span class=mf>2</span>
</code></pre></div> <p>As you can see, the <code>label</code> field is not an actual string label. By default the <code>ClassLabel</code> fields are encoded into integers for convenience:</p> <div class="language-python highlight"><span class=filename>Python</span><pre><span></span><code><span id=__span-14-1><a id=__codelineno-14-1 name=__codelineno-14-1></a><a href=#__codelineno-14-1><span class=linenos data-linenos="1 "></span></a><span class=n>dataset</span><span class=p>[</span><span class=s2>&quot;train&quot;</span><span class=p>]</span><span class=o>.</span><span class=n>features</span><span class=p>[</span><span class=s2>&quot;label&quot;</span><span class=p>]</span>
</span></code></pre></div> <div class=codehilite><pre><span></span><code>ClassLabel(num_classes=10, names=[&#39;AnnualCrop&#39;, &#39;Forest&#39;, &#39;HerbaceousVegetation&#39;, &#39;Highway&#39;, &#39;Industrial&#39;, &#39;Pasture&#39;, &#39;PermanentCrop&#39;, &#39;Residential&#39;, &#39;River&#39;, &#39;SeaLake&#39;], id=None)
</code></pre></div> <p>Let's create an <code>id2label</code> dictionary to decode them back to strings and see what they are. The inverse <code>label2id</code> will be useful too, when we load the model later.</p> <div class="language-python highlight"><span class=filename>Python</span><pre><span></span><code><span id=__span-15-1><a id=__codelineno-15-1 name=__codelineno-15-1></a><a href=#__codelineno-15-1><span class=linenos data-linenos="1 "></span></a><span class=n>labels</span> <span class=o>=</span> <span class=n>dataset</span><span class=p>[</span><span class=s2>&quot;train&quot;</span><span class=p>]</span><span class=o>.</span><span class=n>features</span><span class=p>[</span><span class=s2>&quot;label&quot;</span><span class=p>]</span><span class=o>.</span><span class=n>names</span>
</span><span id=__span-15-2><a id=__codelineno-15-2 name=__codelineno-15-2></a><a href=#__codelineno-15-2><span class=linenos data-linenos="2 "></span></a><span class=n>label2id</span><span class=p>,</span> <span class=n>id2label</span> <span class=o>=</span> <span class=nb>dict</span><span class=p>(),</span> <span class=nb>dict</span><span class=p>()</span>
</span><span id=__span-15-3><a id=__codelineno-15-3 name=__codelineno-15-3></a><a href=#__codelineno-15-3><span class=linenos data-linenos="3 "></span></a><span class=k>for</span> <span class=n>i</span><span class=p>,</span> <span class=n>label</span> <span class=ow>in</span> <span class=nb>enumerate</span><span class=p>(</span><span class=n>labels</span><span class=p>):</span>
</span><span id=__span-15-4><a id=__codelineno-15-4 name=__codelineno-15-4></a><a href=#__codelineno-15-4><span class=linenos data-linenos="4 "></span></a>    <span class=n>label2id</span><span class=p>[</span><span class=n>label</span><span class=p>]</span> <span class=o>=</span> <span class=n>i</span>
</span><span id=__span-15-5><a id=__codelineno-15-5 name=__codelineno-15-5></a><a href=#__codelineno-15-5><span class=linenos data-linenos="5 "></span></a>    <span class=n>id2label</span><span class=p>[</span><span class=n>i</span><span class=p>]</span> <span class=o>=</span> <span class=n>label</span>
</span><span id=__span-15-6><a id=__codelineno-15-6 name=__codelineno-15-6></a><a href=#__codelineno-15-6><span class=linenos data-linenos="6 "></span></a>
</span><span id=__span-15-7><a id=__codelineno-15-7 name=__codelineno-15-7></a><a href=#__codelineno-15-7><span class=linenos data-linenos="7 "></span></a><span class=n>id2label</span><span class=p>[</span><span class=mi>2</span><span class=p>]</span>
</span></code></pre></div> <div class=codehilite><pre><span></span><code>&#39;HerbaceousVegetation&#39;
</code></pre></div> <h3 id=preprocessing-the-data>Preprocessing the data<a class=headerlink href=#preprocessing-the-data title="Permanent link">&para;</a></h3> <p>Before we can feed these images to our model, we need to preprocess them. </p> <p>Preprocessing images typically comes down to (1) resizing them to a particular size (2) normalizing the color channels (R,G,B) using a mean and standard deviation. These are referred to as <strong>image transformations</strong>.</p> <p>In addition, one typically performs what is called <strong>data augmentation</strong> during training (like random cropping and flipping) to make the model more robust and achieve higher accuracy. Data augmentation is also a great technique to increase the size of the training data.</p> <p>We will use <code>Albumentations</code> for the image transformations/data augmentation in this tutorial, but note that one can use any other package (like <a href=https://pytorch.org/vision/stable/transforms.html>torchvision's transforms</a>, <a href=https://github.com/aleju/imgaug>imgaug</a>, <a href=https://kornia.readthedocs.io/en/latest/ >Kornia</a>, etc.).</p> <p>To make sure we (1) resize to the appropriate size (2) use the appropriate image mean and standard deviation for the model architecture we are going to use, we instantiate what is called an image processor with the <code>AutoImageProcessor.from_pretrained</code> method.</p> <p>This image processor is a minimal preprocessor that can be used to prepare images for inference.</p> <div class="language-python highlight"><span class=filename>Python</span><pre><span></span><code><span id=__span-16-1><a id=__codelineno-16-1 name=__codelineno-16-1></a><a href=#__codelineno-16-1><span class=linenos data-linenos="1 "></span></a><span class=kn>from</span><span class=w> </span><span class=nn>transformers</span><span class=w> </span><span class=kn>import</span> <span class=n>AutoImageProcessor</span>
</span><span id=__span-16-2><a id=__codelineno-16-2 name=__codelineno-16-2></a><a href=#__codelineno-16-2><span class=linenos data-linenos="2 "></span></a>
</span><span id=__span-16-3><a id=__codelineno-16-3 name=__codelineno-16-3></a><a href=#__codelineno-16-3><span class=linenos data-linenos="3 "></span></a><span class=n>image_processor</span> <span class=o>=</span> <span class=n>AutoImageProcessor</span><span class=o>.</span><span class=n>from_pretrained</span><span class=p>(</span><span class=n>model_checkpoint</span><span class=p>)</span>
</span><span id=__span-16-4><a id=__codelineno-16-4 name=__codelineno-16-4></a><a href=#__codelineno-16-4><span class=linenos data-linenos="4 "></span></a><span class=n>image_processor</span>
</span></code></pre></div> <div class=codehilite><pre><span></span><code><span class=nx>Could</span><span class=w> </span><span class=k>not</span><span class=w> </span><span class=nx>find</span><span class=w> </span><span class=nx>image</span><span class=w> </span><span class=nx>processor</span><span class=w> </span><span class=kd>class</span><span class=w> </span><span class=k>in</span><span class=w> </span><span class=nx>the</span><span class=w> </span><span class=nx>image</span><span class=w> </span><span class=nx>processor</span><span class=w> </span><span class=nx>config</span><span class=w> </span><span class=k>or</span><span class=w> </span><span class=nx>the</span><span class=w> </span><span class=nx>model</span><span class=w> </span><span class=nx>config</span><span class=p>.</span><span class=w> </span><span class=nx>Loading</span><span class=w> </span><span class=nx>based</span><span class=w> </span><span class=nx>on</span><span class=w> </span><span class=nx>pattern</span><span class=w> </span><span class=nx>matching</span><span class=w> </span><span class=nx>with</span><span class=w> </span><span class=nx>the</span><span class=w> </span><span class=nx>model</span><span class=err>&#39;</span><span class=nx>s</span><span class=w> </span><span class=nx>feature</span><span class=w> </span><span class=nx>extractor</span><span class=w> </span><span class=nx>configuration</span><span class=p>.</span>





<span class=nx>ConvNextImageProcessor</span><span class=w> </span><span class=p>{</span>
<span class=w>  </span><span class=s>&quot;crop_pct&quot;</span><span class=p>:</span><span class=w> </span><span class="m m-Double">0.875</span><span class=p>,</span>
<span class=w>  </span><span class=s>&quot;do_normalize&quot;</span><span class=p>:</span><span class=w> </span><span class=kc>true</span><span class=p>,</span>
<span class=w>  </span><span class=s>&quot;do_rescale&quot;</span><span class=p>:</span><span class=w> </span><span class=kc>true</span><span class=p>,</span>
<span class=w>  </span><span class=s>&quot;do_resize&quot;</span><span class=p>:</span><span class=w> </span><span class=kc>true</span><span class=p>,</span>
<span class=w>  </span><span class=s>&quot;image_mean&quot;</span><span class=p>:</span><span class=w> </span><span class=p>[</span>
<span class=w>    </span><span class="m m-Double">0.485</span><span class=p>,</span>
<span class=w>    </span><span class="m m-Double">0.456</span><span class=p>,</span>
<span class=w>    </span><span class="m m-Double">0.406</span>
<span class=w>  </span><span class=p>],</span>
<span class=w>  </span><span class=s>&quot;image_processor_type&quot;</span><span class=p>:</span><span class=w> </span><span class=s>&quot;ConvNextImageProcessor&quot;</span><span class=p>,</span>
<span class=w>  </span><span class=s>&quot;image_std&quot;</span><span class=p>:</span><span class=w> </span><span class=p>[</span>
<span class=w>    </span><span class="m m-Double">0.229</span><span class=p>,</span>
<span class=w>    </span><span class="m m-Double">0.224</span><span class=p>,</span>
<span class=w>    </span><span class="m m-Double">0.225</span>
<span class=w>  </span><span class=p>],</span>
<span class=w>  </span><span class=s>&quot;resample&quot;</span><span class=p>:</span><span class=w> </span><span class=mi>3</span><span class=p>,</span>
<span class=w>  </span><span class=s>&quot;rescale_factor&quot;</span><span class=p>:</span><span class=w> </span><span class="m m-Double">0.00392156862745098</span><span class=p>,</span>
<span class=w>  </span><span class=s>&quot;size&quot;</span><span class=p>:</span><span class=w> </span><span class=p>{</span>
<span class=w>    </span><span class=s>&quot;shortest_edge&quot;</span><span class=p>:</span><span class=w> </span><span class=mi>224</span>
<span class=w>  </span><span class=p>}</span>
<span class=p>}</span>
</code></pre></div> <p>The Datasets library is made for processing data very easily. We can write custom functions, which can then be applied on an entire dataset (either using <a href="https://huggingface.co/docs/datasets/package_reference/main_classes.html?highlight=map#datasets.Dataset.map"><code>.map()</code></a> or <a href="https://huggingface.co/docs/datasets/package_reference/main_classes.html?highlight=set_transform#datasets.Dataset.set_transform"><code>.set_transform()</code></a>).</p> <p>Here we define 2 separate functions, one for training (which includes data augmentation) and one for validation (which only includes resizing, center cropping and normalizing). </p> <div class="language-python highlight"><span class=filename>Python</span><pre><span></span><code><span id=__span-17-1><a id=__codelineno-17-1 name=__codelineno-17-1></a><a href=#__codelineno-17-1><span class=linenos data-linenos=" 1 "></span></a><span class=kn>import</span><span class=w> </span><span class=nn>cv2</span>
</span><span id=__span-17-2><a id=__codelineno-17-2 name=__codelineno-17-2></a><a href=#__codelineno-17-2><span class=linenos data-linenos=" 2 "></span></a><span class=kn>import</span><span class=w> </span><span class=nn>albumentations</span><span class=w> </span><span class=k>as</span><span class=w> </span><span class=nn>A</span>
</span><span id=__span-17-3><a id=__codelineno-17-3 name=__codelineno-17-3></a><a href=#__codelineno-17-3><span class=linenos data-linenos=" 3 "></span></a><span class=kn>import</span><span class=w> </span><span class=nn>numpy</span><span class=w> </span><span class=k>as</span><span class=w> </span><span class=nn>np</span>
</span><span id=__span-17-4><a id=__codelineno-17-4 name=__codelineno-17-4></a><a href=#__codelineno-17-4><span class=linenos data-linenos=" 4 "></span></a>
</span><span id=__span-17-5><a id=__codelineno-17-5 name=__codelineno-17-5></a><a href=#__codelineno-17-5><span class=linenos data-linenos=" 5 "></span></a><span class=k>if</span> <span class=s2>&quot;height&quot;</span> <span class=ow>in</span> <span class=n>image_processor</span><span class=o>.</span><span class=n>size</span><span class=p>:</span>
</span><span id=__span-17-6><a id=__codelineno-17-6 name=__codelineno-17-6></a><a href=#__codelineno-17-6><span class=linenos data-linenos=" 6 "></span></a>    <span class=n>size</span> <span class=o>=</span> <span class=p>(</span><span class=n>image_processor</span><span class=o>.</span><span class=n>size</span><span class=p>[</span><span class=s2>&quot;height&quot;</span><span class=p>],</span> <span class=n>image_processor</span><span class=o>.</span><span class=n>size</span><span class=p>[</span><span class=s2>&quot;width&quot;</span><span class=p>])</span>
</span><span id=__span-17-7><a id=__codelineno-17-7 name=__codelineno-17-7></a><a href=#__codelineno-17-7><span class=linenos data-linenos=" 7 "></span></a>    <span class=n>crop_size</span> <span class=o>=</span> <span class=n>size</span>
</span><span id=__span-17-8><a id=__codelineno-17-8 name=__codelineno-17-8></a><a href=#__codelineno-17-8><span class=linenos data-linenos=" 8 "></span></a>    <span class=n>max_size</span> <span class=o>=</span> <span class=kc>None</span>
</span><span id=__span-17-9><a id=__codelineno-17-9 name=__codelineno-17-9></a><a href=#__codelineno-17-9><span class=linenos data-linenos=" 9 "></span></a><span class=k>elif</span> <span class=s2>&quot;shortest_edge&quot;</span> <span class=ow>in</span> <span class=n>image_processor</span><span class=o>.</span><span class=n>size</span><span class=p>:</span>
</span><span id=__span-17-10><a id=__codelineno-17-10 name=__codelineno-17-10></a><a href=#__codelineno-17-10><span class=linenos data-linenos="10 "></span></a>    <span class=n>size</span> <span class=o>=</span> <span class=n>image_processor</span><span class=o>.</span><span class=n>size</span><span class=p>[</span><span class=s2>&quot;shortest_edge&quot;</span><span class=p>]</span>
</span><span id=__span-17-11><a id=__codelineno-17-11 name=__codelineno-17-11></a><a href=#__codelineno-17-11><span class=linenos data-linenos="11 "></span></a>    <span class=n>crop_size</span> <span class=o>=</span> <span class=p>(</span><span class=n>size</span><span class=p>,</span> <span class=n>size</span><span class=p>)</span>
</span><span id=__span-17-12><a id=__codelineno-17-12 name=__codelineno-17-12></a><a href=#__codelineno-17-12><span class=linenos data-linenos="12 "></span></a>    <span class=n>max_size</span> <span class=o>=</span> <span class=n>image_processor</span><span class=o>.</span><span class=n>size</span><span class=o>.</span><span class=n>get</span><span class=p>(</span><span class=s2>&quot;longest_edge&quot;</span><span class=p>)</span>
</span><span id=__span-17-13><a id=__codelineno-17-13 name=__codelineno-17-13></a><a href=#__codelineno-17-13><span class=linenos data-linenos="13 "></span></a>
</span><span id=__span-17-14><a id=__codelineno-17-14 name=__codelineno-17-14></a><a href=#__codelineno-17-14><span class=linenos data-linenos="14 "></span></a><span class=n>train_transforms</span> <span class=o>=</span> <span class=n>A</span><span class=o>.</span><span class=n>Compose</span><span class=p>([</span>
</span><span id=__span-17-15><a id=__codelineno-17-15 name=__codelineno-17-15></a><a href=#__codelineno-17-15><span class=linenos data-linenos="15 "></span></a>    <span class=n>A</span><span class=o>.</span><span class=n>Resize</span><span class=p>(</span><span class=n>height</span><span class=o>=</span><span class=n>size</span><span class=p>,</span> <span class=n>width</span><span class=o>=</span><span class=n>size</span><span class=p>),</span>
</span><span id=__span-17-16><a id=__codelineno-17-16 name=__codelineno-17-16></a><a href=#__codelineno-17-16><span class=linenos data-linenos="16 "></span></a>    <span class=n>A</span><span class=o>.</span><span class=n>RandomRotate90</span><span class=p>(),</span>
</span><span id=__span-17-17><a id=__codelineno-17-17 name=__codelineno-17-17></a><a href=#__codelineno-17-17><span class=linenos data-linenos="17 "></span></a>    <span class=n>A</span><span class=o>.</span><span class=n>HorizontalFlip</span><span class=p>(</span><span class=n>p</span><span class=o>=</span><span class=mf>0.5</span><span class=p>),</span>
</span><span id=__span-17-18><a id=__codelineno-17-18 name=__codelineno-17-18></a><a href=#__codelineno-17-18><span class=linenos data-linenos="18 "></span></a>    <span class=n>A</span><span class=o>.</span><span class=n>RandomBrightnessContrast</span><span class=p>(</span><span class=n>p</span><span class=o>=</span><span class=mf>0.2</span><span class=p>),</span>
</span><span id=__span-17-19><a id=__codelineno-17-19 name=__codelineno-17-19></a><a href=#__codelineno-17-19><span class=linenos data-linenos="19 "></span></a>    <span class=n>A</span><span class=o>.</span><span class=n>Normalize</span><span class=p>(),</span>
</span><span id=__span-17-20><a id=__codelineno-17-20 name=__codelineno-17-20></a><a href=#__codelineno-17-20><span class=linenos data-linenos="20 "></span></a><span class=p>])</span>
</span><span id=__span-17-21><a id=__codelineno-17-21 name=__codelineno-17-21></a><a href=#__codelineno-17-21><span class=linenos data-linenos="21 "></span></a>
</span><span id=__span-17-22><a id=__codelineno-17-22 name=__codelineno-17-22></a><a href=#__codelineno-17-22><span class=linenos data-linenos="22 "></span></a><span class=n>val_transforms</span> <span class=o>=</span> <span class=n>A</span><span class=o>.</span><span class=n>Compose</span><span class=p>([</span>
</span><span id=__span-17-23><a id=__codelineno-17-23 name=__codelineno-17-23></a><a href=#__codelineno-17-23><span class=linenos data-linenos="23 "></span></a>    <span class=n>A</span><span class=o>.</span><span class=n>Resize</span><span class=p>(</span><span class=n>height</span><span class=o>=</span><span class=n>size</span><span class=p>,</span> <span class=n>width</span><span class=o>=</span><span class=n>size</span><span class=p>),</span>
</span><span id=__span-17-24><a id=__codelineno-17-24 name=__codelineno-17-24></a><a href=#__codelineno-17-24><span class=linenos data-linenos="24 "></span></a>    <span class=n>A</span><span class=o>.</span><span class=n>Normalize</span><span class=p>(),</span>
</span><span id=__span-17-25><a id=__codelineno-17-25 name=__codelineno-17-25></a><a href=#__codelineno-17-25><span class=linenos data-linenos="25 "></span></a><span class=p>])</span>
</span><span id=__span-17-26><a id=__codelineno-17-26 name=__codelineno-17-26></a><a href=#__codelineno-17-26><span class=linenos data-linenos="26 "></span></a>
</span><span id=__span-17-27><a id=__codelineno-17-27 name=__codelineno-17-27></a><a href=#__codelineno-17-27><span class=linenos data-linenos="27 "></span></a><span class=k>def</span><span class=w> </span><span class=nf>preprocess_train</span><span class=p>(</span><span class=n>examples</span><span class=p>):</span>
</span><span id=__span-17-28><a id=__codelineno-17-28 name=__codelineno-17-28></a><a href=#__codelineno-17-28><span class=linenos data-linenos="28 "></span></a>    <span class=n>examples</span><span class=p>[</span><span class=s2>&quot;pixel_values&quot;</span><span class=p>]</span> <span class=o>=</span> <span class=p>[</span>
</span><span id=__span-17-29><a id=__codelineno-17-29 name=__codelineno-17-29></a><a href=#__codelineno-17-29><span class=linenos data-linenos="29 "></span></a>        <span class=n>train_transforms</span><span class=p>(</span><span class=n>image</span><span class=o>=</span><span class=n>np</span><span class=o>.</span><span class=n>array</span><span class=p>(</span><span class=n>image</span><span class=p>))[</span><span class=s2>&quot;image&quot;</span><span class=p>]</span> <span class=k>for</span> <span class=n>image</span> <span class=ow>in</span> <span class=n>examples</span><span class=p>[</span><span class=s2>&quot;image&quot;</span><span class=p>]</span>
</span><span id=__span-17-30><a id=__codelineno-17-30 name=__codelineno-17-30></a><a href=#__codelineno-17-30><span class=linenos data-linenos="30 "></span></a>    <span class=p>]</span>
</span><span id=__span-17-31><a id=__codelineno-17-31 name=__codelineno-17-31></a><a href=#__codelineno-17-31><span class=linenos data-linenos="31 "></span></a>
</span><span id=__span-17-32><a id=__codelineno-17-32 name=__codelineno-17-32></a><a href=#__codelineno-17-32><span class=linenos data-linenos="32 "></span></a>    <span class=k>return</span> <span class=n>examples</span>
</span><span id=__span-17-33><a id=__codelineno-17-33 name=__codelineno-17-33></a><a href=#__codelineno-17-33><span class=linenos data-linenos="33 "></span></a>
</span><span id=__span-17-34><a id=__codelineno-17-34 name=__codelineno-17-34></a><a href=#__codelineno-17-34><span class=linenos data-linenos="34 "></span></a><span class=k>def</span><span class=w> </span><span class=nf>preprocess_val</span><span class=p>(</span><span class=n>examples</span><span class=p>):</span>
</span><span id=__span-17-35><a id=__codelineno-17-35 name=__codelineno-17-35></a><a href=#__codelineno-17-35><span class=linenos data-linenos="35 "></span></a>    <span class=n>examples</span><span class=p>[</span><span class=s2>&quot;pixel_values&quot;</span><span class=p>]</span> <span class=o>=</span> <span class=p>[</span>
</span><span id=__span-17-36><a id=__codelineno-17-36 name=__codelineno-17-36></a><a href=#__codelineno-17-36><span class=linenos data-linenos="36 "></span></a>        <span class=n>val_transforms</span><span class=p>(</span><span class=n>image</span><span class=o>=</span><span class=n>np</span><span class=o>.</span><span class=n>array</span><span class=p>(</span><span class=n>image</span><span class=p>))[</span><span class=s2>&quot;image&quot;</span><span class=p>]</span> <span class=k>for</span> <span class=n>image</span> <span class=ow>in</span> <span class=n>examples</span><span class=p>[</span><span class=s2>&quot;image&quot;</span><span class=p>]</span>
</span><span id=__span-17-37><a id=__codelineno-17-37 name=__codelineno-17-37></a><a href=#__codelineno-17-37><span class=linenos data-linenos="37 "></span></a>    <span class=p>]</span>
</span><span id=__span-17-38><a id=__codelineno-17-38 name=__codelineno-17-38></a><a href=#__codelineno-17-38><span class=linenos data-linenos="38 "></span></a>
</span><span id=__span-17-39><a id=__codelineno-17-39 name=__codelineno-17-39></a><a href=#__codelineno-17-39><span class=linenos data-linenos="39 "></span></a>    <span class=k>return</span> <span class=n>examples</span>
</span></code></pre></div> <p>Next, we can preprocess our dataset by applying these functions. We will use the <code>set_transform</code> functionality, which allows to apply the functions above on-the-fly (meaning that they will only be applied when the images are loaded in RAM).</p> <div class="language-python highlight"><span class=filename>Python</span><pre><span></span><code><span id=__span-18-1><a id=__codelineno-18-1 name=__codelineno-18-1></a><a href=#__codelineno-18-1><span class=linenos data-linenos="1 "></span></a><span class=c1># split up training into training + validation</span>
</span><span id=__span-18-2><a id=__codelineno-18-2 name=__codelineno-18-2></a><a href=#__codelineno-18-2><span class=linenos data-linenos="2 "></span></a><span class=n>splits</span> <span class=o>=</span> <span class=n>dataset</span><span class=p>[</span><span class=s2>&quot;train&quot;</span><span class=p>]</span><span class=o>.</span><span class=n>train_test_split</span><span class=p>(</span><span class=n>test_size</span><span class=o>=</span><span class=mf>0.1</span><span class=p>)</span>
</span><span id=__span-18-3><a id=__codelineno-18-3 name=__codelineno-18-3></a><a href=#__codelineno-18-3><span class=linenos data-linenos="3 "></span></a><span class=n>train_ds</span> <span class=o>=</span> <span class=n>splits</span><span class=p>[</span><span class=s1>&#39;train&#39;</span><span class=p>]</span>
</span><span id=__span-18-4><a id=__codelineno-18-4 name=__codelineno-18-4></a><a href=#__codelineno-18-4><span class=linenos data-linenos="4 "></span></a><span class=n>val_ds</span> <span class=o>=</span> <span class=n>splits</span><span class=p>[</span><span class=s1>&#39;test&#39;</span><span class=p>]</span>
</span></code></pre></div> <div class="language-python highlight"><span class=filename>Python</span><pre><span></span><code><span id=__span-19-1><a id=__codelineno-19-1 name=__codelineno-19-1></a><a href=#__codelineno-19-1><span class=linenos data-linenos="1 "></span></a><span class=n>train_ds</span><span class=o>.</span><span class=n>set_transform</span><span class=p>(</span><span class=n>preprocess_train</span><span class=p>)</span>
</span><span id=__span-19-2><a id=__codelineno-19-2 name=__codelineno-19-2></a><a href=#__codelineno-19-2><span class=linenos data-linenos="2 "></span></a><span class=n>val_ds</span><span class=o>.</span><span class=n>set_transform</span><span class=p>(</span><span class=n>preprocess_val</span><span class=p>)</span>
</span></code></pre></div> <p>Let's check the first example:</p> <div class="language-python highlight"><span class=filename>Python</span><pre><span></span><code><span id=__span-20-1><a id=__codelineno-20-1 name=__codelineno-20-1></a><a href=#__codelineno-20-1><span class=linenos data-linenos="1 "></span></a><span class=n>train_ds</span><span class=p>[</span><span class=mi>0</span><span class=p>]</span>
</span></code></pre></div> <div class=codehilite><pre><span></span><code><span class=p>{</span><span class=err>&#39;</span><span class=nx>image</span><span class=err>&#39;</span><span class=p>:</span><span class=w> </span><span class=p>&lt;</span><span class=nx>PIL</span><span class=p>.</span><span class=nx>JpegImagePlugin</span><span class=p>.</span><span class=nx>JpegImageFile</span><span class=w> </span><span class=nx>image</span><span class=w> </span><span class=nx>mode</span><span class=p>=</span><span class=nx>RGB</span><span class=w> </span><span class=nx>size</span><span class=p>=</span><span class=mi>64</span><span class=nx>x64</span><span class=w> </span><span class=nx>at</span><span class=w> </span><span class=mh>0x7FD610178490</span><span class=p>&gt;,</span>
<span class=w> </span><span class=err>&#39;</span><span class=nx>label</span><span class=err>&#39;</span><span class=p>:</span><span class=w> </span><span class=mi>5</span><span class=p>,</span>
<span class=w> </span><span class=err>&#39;</span><span class=nx>pixel_values</span><span class=err>&#39;</span><span class=p>:</span><span class=w> </span><span class=nx>array</span><span class=p>([[[</span><span class=o>-</span><span class="m m-Double">1.415789</span><span class=w>  </span><span class=p>,</span><span class=w> </span><span class=o>-</span><span class="m m-Double">0.53011197</span><span class=p>,</span><span class=w> </span><span class=o>-</span><span class="m m-Double">0.37525052</span><span class=p>],</span>
<span class=w>         </span><span class=p>[</span><span class=o>-</span><span class="m m-Double">1.415789</span><span class=w>  </span><span class=p>,</span><span class=w> </span><span class=o>-</span><span class="m m-Double">0.53011197</span><span class=p>,</span><span class=w> </span><span class=o>-</span><span class="m m-Double">0.37525052</span><span class=p>],</span>
<span class=w>         </span><span class=p>[</span><span class=o>-</span><span class="m m-Double">1.415789</span><span class=w>  </span><span class=p>,</span><span class=w> </span><span class=o>-</span><span class="m m-Double">0.53011197</span><span class=p>,</span><span class=w> </span><span class=o>-</span><span class="m m-Double">0.37525052</span><span class=p>],</span>
<span class=w>         </span><span class=o>...</span><span class=p>,</span>
<span class=w>         </span><span class=p>[</span><span class=o>-</span><span class="m m-Double">1.34729</span><span class=w>   </span><span class=p>,</span><span class=w> </span><span class=o>-</span><span class="m m-Double">0.897759</span><span class=w>  </span><span class=p>,</span><span class=w> </span><span class=o>-</span><span class="m m-Double">0.37525052</span><span class=p>],</span>
<span class=w>         </span><span class=p>[</span><span class=o>-</span><span class="m m-Double">1.34729</span><span class=w>   </span><span class=p>,</span><span class=w> </span><span class=o>-</span><span class="m m-Double">0.897759</span><span class=w>  </span><span class=p>,</span><span class=w> </span><span class=o>-</span><span class="m m-Double">0.37525052</span><span class=p>],</span>
<span class=w>         </span><span class=p>[</span><span class=o>-</span><span class="m m-Double">1.34729</span><span class=w>   </span><span class=p>,</span><span class=w> </span><span class=o>-</span><span class="m m-Double">0.897759</span><span class=w>  </span><span class=p>,</span><span class=w> </span><span class=o>-</span><span class="m m-Double">0.37525052</span><span class=p>]],</span>

<span class=w>        </span><span class=p>[[</span><span class=o>-</span><span class="m m-Double">1.415789</span><span class=w>  </span><span class=p>,</span><span class=w> </span><span class=o>-</span><span class="m m-Double">0.53011197</span><span class=p>,</span><span class=w> </span><span class=o>-</span><span class="m m-Double">0.37525052</span><span class=p>],</span>
<span class=w>         </span><span class=p>[</span><span class=o>-</span><span class="m m-Double">1.415789</span><span class=w>  </span><span class=p>,</span><span class=w> </span><span class=o>-</span><span class="m m-Double">0.53011197</span><span class=p>,</span><span class=w> </span><span class=o>-</span><span class="m m-Double">0.37525052</span><span class=p>],</span>
<span class=w>         </span><span class=p>[</span><span class=o>-</span><span class="m m-Double">1.415789</span><span class=w>  </span><span class=p>,</span><span class=w> </span><span class=o>-</span><span class="m m-Double">0.53011197</span><span class=p>,</span><span class=w> </span><span class=o>-</span><span class="m m-Double">0.37525052</span><span class=p>],</span>
<span class=w>         </span><span class=o>...</span><span class=p>,</span>
<span class=w>         </span><span class=p>[</span><span class=o>-</span><span class="m m-Double">1.34729</span><span class=w>   </span><span class=p>,</span><span class=w> </span><span class=o>-</span><span class="m m-Double">0.897759</span><span class=w>  </span><span class=p>,</span><span class=w> </span><span class=o>-</span><span class="m m-Double">0.37525052</span><span class=p>],</span>
<span class=w>         </span><span class=p>[</span><span class=o>-</span><span class="m m-Double">1.34729</span><span class=w>   </span><span class=p>,</span><span class=w> </span><span class=o>-</span><span class="m m-Double">0.897759</span><span class=w>  </span><span class=p>,</span><span class=w> </span><span class=o>-</span><span class="m m-Double">0.37525052</span><span class=p>],</span>
<span class=w>         </span><span class=p>[</span><span class=o>-</span><span class="m m-Double">1.34729</span><span class=w>   </span><span class=p>,</span><span class=w> </span><span class=o>-</span><span class="m m-Double">0.897759</span><span class=w>  </span><span class=p>,</span><span class=w> </span><span class=o>-</span><span class="m m-Double">0.37525052</span><span class=p>]],</span>

<span class=w>        </span><span class=p>[[</span><span class=o>-</span><span class="m m-Double">1.415789</span><span class=w>  </span><span class=p>,</span><span class=w> </span><span class=o>-</span><span class="m m-Double">0.53011197</span><span class=p>,</span><span class=w> </span><span class=o>-</span><span class="m m-Double">0.37525052</span><span class=p>],</span>
<span class=w>         </span><span class=p>[</span><span class=o>-</span><span class="m m-Double">1.415789</span><span class=w>  </span><span class=p>,</span><span class=w> </span><span class=o>-</span><span class="m m-Double">0.53011197</span><span class=p>,</span><span class=w> </span><span class=o>-</span><span class="m m-Double">0.37525052</span><span class=p>],</span>
<span class=w>         </span><span class=p>[</span><span class=o>-</span><span class="m m-Double">1.415789</span><span class=w>  </span><span class=p>,</span><span class=w> </span><span class=o>-</span><span class="m m-Double">0.53011197</span><span class=p>,</span><span class=w> </span><span class=o>-</span><span class="m m-Double">0.37525052</span><span class=p>],</span>
<span class=w>         </span><span class=o>...</span><span class=p>,</span>
<span class=w>         </span><span class=p>[</span><span class=o>-</span><span class="m m-Double">1.3986642</span><span class=w> </span><span class=p>,</span><span class=w> </span><span class=o>-</span><span class="m m-Double">0.93277305</span><span class=p>,</span><span class=w> </span><span class=o>-</span><span class="m m-Double">0.4101089</span><span class=w> </span><span class=p>],</span>
<span class=w>         </span><span class=p>[</span><span class=o>-</span><span class="m m-Double">1.3986642</span><span class=w> </span><span class=p>,</span><span class=w> </span><span class=o>-</span><span class="m m-Double">0.93277305</span><span class=p>,</span><span class=w> </span><span class=o>-</span><span class="m m-Double">0.4101089</span><span class=w> </span><span class=p>],</span>
<span class=w>         </span><span class=p>[</span><span class=o>-</span><span class="m m-Double">1.3986642</span><span class=w> </span><span class=p>,</span><span class=w> </span><span class=o>-</span><span class="m m-Double">0.93277305</span><span class=p>,</span><span class=w> </span><span class=o>-</span><span class="m m-Double">0.4101089</span><span class=w> </span><span class=p>]],</span>

<span class=w>        </span><span class=o>...</span><span class=p>,</span>

<span class=w>        </span><span class=p>[[</span><span class=o>-</span><span class="m m-Double">1.5014129</span><span class=w> </span><span class=p>,</span><span class=w> </span><span class=o>-</span><span class="m m-Double">0.582633</span><span class=w>  </span><span class=p>,</span><span class=w> </span><span class=o>-</span><span class="m m-Double">0.35782132</span><span class=p>],</span>
<span class=w>         </span><span class=p>[</span><span class=o>-</span><span class="m m-Double">1.5014129</span><span class=w> </span><span class=p>,</span><span class=w> </span><span class=o>-</span><span class="m m-Double">0.582633</span><span class=w>  </span><span class=p>,</span><span class=w> </span><span class=o>-</span><span class="m m-Double">0.35782132</span><span class=p>],</span>
<span class=w>         </span><span class=p>[</span><span class=o>-</span><span class="m m-Double">1.5014129</span><span class=w> </span><span class=p>,</span><span class=w> </span><span class=o>-</span><span class="m m-Double">0.582633</span><span class=w>  </span><span class=p>,</span><span class=w> </span><span class=o>-</span><span class="m m-Double">0.35782132</span><span class=p>],</span>
<span class=w>         </span><span class=o>...</span><span class=p>,</span>
<span class=w>         </span><span class=p>[</span><span class=o>-</span><span class="m m-Double">1.4842881</span><span class=w> </span><span class=p>,</span><span class=w> </span><span class=o>-</span><span class="m m-Double">0.98529404</span><span class=p>,</span><span class=w> </span><span class=o>-</span><span class="m m-Double">0.5146841</span><span class=w> </span><span class=p>],</span>
<span class=w>         </span><span class=p>[</span><span class=o>-</span><span class="m m-Double">1.4671633</span><span class=w> </span><span class=p>,</span><span class=w> </span><span class=o>-</span><span class="m m-Double">1.0028011</span><span class=w> </span><span class=p>,</span><span class=w> </span><span class=o>-</span><span class="m m-Double">0.49725488</span><span class=p>],</span>
<span class=w>         </span><span class=p>[</span><span class=o>-</span><span class="m m-Double">1.4671633</span><span class=w> </span><span class=p>,</span><span class=w> </span><span class=o>-</span><span class="m m-Double">1.0028011</span><span class=w> </span><span class=p>,</span><span class=w> </span><span class=o>-</span><span class="m m-Double">0.49725488</span><span class=p>]],</span>

<span class=w>        </span><span class=p>[[</span><span class=o>-</span><span class="m m-Double">1.5356623</span><span class=w> </span><span class=p>,</span><span class=w> </span><span class=o>-</span><span class="m m-Double">0.565126</span><span class=w>  </span><span class=p>,</span><span class=w> </span><span class=o>-</span><span class="m m-Double">0.3403921</span><span class=w> </span><span class=p>],</span>
<span class=w>         </span><span class=p>[</span><span class=o>-</span><span class="m m-Double">1.5356623</span><span class=w> </span><span class=p>,</span><span class=w> </span><span class=o>-</span><span class="m m-Double">0.565126</span><span class=w>  </span><span class=p>,</span><span class=w> </span><span class=o>-</span><span class="m m-Double">0.3403921</span><span class=w> </span><span class=p>],</span>
<span class=w>         </span><span class=p>[</span><span class=o>-</span><span class="m m-Double">1.5356623</span><span class=w> </span><span class=p>,</span><span class=w> </span><span class=o>-</span><span class="m m-Double">0.565126</span><span class=w>  </span><span class=p>,</span><span class=w> </span><span class=o>-</span><span class="m m-Double">0.35782132</span><span class=p>],</span>
<span class=w>         </span><span class=o>...</span><span class=p>,</span>
<span class=w>         </span><span class=p>[</span><span class=o>-</span><span class="m m-Double">1.4842881</span><span class=w> </span><span class=p>,</span><span class=w> </span><span class=o>-</span><span class="m m-Double">0.98529404</span><span class=p>,</span><span class=w> </span><span class=o>-</span><span class="m m-Double">0.5146841</span><span class=w> </span><span class=p>],</span>
<span class=w>         </span><span class=p>[</span><span class=o>-</span><span class="m m-Double">1.4671633</span><span class=w> </span><span class=p>,</span><span class=w> </span><span class=o>-</span><span class="m m-Double">1.0028011</span><span class=w> </span><span class=p>,</span><span class=w> </span><span class=o>-</span><span class="m m-Double">0.49725488</span><span class=p>],</span>
<span class=w>         </span><span class=p>[</span><span class=o>-</span><span class="m m-Double">1.4671633</span><span class=w> </span><span class=p>,</span><span class=w> </span><span class=o>-</span><span class="m m-Double">1.0028011</span><span class=w> </span><span class=p>,</span><span class=w> </span><span class=o>-</span><span class="m m-Double">0.49725488</span><span class=p>]],</span>

<span class=w>        </span><span class=p>[[</span><span class=o>-</span><span class="m m-Double">1.5356623</span><span class=w> </span><span class=p>,</span><span class=w> </span><span class=o>-</span><span class="m m-Double">0.565126</span><span class=w>  </span><span class=p>,</span><span class=w> </span><span class=o>-</span><span class="m m-Double">0.3403921</span><span class=w> </span><span class=p>],</span>
<span class=w>         </span><span class=p>[</span><span class=o>-</span><span class="m m-Double">1.5356623</span><span class=w> </span><span class=p>,</span><span class=w> </span><span class=o>-</span><span class="m m-Double">0.565126</span><span class=w>  </span><span class=p>,</span><span class=w> </span><span class=o>-</span><span class="m m-Double">0.3403921</span><span class=w> </span><span class=p>],</span>
<span class=w>         </span><span class=p>[</span><span class=o>-</span><span class="m m-Double">1.5356623</span><span class=w> </span><span class=p>,</span><span class=w> </span><span class=o>-</span><span class="m m-Double">0.565126</span><span class=w>  </span><span class=p>,</span><span class=w> </span><span class=o>-</span><span class="m m-Double">0.35782132</span><span class=p>],</span>
<span class=w>         </span><span class=o>...</span><span class=p>,</span>
<span class=w>         </span><span class=p>[</span><span class=o>-</span><span class="m m-Double">1.4842881</span><span class=w> </span><span class=p>,</span><span class=w> </span><span class=o>-</span><span class="m m-Double">0.98529404</span><span class=p>,</span><span class=w> </span><span class=o>-</span><span class="m m-Double">0.5146841</span><span class=w> </span><span class=p>],</span>
<span class=w>         </span><span class=p>[</span><span class=o>-</span><span class="m m-Double">1.4671633</span><span class=w> </span><span class=p>,</span><span class=w> </span><span class=o>-</span><span class="m m-Double">1.0028011</span><span class=w> </span><span class=p>,</span><span class=w> </span><span class=o>-</span><span class="m m-Double">0.49725488</span><span class=p>],</span>
<span class=w>         </span><span class=p>[</span><span class=o>-</span><span class="m m-Double">1.4671633</span><span class=w> </span><span class=p>,</span><span class=w> </span><span class=o>-</span><span class="m m-Double">1.0028011</span><span class=w> </span><span class=p>,</span><span class=w> </span><span class=o>-</span><span class="m m-Double">0.49725488</span><span class=p>]]],</span><span class=w> </span><span class=nx>dtype</span><span class=p>=</span><span class=nx>float32</span><span class=p>)}</span>
</code></pre></div> <h3 id=training-the-model>Training the model<a class=headerlink href=#training-the-model title="Permanent link">&para;</a></h3> <p>Now that our data is ready, we can download the pretrained model and fine-tune it. For classification we use the <code>AutoModelForImageClassification</code> class. Like with the image processor, the <code>from_pretrained</code> method will download and cache the model for us. As the label ids and the number of labels are dataset dependent, we pass <code>num_labels</code>, <code>label2id</code>, and <code>id2label</code> alongside the <code>model_checkpoint</code> he£re.</p> <p>NOTE: in case you're planning to fine-tune an already fine-tuned checkpoint, like <a href=https://huggingface.co/facebook/convnext-tiny-224>facebook/convnext-tiny-224</a> (which has already been fine-tuned on ImageNet-1k), then you need to provide the additional argument <code>ignore_mismatched_sizes=True</code> to the <code>from_pretrained</code> method. This will make sure the output head is thrown away and replaced by a new, randomly initialized classification head that includes a custom number of output neurons.</p> <div class="language-python highlight"><span class=filename>Python</span><pre><span></span><code><span id=__span-21-1><a id=__codelineno-21-1 name=__codelineno-21-1></a><a href=#__codelineno-21-1><span class=linenos data-linenos="1 "></span></a><span class=kn>from</span><span class=w> </span><span class=nn>transformers</span><span class=w> </span><span class=kn>import</span> <span class=n>AutoModelForImageClassification</span><span class=p>,</span> <span class=n>TrainingArguments</span><span class=p>,</span> <span class=n>Trainer</span>
</span><span id=__span-21-2><a id=__codelineno-21-2 name=__codelineno-21-2></a><a href=#__codelineno-21-2><span class=linenos data-linenos="2 "></span></a>
</span><span id=__span-21-3><a id=__codelineno-21-3 name=__codelineno-21-3></a><a href=#__codelineno-21-3><span class=linenos data-linenos="3 "></span></a><span class=n>num_labels</span> <span class=o>=</span> <span class=nb>len</span><span class=p>(</span><span class=n>id2label</span><span class=p>)</span>
</span><span id=__span-21-4><a id=__codelineno-21-4 name=__codelineno-21-4></a><a href=#__codelineno-21-4><span class=linenos data-linenos="4 "></span></a><span class=n>model</span> <span class=o>=</span> <span class=n>AutoModelForImageClassification</span><span class=o>.</span><span class=n>from_pretrained</span><span class=p>(</span>
</span><span id=__span-21-5><a id=__codelineno-21-5 name=__codelineno-21-5></a><a href=#__codelineno-21-5><span class=linenos data-linenos="5 "></span></a>    <span class=n>model_checkpoint</span><span class=p>,</span> 
</span><span id=__span-21-6><a id=__codelineno-21-6 name=__codelineno-21-6></a><a href=#__codelineno-21-6><span class=linenos data-linenos="6 "></span></a>    <span class=n>label2id</span><span class=o>=</span><span class=n>label2id</span><span class=p>,</span>
</span><span id=__span-21-7><a id=__codelineno-21-7 name=__codelineno-21-7></a><a href=#__codelineno-21-7><span class=linenos data-linenos="7 "></span></a>    <span class=n>id2label</span><span class=o>=</span><span class=n>id2label</span><span class=p>,</span>
</span><span id=__span-21-8><a id=__codelineno-21-8 name=__codelineno-21-8></a><a href=#__codelineno-21-8><span class=linenos data-linenos="8 "></span></a>    <span class=n>ignore_mismatched_sizes</span> <span class=o>=</span> <span class=kc>True</span><span class=p>,</span> <span class=c1># provide this in case you&#39;d like to fine-tune an already fine-tuned checkpoint</span>
</span><span id=__span-21-9><a id=__codelineno-21-9 name=__codelineno-21-9></a><a href=#__codelineno-21-9><span class=linenos data-linenos="9 "></span></a><span class=p>)</span>
</span></code></pre></div> <div class=codehilite><pre><span></span><code><span class=n>Downloading</span><span class=p>:</span><span class=w>   </span><span class=mi>0</span><span class=o>%|</span><span class=w>          </span><span class=o>|</span><span class=w> </span><span class=mf>0.00</span><span class=o>/</span><span class=mf>68.0</span><span class=n>k</span><span class=w> </span><span class=p>[</span><span class=mi>00</span><span class=p>:</span><span class=mi>00</span><span class=o>&lt;</span><span class=err>?</span><span class=p>,</span><span class=w> </span><span class=err>?</span><span class=n>B</span><span class=o>/</span><span class=n>s</span><span class=p>]</span>



<span class=n>Downloading</span><span class=p>:</span><span class=w>   </span><span class=mi>0</span><span class=o>%|</span><span class=w>          </span><span class=o>|</span><span class=w> </span><span class=mf>0.00</span><span class=o>/</span><span class=mi>109</span><span class=n>M</span><span class=w> </span><span class=p>[</span><span class=mi>00</span><span class=p>:</span><span class=mi>00</span><span class=o>&lt;</span><span class=err>?</span><span class=p>,</span><span class=w> </span><span class=err>?</span><span class=n>B</span><span class=o>/</span><span class=n>s</span><span class=p>]</span>


<span class=n>Some</span><span class=w> </span><span class=n>weights</span><span class=w> </span><span class=n>of</span><span class=w> </span><span class=n>ConvNextForImageClassification</span><span class=w> </span><span class=n>were</span><span class=w> </span><span class=ow>not</span><span class=w> </span><span class=n>initialized</span><span class=w> </span><span class=n>from</span><span class=w> </span><span class=n>the</span><span class=w> </span><span class=n>model</span><span class=w> </span><span class=n>checkpoint</span><span class=w> </span><span class=n>at</span><span class=w> </span><span class=n>facebook</span><span class=o>/</span><span class=n>convnext</span><span class=o>-</span><span class=n>tiny</span><span class=o>-</span><span class=mi>224</span><span class=w> </span><span class=ow>and</span><span class=w> </span><span class=n>are</span><span class=w> </span><span class=n>newly</span><span class=w> </span><span class=n>initialized</span><span class=w> </span><span class=n>because</span><span class=w> </span><span class=n>the</span><span class=w> </span><span class=n>shapes</span><span class=w> </span><span class=n>did</span><span class=w> </span><span class=ow>not</span><span class=w> </span><span class=k>match</span><span class=p>:</span>
<span class=o>-</span><span class=w> </span><span class=n>classifier</span><span class=o>.</span><span class=n>weight</span><span class=p>:</span><span class=w> </span><span class=n>found</span><span class=w> </span><span class=n>shape</span><span class=w> </span><span class=n>torch</span><span class=o>.</span><span class=n>Size</span><span class=p>([</span><span class=mi>1000</span><span class=p>,</span><span class=w> </span><span class=mi>768</span><span class=p>])</span><span class=w> </span><span class=ow>in</span><span class=w> </span><span class=n>the</span><span class=w> </span><span class=n>checkpoint</span><span class=w> </span><span class=ow>and</span><span class=w> </span><span class=n>torch</span><span class=o>.</span><span class=n>Size</span><span class=p>([</span><span class=mi>10</span><span class=p>,</span><span class=w> </span><span class=mi>768</span><span class=p>])</span><span class=w> </span><span class=ow>in</span><span class=w> </span><span class=n>the</span><span class=w> </span><span class=n>model</span><span class=w> </span><span class=n>instantiated</span>
<span class=o>-</span><span class=w> </span><span class=n>classifier</span><span class=o>.</span><span class=n>bias</span><span class=p>:</span><span class=w> </span><span class=n>found</span><span class=w> </span><span class=n>shape</span><span class=w> </span><span class=n>torch</span><span class=o>.</span><span class=n>Size</span><span class=p>([</span><span class=mi>1000</span><span class=p>])</span><span class=w> </span><span class=ow>in</span><span class=w> </span><span class=n>the</span><span class=w> </span><span class=n>checkpoint</span><span class=w> </span><span class=ow>and</span><span class=w> </span><span class=n>torch</span><span class=o>.</span><span class=n>Size</span><span class=p>([</span><span class=mi>10</span><span class=p>])</span><span class=w> </span><span class=ow>in</span><span class=w> </span><span class=n>the</span><span class=w> </span><span class=n>model</span><span class=w> </span><span class=n>instantiated</span>
<span class=n>You</span><span class=w> </span><span class=n>should</span><span class=w> </span><span class=n>probably</span><span class=w> </span><span class=n>TRAIN</span><span class=w> </span><span class=n>this</span><span class=w> </span><span class=n>model</span><span class=w> </span><span class=n>on</span><span class=w> </span><span class=n>a</span><span class=w> </span><span class=n>down</span><span class=o>-</span><span class=n>stream</span><span class=w> </span><span class=n>task</span><span class=w> </span><span class=n>to</span><span class=w> </span><span class=n>be</span><span class=w> </span><span class=n>able</span><span class=w> </span><span class=n>to</span><span class=w> </span><span class=n>use</span><span class=w> </span><span class=n>it</span><span class=w> </span><span class=k>for</span><span class=w> </span><span class=n>predictions</span><span class=w> </span><span class=ow>and</span><span class=w> </span><span class=n>inference</span><span class=o>.</span>
</code></pre></div> <p>The warning is telling us we are throwing away some weights (the weights and bias of the <code>pooler</code> layer) and randomly initializing some other (the weights and bias of the <code>classifier</code> layer). This is expected in this case, because we are adding a new head for which we don't have pretrained weights, so the library warns us we should fine-tune this model before using it for inference, which is exactly what we are going to do.</p> <p>To instantiate a <code>Trainer</code>, we will need to define the training configuration and the evaluation metric. The most important is the <a href=https://huggingface.co/transformers/main_classes/trainer.html#transformers.TrainingArguments><code>TrainingArguments</code></a>, which is a class that contains all the attributes to customize the training. It requires one folder name, which will be used to save the checkpoints of the model.</p> <p>Most of the training arguments are pretty self-explanatory, but one that is quite important here is <code>remove_unused_columns=False</code>. This one will drop any features not used by the model's call function. By default it's <code>True</code> because usually it's ideal to drop unused feature columns, making it easier to unpack inputs into the model's call function. But, in our case, we need the unused features ('img' in particular) in order to create 'pixel_values'.</p> <div class="language-python highlight"><span class=filename>Python</span><pre><span></span><code><span id=__span-22-1><a id=__codelineno-22-1 name=__codelineno-22-1></a><a href=#__codelineno-22-1><span class=linenos data-linenos=" 1 "></span></a><span class=n>model_name</span> <span class=o>=</span> <span class=n>model_checkpoint</span><span class=o>.</span><span class=n>split</span><span class=p>(</span><span class=s2>&quot;/&quot;</span><span class=p>)[</span><span class=o>-</span><span class=mi>1</span><span class=p>]</span>
</span><span id=__span-22-2><a id=__codelineno-22-2 name=__codelineno-22-2></a><a href=#__codelineno-22-2><span class=linenos data-linenos=" 2 "></span></a>
</span><span id=__span-22-3><a id=__codelineno-22-3 name=__codelineno-22-3></a><a href=#__codelineno-22-3><span class=linenos data-linenos=" 3 "></span></a><span class=n>args</span> <span class=o>=</span> <span class=n>TrainingArguments</span><span class=p>(</span>
</span><span id=__span-22-4><a id=__codelineno-22-4 name=__codelineno-22-4></a><a href=#__codelineno-22-4><span class=linenos data-linenos=" 4 "></span></a>    <span class=sa>f</span><span class=s2>&quot;</span><span class=si>{</span><span class=n>model_name</span><span class=si>}</span><span class=s2>-finetuned-eurosat-albumentations&quot;</span><span class=p>,</span>
</span><span id=__span-22-5><a id=__codelineno-22-5 name=__codelineno-22-5></a><a href=#__codelineno-22-5><span class=linenos data-linenos=" 5 "></span></a>    <span class=n>remove_unused_columns</span><span class=o>=</span><span class=kc>False</span><span class=p>,</span>
</span><span id=__span-22-6><a id=__codelineno-22-6 name=__codelineno-22-6></a><a href=#__codelineno-22-6><span class=linenos data-linenos=" 6 "></span></a>    <span class=n>evaluation_strategy</span> <span class=o>=</span> <span class=s2>&quot;epoch&quot;</span><span class=p>,</span>
</span><span id=__span-22-7><a id=__codelineno-22-7 name=__codelineno-22-7></a><a href=#__codelineno-22-7><span class=linenos data-linenos=" 7 "></span></a>    <span class=n>save_strategy</span> <span class=o>=</span> <span class=s2>&quot;epoch&quot;</span><span class=p>,</span>
</span><span id=__span-22-8><a id=__codelineno-22-8 name=__codelineno-22-8></a><a href=#__codelineno-22-8><span class=linenos data-linenos=" 8 "></span></a>    <span class=n>learning_rate</span><span class=o>=</span><span class=mf>5e-5</span><span class=p>,</span>
</span><span id=__span-22-9><a id=__codelineno-22-9 name=__codelineno-22-9></a><a href=#__codelineno-22-9><span class=linenos data-linenos=" 9 "></span></a>    <span class=n>per_device_train_batch_size</span><span class=o>=</span><span class=n>batch_size</span><span class=p>,</span>
</span><span id=__span-22-10><a id=__codelineno-22-10 name=__codelineno-22-10></a><a href=#__codelineno-22-10><span class=linenos data-linenos="10 "></span></a>    <span class=n>gradient_accumulation_steps</span><span class=o>=</span><span class=mi>4</span><span class=p>,</span>
</span><span id=__span-22-11><a id=__codelineno-22-11 name=__codelineno-22-11></a><a href=#__codelineno-22-11><span class=linenos data-linenos="11 "></span></a>    <span class=n>per_device_eval_batch_size</span><span class=o>=</span><span class=n>batch_size</span><span class=p>,</span>
</span><span id=__span-22-12><a id=__codelineno-22-12 name=__codelineno-22-12></a><a href=#__codelineno-22-12><span class=linenos data-linenos="12 "></span></a>    <span class=n>num_train_epochs</span><span class=o>=</span><span class=mi>3</span><span class=p>,</span>
</span><span id=__span-22-13><a id=__codelineno-22-13 name=__codelineno-22-13></a><a href=#__codelineno-22-13><span class=linenos data-linenos="13 "></span></a>    <span class=n>warmup_ratio</span><span class=o>=</span><span class=mf>0.1</span><span class=p>,</span>
</span><span id=__span-22-14><a id=__codelineno-22-14 name=__codelineno-22-14></a><a href=#__codelineno-22-14><span class=linenos data-linenos="14 "></span></a>    <span class=n>logging_steps</span><span class=o>=</span><span class=mi>10</span><span class=p>,</span>
</span><span id=__span-22-15><a id=__codelineno-22-15 name=__codelineno-22-15></a><a href=#__codelineno-22-15><span class=linenos data-linenos="15 "></span></a>    <span class=n>load_best_model_at_end</span><span class=o>=</span><span class=kc>True</span><span class=p>,</span>
</span><span id=__span-22-16><a id=__codelineno-22-16 name=__codelineno-22-16></a><a href=#__codelineno-22-16><span class=linenos data-linenos="16 "></span></a>    <span class=n>metric_for_best_model</span><span class=o>=</span><span class=s2>&quot;accuracy&quot;</span><span class=p>,</span>
</span><span id=__span-22-17><a id=__codelineno-22-17 name=__codelineno-22-17></a><a href=#__codelineno-22-17><span class=linenos data-linenos="17 "></span></a>    <span class=n>push_to_hub</span><span class=o>=</span><span class=kc>True</span><span class=p>,</span>
</span><span id=__span-22-18><a id=__codelineno-22-18 name=__codelineno-22-18></a><a href=#__codelineno-22-18><span class=linenos data-linenos="18 "></span></a><span class=p>)</span>
</span></code></pre></div> <p>Here we set the evaluation to be done at the end of each epoch, tweak the learning rate, use the <code>batch_size</code> defined at the top of the notebook and customize the number of epochs for training, as well as the weight decay. Since the best model might not be the one at the end of training, we ask the <code>Trainer</code> to load the best model it saved (according to <code>metric_name</code>) at the end of training.</p> <p>The last argument <code>push_to_hub</code> allows the Trainer to push the model to the <a href=https://huggingface.co/models>Hub</a> regularly during training. Remove it if you didn't follow the installation steps at the top of the notebook. If you want to save your model locally with a name that is different from the name of the repository, or if you want to push your model under an organization and not your name space, use the <code>hub_model_id</code> argument to set the repo name (it needs to be the full name, including your namespace: for instance <code>"nielsr/vit-finetuned-cifar10"</code> or <code>"huggingface/nielsr/vit-finetuned-cifar10"</code>).</p> <p>Next, we need to define a function for how to compute the metrics from the predictions, which will just use the <code>metric</code> we loaded earlier. The only preprocessing we have to do is to take the argmax of our predicted logits:</p> <div class="language-python highlight"><span class=filename>Python</span><pre><span></span><code><span id=__span-23-1><a id=__codelineno-23-1 name=__codelineno-23-1></a><a href=#__codelineno-23-1><span class=linenos data-linenos="1 "></span></a><span class=kn>import</span><span class=w> </span><span class=nn>numpy</span><span class=w> </span><span class=k>as</span><span class=w> </span><span class=nn>np</span>
</span><span id=__span-23-2><a id=__codelineno-23-2 name=__codelineno-23-2></a><a href=#__codelineno-23-2><span class=linenos data-linenos="2 "></span></a>
</span><span id=__span-23-3><a id=__codelineno-23-3 name=__codelineno-23-3></a><a href=#__codelineno-23-3><span class=linenos data-linenos="3 "></span></a><span class=c1># the compute_metrics function takes a Named Tuple as input:</span>
</span><span id=__span-23-4><a id=__codelineno-23-4 name=__codelineno-23-4></a><a href=#__codelineno-23-4><span class=linenos data-linenos="4 "></span></a><span class=c1># predictions, which are the logits of the model as Numpy arrays,</span>
</span><span id=__span-23-5><a id=__codelineno-23-5 name=__codelineno-23-5></a><a href=#__codelineno-23-5><span class=linenos data-linenos="5 "></span></a><span class=c1># and label_ids, which are the ground-truth labels as Numpy arrays.</span>
</span><span id=__span-23-6><a id=__codelineno-23-6 name=__codelineno-23-6></a><a href=#__codelineno-23-6><span class=linenos data-linenos="6 "></span></a><span class=k>def</span><span class=w> </span><span class=nf>compute_metrics</span><span class=p>(</span><span class=n>eval_pred</span><span class=p>):</span>
</span><span id=__span-23-7><a id=__codelineno-23-7 name=__codelineno-23-7></a><a href=#__codelineno-23-7><span class=linenos data-linenos="7 "></span></a><span class=w>    </span><span class=sd>&quot;&quot;&quot;Computes accuracy on a batch of predictions&quot;&quot;&quot;</span>
</span><span id=__span-23-8><a id=__codelineno-23-8 name=__codelineno-23-8></a><a href=#__codelineno-23-8><span class=linenos data-linenos="8 "></span></a>    <span class=n>predictions</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>argmax</span><span class=p>(</span><span class=n>eval_pred</span><span class=o>.</span><span class=n>predictions</span><span class=p>,</span> <span class=n>axis</span><span class=o>=</span><span class=mi>1</span><span class=p>)</span>
</span><span id=__span-23-9><a id=__codelineno-23-9 name=__codelineno-23-9></a><a href=#__codelineno-23-9><span class=linenos data-linenos="9 "></span></a>    <span class=k>return</span> <span class=n>metric</span><span class=o>.</span><span class=n>compute</span><span class=p>(</span><span class=n>predictions</span><span class=o>=</span><span class=n>predictions</span><span class=p>,</span> <span class=n>references</span><span class=o>=</span><span class=n>eval_pred</span><span class=o>.</span><span class=n>label_ids</span><span class=p>)</span>
</span></code></pre></div> <p>We also define a <code>collate_fn</code>, which will be used to batch examples together. Each batch consists of 2 keys, namely <code>pixel_values</code> and <code>labels</code>.</p> <div class="language-python highlight"><span class=filename>Python</span><pre><span></span><code><span id=__span-24-1><a id=__codelineno-24-1 name=__codelineno-24-1></a><a href=#__codelineno-24-1><span class=linenos data-linenos=" 1 "></span></a><span class=kn>import</span><span class=w> </span><span class=nn>torch</span>
</span><span id=__span-24-2><a id=__codelineno-24-2 name=__codelineno-24-2></a><a href=#__codelineno-24-2><span class=linenos data-linenos=" 2 "></span></a>
</span><span id=__span-24-3><a id=__codelineno-24-3 name=__codelineno-24-3></a><a href=#__codelineno-24-3><span class=linenos data-linenos=" 3 "></span></a><span class=k>def</span><span class=w> </span><span class=nf>collate_fn</span><span class=p>(</span><span class=n>examples</span><span class=p>):</span>
</span><span id=__span-24-4><a id=__codelineno-24-4 name=__codelineno-24-4></a><a href=#__codelineno-24-4><span class=linenos data-linenos=" 4 "></span></a>    <span class=n>images</span> <span class=o>=</span> <span class=p>[]</span>
</span><span id=__span-24-5><a id=__codelineno-24-5 name=__codelineno-24-5></a><a href=#__codelineno-24-5><span class=linenos data-linenos=" 5 "></span></a>    <span class=n>labels</span> <span class=o>=</span> <span class=p>[]</span>
</span><span id=__span-24-6><a id=__codelineno-24-6 name=__codelineno-24-6></a><a href=#__codelineno-24-6><span class=linenos data-linenos=" 6 "></span></a>    <span class=k>for</span> <span class=n>example</span> <span class=ow>in</span> <span class=n>examples</span><span class=p>:</span>
</span><span id=__span-24-7><a id=__codelineno-24-7 name=__codelineno-24-7></a><a href=#__codelineno-24-7><span class=linenos data-linenos=" 7 "></span></a>        <span class=n>image</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>moveaxis</span><span class=p>(</span><span class=n>example</span><span class=p>[</span><span class=s2>&quot;pixel_values&quot;</span><span class=p>],</span> <span class=n>source</span><span class=o>=</span><span class=mi>2</span><span class=p>,</span> <span class=n>destination</span><span class=o>=</span><span class=mi>0</span><span class=p>)</span>
</span><span id=__span-24-8><a id=__codelineno-24-8 name=__codelineno-24-8></a><a href=#__codelineno-24-8><span class=linenos data-linenos=" 8 "></span></a>        <span class=n>images</span><span class=o>.</span><span class=n>append</span><span class=p>(</span><span class=n>torch</span><span class=o>.</span><span class=n>from_numpy</span><span class=p>(</span><span class=n>image</span><span class=p>))</span>
</span><span id=__span-24-9><a id=__codelineno-24-9 name=__codelineno-24-9></a><a href=#__codelineno-24-9><span class=linenos data-linenos=" 9 "></span></a>        <span class=n>labels</span><span class=o>.</span><span class=n>append</span><span class=p>(</span><span class=n>example</span><span class=p>[</span><span class=s2>&quot;label&quot;</span><span class=p>])</span>
</span><span id=__span-24-10><a id=__codelineno-24-10 name=__codelineno-24-10></a><a href=#__codelineno-24-10><span class=linenos data-linenos="10 "></span></a>
</span><span id=__span-24-11><a id=__codelineno-24-11 name=__codelineno-24-11></a><a href=#__codelineno-24-11><span class=linenos data-linenos="11 "></span></a>    <span class=n>pixel_values</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>stack</span><span class=p>(</span><span class=n>images</span><span class=p>)</span>
</span><span id=__span-24-12><a id=__codelineno-24-12 name=__codelineno-24-12></a><a href=#__codelineno-24-12><span class=linenos data-linenos="12 "></span></a>    <span class=n>labels</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>tensor</span><span class=p>(</span><span class=n>labels</span><span class=p>)</span>
</span><span id=__span-24-13><a id=__codelineno-24-13 name=__codelineno-24-13></a><a href=#__codelineno-24-13><span class=linenos data-linenos="13 "></span></a>    <span class=k>return</span> <span class=p>{</span><span class=s2>&quot;pixel_values&quot;</span><span class=p>:</span> <span class=n>pixel_values</span><span class=p>,</span> <span class=s2>&quot;labels&quot;</span><span class=p>:</span> <span class=n>labels</span><span class=p>}</span>
</span></code></pre></div> <p>Then we just need to pass all of this along with our datasets to the <code>Trainer</code>:</p> <div class="language-python highlight"><span class=filename>Python</span><pre><span></span><code><span id=__span-25-1><a id=__codelineno-25-1 name=__codelineno-25-1></a><a href=#__codelineno-25-1><span class=linenos data-linenos="1 "></span></a><span class=n>trainer</span> <span class=o>=</span> <span class=n>Trainer</span><span class=p>(</span>
</span><span id=__span-25-2><a id=__codelineno-25-2 name=__codelineno-25-2></a><a href=#__codelineno-25-2><span class=linenos data-linenos="2 "></span></a>    <span class=n>model</span><span class=p>,</span>
</span><span id=__span-25-3><a id=__codelineno-25-3 name=__codelineno-25-3></a><a href=#__codelineno-25-3><span class=linenos data-linenos="3 "></span></a>    <span class=n>args</span><span class=p>,</span>
</span><span id=__span-25-4><a id=__codelineno-25-4 name=__codelineno-25-4></a><a href=#__codelineno-25-4><span class=linenos data-linenos="4 "></span></a>    <span class=n>train_dataset</span><span class=o>=</span><span class=n>train_ds</span><span class=p>,</span>
</span><span id=__span-25-5><a id=__codelineno-25-5 name=__codelineno-25-5></a><a href=#__codelineno-25-5><span class=linenos data-linenos="5 "></span></a>    <span class=n>eval_dataset</span><span class=o>=</span><span class=n>val_ds</span><span class=p>,</span>
</span><span id=__span-25-6><a id=__codelineno-25-6 name=__codelineno-25-6></a><a href=#__codelineno-25-6><span class=linenos data-linenos="6 "></span></a>    <span class=n>tokenizer</span><span class=o>=</span><span class=n>image_processor</span><span class=p>,</span>
</span><span id=__span-25-7><a id=__codelineno-25-7 name=__codelineno-25-7></a><a href=#__codelineno-25-7><span class=linenos data-linenos="7 "></span></a>    <span class=n>compute_metrics</span><span class=o>=</span><span class=n>compute_metrics</span><span class=p>,</span>
</span><span id=__span-25-8><a id=__codelineno-25-8 name=__codelineno-25-8></a><a href=#__codelineno-25-8><span class=linenos data-linenos="8 "></span></a>    <span class=n>data_collator</span><span class=o>=</span><span class=n>collate_fn</span><span class=p>,</span>
</span><span id=__span-25-9><a id=__codelineno-25-9 name=__codelineno-25-9></a><a href=#__codelineno-25-9><span class=linenos data-linenos="9 "></span></a><span class=p>)</span>
</span></code></pre></div> <div class=codehilite><pre><span></span><code>/content/convnext-tiny-224-finetuned-eurosat-albumentations is already a clone of https://huggingface.co/nielsr/convnext-tiny-224-finetuned-eurosat-albumentations. Make sure you pull the latest changes with <span class=sb>`repo.git_pull()`</span>.
</code></pre></div> <p>You might wonder why we pass along the <code>image_processor</code> as a tokenizer when we already preprocessed our data. This is only to make sure the image processor configuration file (stored as JSON) will also be uploaded to the repo on the hub.</p> <p>Now we can finetune our model by calling the <code>train</code> method:</p> <div class="language-python highlight"><span class=filename>Python</span><pre><span></span><code><span id=__span-26-1><a id=__codelineno-26-1 name=__codelineno-26-1></a><a href=#__codelineno-26-1><span class=linenos data-linenos="1 "></span></a><span class=n>trainer</span><span class=o>.</span><span class=n>train</span><span class=p>()</span>
</span></code></pre></div> <div class=codehilite><pre><span></span><code>/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309:<span class=w> </span>FutureWarning:<span class=w> </span>This<span class=w> </span>implementation<span class=w> </span>of<span class=w> </span>AdamW<span class=w> </span>is<span class=w> </span>deprecated<span class=w> </span>and<span class=w> </span>will<span class=w> </span>be<span class=w> </span>removed<span class=w> </span>in<span class=w> </span>a<span class=w> </span>future<span class=w> </span>version.<span class=w> </span>Use<span class=w> </span>the<span class=w> </span>PyTorch<span class=w> </span>implementation<span class=w> </span>torch.optim.AdamW<span class=w> </span>instead,<span class=w> </span>or<span class=w> </span>set<span class=w> </span>`no_deprecation_warning=True`<span class=w> </span>to<span class=w> </span>disable<span class=w> </span>this<span class=w> </span>warning
<span class=w>  </span>FutureWarning,
*****<span class=w> </span>Running<span class=w> </span>training<span class=w> </span>*****
<span class=w>  </span>Num<span class=w> </span>examples<span class=w> </span>=<span class=w> </span>24300
<span class=w>  </span>Num<span class=w> </span>Epochs<span class=w> </span>=<span class=w> </span>3
<span class=w>  </span>Instantaneous<span class=w> </span>batch<span class=w> </span>size<span class=w> </span>per<span class=w> </span>device<span class=w> </span>=<span class=w> </span>32
<span class=w>  </span>Total<span class=w> </span>train<span class=w> </span>batch<span class=w> </span>size<span class=w> </span>(w.<span class=w> </span>parallel,<span class=w> </span>distributed<span class=w> </span><span class=err>&amp;</span><span class=w> </span>accumulation)<span class=w> </span>=<span class=w> </span>128
<span class=w>  </span>Gradient<span class=w> </span>Accumulation<span class=w> </span>steps<span class=w> </span>=<span class=w> </span>4
<span class=w>  </span>Total<span class=w> </span>optimization<span class=w> </span>steps<span class=w> </span>=<span class=w> </span>570




<span class=nt>&lt;div&gt;</span>

<span class=w>  </span><span class=nt>&lt;progress</span><span class=w> </span><span class=na>value=</span><span class=s>&#39;570&#39;</span><span class=w> </span><span class=na>max=</span><span class=s>&#39;570&#39;</span><span class=w> </span><span class=na>style=</span><span class=s>&#39;width:300px; height:20px; vertical-align: middle;&#39;</span><span class=nt>&gt;&lt;/progress&gt;</span>
<span class=w>  </span>[570/570<span class=w> </span>15:59,<span class=w> </span>Epoch<span class=w> </span>3/3]
<span class=nt>&lt;/div&gt;</span>
<span class=nt>&lt;table</span><span class=w> </span><span class=na>border=</span><span class=s>&quot;1&quot;</span><span class=w> </span><span class=na>class=</span><span class=s>&quot;dataframe&quot;</span><span class=nt>&gt;</span>
</code></pre></div> <thead> <tr style="text-align: left;"> <th>Epoch</th> <th>Training Loss</th> <th>Validation Loss</th> <th>Accuracy</th> </tr> </thead> <tbody> <tr> <td>1</td> <td>0.141000</td> <td>0.149633</td> <td>0.954444</td> </tr> <tr> <td>2</td> <td>0.073600</td> <td>0.095782</td> <td>0.971852</td> </tr> <tr> <td>3</td> <td>0.056800</td> <td>0.072716</td> <td>0.974815</td> </tr> </tbody> <p></table><p></p> <div class=codehilite><pre><span></span><code>***** Running Evaluation *****
  Num examples = 2700
  Batch size = 32
Saving model checkpoint to convnext-tiny-224-finetuned-eurosat-albumentations/checkpoint-190
Configuration saved in convnext-tiny-224-finetuned-eurosat-albumentations/checkpoint-190/config.json
Model weights saved in convnext-tiny-224-finetuned-eurosat-albumentations/checkpoint-190/pytorch_model.bin
Feature extractor saved in convnext-tiny-224-finetuned-eurosat-albumentations/checkpoint-190/preprocessor_config.json
Feature extractor saved in convnext-tiny-224-finetuned-eurosat-albumentations/preprocessor_config.json
***** Running Evaluation *****
  Num examples = 2700
  Batch size = 32
Saving model checkpoint to convnext-tiny-224-finetuned-eurosat-albumentations/checkpoint-380
Configuration saved in convnext-tiny-224-finetuned-eurosat-albumentations/checkpoint-380/config.json
Model weights saved in convnext-tiny-224-finetuned-eurosat-albumentations/checkpoint-380/pytorch_model.bin
Feature extractor saved in convnext-tiny-224-finetuned-eurosat-albumentations/checkpoint-380/preprocessor_config.json
Feature extractor saved in convnext-tiny-224-finetuned-eurosat-albumentations/preprocessor_config.json
***** Running Evaluation *****
  Num examples = 2700
  Batch size = 32
Saving model checkpoint to convnext-tiny-224-finetuned-eurosat-albumentations/checkpoint-570
Configuration saved in convnext-tiny-224-finetuned-eurosat-albumentations/checkpoint-570/config.json
Model weights saved in convnext-tiny-224-finetuned-eurosat-albumentations/checkpoint-570/pytorch_model.bin
Feature extractor saved in convnext-tiny-224-finetuned-eurosat-albumentations/checkpoint-570/preprocessor_config.json
Feature extractor saved in convnext-tiny-224-finetuned-eurosat-albumentations/preprocessor_config.json


Training completed. Do not forget to share your model on huggingface.co/models =)


Loading best model from convnext-tiny-224-finetuned-eurosat-albumentations/checkpoint-570 (score: 0.9748148148148148).





TrainOutput(global_step=570, training_loss=0.34729809766275843, metrics={&#39;train_runtime&#39;: 961.6293, &#39;train_samples_per_second&#39;: 75.809, &#39;train_steps_per_second&#39;: 0.593, &#39;total_flos&#39;: 1.8322098956292096e+18, &#39;train_loss&#39;: 0.34729809766275843, &#39;epoch&#39;: 3.0})
</code></pre></div> <p>We can check with the <code>evaluate</code> method that our <code>Trainer</code> did reload the best model properly (if it was not the last one):</p> <div class="language-python highlight"><span class=filename>Python</span><pre><span></span><code><span id=__span-27-1><a id=__codelineno-27-1 name=__codelineno-27-1></a><a href=#__codelineno-27-1><span class=linenos data-linenos="1 "></span></a><span class=n>metrics</span> <span class=o>=</span> <span class=n>trainer</span><span class=o>.</span><span class=n>evaluate</span><span class=p>()</span>
</span><span id=__span-27-2><a id=__codelineno-27-2 name=__codelineno-27-2></a><a href=#__codelineno-27-2><span class=linenos data-linenos="2 "></span></a><span class=nb>print</span><span class=p>(</span><span class=n>metrics</span><span class=p>)</span>
</span></code></pre></div> <div class=codehilite><pre><span></span><code>***** Running Evaluation *****
  Num examples = 2700
  Batch size = 32
</code></pre></div> <div> <progress value=85 max=85 style="width:300px; height:20px; vertical-align: middle;"></progress> [85/85 00:12] </div> <div class=codehilite><pre><span></span><code>{&#39;eval_loss&#39;: 0.0727163776755333, &#39;eval_accuracy&#39;: 0.9748148148148148, &#39;eval_runtime&#39;: 13.0419, &#39;eval_samples_per_second&#39;: 207.026, &#39;eval_steps_per_second&#39;: 6.517, &#39;epoch&#39;: 3.0}
</code></pre></div> <p>You can now upload the result of the training to the Hub, just execute this instruction (note that the Trainer will automatically create a model card for you, as well as adding Tensorboard metrics - see the "Training metrics" tab!):</p> <div class="language-python highlight"><span class=filename>Python</span><pre><span></span><code><span id=__span-28-1><a id=__codelineno-28-1 name=__codelineno-28-1></a><a href=#__codelineno-28-1><span class=linenos data-linenos="1 "></span></a><span class=n>trainer</span><span class=o>.</span><span class=n>push_to_hub</span><span class=p>()</span>
</span></code></pre></div> <div class=codehilite><pre><span></span><code><span class=n>Saving</span><span class=w> </span><span class=n>model</span><span class=w> </span><span class=n>checkpoint</span><span class=w> </span><span class=n>to</span><span class=w> </span><span class=n>convnext</span><span class=o>-</span><span class=n>tiny</span><span class=o>-</span><span class=mi>224</span><span class=o>-</span><span class=n>finetuned</span><span class=o>-</span><span class=n>eurosat</span><span class=o>-</span><span class=n>albumentations</span>
<span class=n>Configuration</span><span class=w> </span><span class=n>saved</span><span class=w> </span><span class=ow>in</span><span class=w> </span><span class=n>convnext</span><span class=o>-</span><span class=n>tiny</span><span class=o>-</span><span class=mi>224</span><span class=o>-</span><span class=n>finetuned</span><span class=o>-</span><span class=n>eurosat</span><span class=o>-</span><span class=n>albumentations</span><span class=o>/</span><span class=n>config</span><span class=o>.</span><span class=n>json</span>
<span class=n>Model</span><span class=w> </span><span class=n>weights</span><span class=w> </span><span class=n>saved</span><span class=w> </span><span class=ow>in</span><span class=w> </span><span class=n>convnext</span><span class=o>-</span><span class=n>tiny</span><span class=o>-</span><span class=mi>224</span><span class=o>-</span><span class=n>finetuned</span><span class=o>-</span><span class=n>eurosat</span><span class=o>-</span><span class=n>albumentations</span><span class=o>/</span><span class=n>pytorch_model</span><span class=o>.</span><span class=n>bin</span>
<span class=n>Feature</span><span class=w> </span><span class=n>extractor</span><span class=w> </span><span class=n>saved</span><span class=w> </span><span class=ow>in</span><span class=w> </span><span class=n>convnext</span><span class=o>-</span><span class=n>tiny</span><span class=o>-</span><span class=mi>224</span><span class=o>-</span><span class=n>finetuned</span><span class=o>-</span><span class=n>eurosat</span><span class=o>-</span><span class=n>albumentations</span><span class=o>/</span><span class=n>preprocessor_config</span><span class=o>.</span><span class=n>json</span>



<span class=n>Upload</span><span class=w> </span><span class=n>file</span><span class=w> </span><span class=n>runs</span><span class=o>/</span><span class=n>Apr12_12</span><span class=o>-</span><span class=mi>03</span><span class=o>-</span><span class=mi>24</span><span class=n>_1ad162e1ead9</span><span class=o>/</span><span class=n>events</span><span class=o>.</span><span class=n>out</span><span class=o>.</span><span class=n>tfevents</span><span class=o>.</span><span class=mf>1649765159.1</span><span class=n>ad162e1ead9</span><span class=o>.</span><span class=mf>73.4</span><span class=p>:</span><span class=w>  </span><span class=mi>24</span><span class=o>%|</span><span class=c1>##4       …</span>



<span class=n>Upload</span><span class=w> </span><span class=n>file</span><span class=w> </span><span class=n>runs</span><span class=o>/</span><span class=n>Apr12_12</span><span class=o>-</span><span class=mi>03</span><span class=o>-</span><span class=mi>24</span><span class=n>_1ad162e1ead9</span><span class=o>/</span><span class=n>events</span><span class=o>.</span><span class=n>out</span><span class=o>.</span><span class=n>tfevents</span><span class=o>.</span><span class=mf>1649767032.1</span><span class=n>ad162e1ead9</span><span class=o>.</span><span class=mf>73.6</span><span class=p>:</span><span class=w> </span><span class=mi>100</span><span class=o>%|</span><span class=c1>##########…</span>


<span class=n>To</span><span class=w> </span><span class=n>https</span><span class=p>:</span><span class=o>//</span><span class=n>huggingface</span><span class=o>.</span><span class=n>co</span><span class=o>/</span><span class=n>nielsr</span><span class=o>/</span><span class=n>convnext</span><span class=o>-</span><span class=n>tiny</span><span class=o>-</span><span class=mi>224</span><span class=o>-</span><span class=n>finetuned</span><span class=o>-</span><span class=n>eurosat</span><span class=o>-</span><span class=n>albumentations</span>
<span class=w>   </span><span class=n>c500b3f</span><span class=o>..</span><span class=mi>2143</span><span class=n>b42</span><span class=w>  </span><span class=n>main</span><span class=w> </span><span class=o>-&gt;</span><span class=w> </span><span class=n>main</span>

<span class=n>To</span><span class=w> </span><span class=n>https</span><span class=p>:</span><span class=o>//</span><span class=n>huggingface</span><span class=o>.</span><span class=n>co</span><span class=o>/</span><span class=n>nielsr</span><span class=o>/</span><span class=n>convnext</span><span class=o>-</span><span class=n>tiny</span><span class=o>-</span><span class=mi>224</span><span class=o>-</span><span class=n>finetuned</span><span class=o>-</span><span class=n>eurosat</span><span class=o>-</span><span class=n>albumentations</span>
<span class=w>   </span><span class=mi>2143</span><span class=n>b42</span><span class=o>..</span><span class=mi>71339</span><span class=n>cf</span><span class=w>  </span><span class=n>main</span><span class=w> </span><span class=o>-&gt;</span><span class=w> </span><span class=n>main</span>






<span class=s1>&#39;https://huggingface.co/nielsr/convnext-tiny-224-finetuned-eurosat-albumentations/commit/2143b423b5cacdde6daebd3ee2b5971ecab463f6&#39;</span>
</code></pre></div> <p>You can now share this model with all your friends, family, favorite pets: they can all load it with the identifier <code>"your-username/the-name-you-picked"</code> so for instance:</p> <div class="language-python highlight"><span class=filename>Python</span><pre><span></span><code><span id=__span-29-1><a id=__codelineno-29-1 name=__codelineno-29-1></a><a href=#__codelineno-29-1><span class=linenos data-linenos="1 "></span></a><span class=kn>from</span><span class=w> </span><span class=nn>transformers</span><span class=w> </span><span class=kn>import</span> <span class=n>AutoModelForImageClassification</span><span class=p>,</span> <span class=n>AutoImageProcessor</span>
</span><span id=__span-29-2><a id=__codelineno-29-2 name=__codelineno-29-2></a><a href=#__codelineno-29-2><span class=linenos data-linenos="2 "></span></a>
</span><span id=__span-29-3><a id=__codelineno-29-3 name=__codelineno-29-3></a><a href=#__codelineno-29-3><span class=linenos data-linenos="3 "></span></a><span class=n>image_processor</span> <span class=o>=</span> <span class=n>AutoImageProcessor</span><span class=o>.</span><span class=n>from_pretrained</span><span class=p>(</span><span class=s2>&quot;nielsr/my-awesome-model&quot;</span><span class=p>)</span>
</span><span id=__span-29-4><a id=__codelineno-29-4 name=__codelineno-29-4></a><a href=#__codelineno-29-4><span class=linenos data-linenos="4 "></span></a><span class=n>model</span> <span class=o>=</span> <span class=n>AutoModelForImageClassification</span><span class=o>.</span><span class=n>from_pretrained</span><span class=p>(</span><span class=s2>&quot;nielsr/my-awesome-model&quot;</span><span class=p>)</span>
</span></code></pre></div> <h2 id=inference>Inference<a class=headerlink href=#inference title="Permanent link">&para;</a></h2> <p>Let's say you have a new image, on which you'd like to make a prediction. Let's load a satellite image of a highway (that's not part of the EuroSAT dataset), and see how the model does.</p> <div class="language-python highlight"><span class=filename>Python</span><pre><span></span><code><span id=__span-30-1><a id=__codelineno-30-1 name=__codelineno-30-1></a><a href=#__codelineno-30-1><span class=linenos data-linenos="1 "></span></a><span class=kn>from</span><span class=w> </span><span class=nn>PIL</span><span class=w> </span><span class=kn>import</span> <span class=n>Image</span>
</span><span id=__span-30-2><a id=__codelineno-30-2 name=__codelineno-30-2></a><a href=#__codelineno-30-2><span class=linenos data-linenos="2 "></span></a><span class=kn>import</span><span class=w> </span><span class=nn>requests</span>
</span><span id=__span-30-3><a id=__codelineno-30-3 name=__codelineno-30-3></a><a href=#__codelineno-30-3><span class=linenos data-linenos="3 "></span></a>
</span><span id=__span-30-4><a id=__codelineno-30-4 name=__codelineno-30-4></a><a href=#__codelineno-30-4><span class=linenos data-linenos="4 "></span></a><span class=n>url</span> <span class=o>=</span> <span class=s1>&#39;https://huggingface.co/nielsr/convnext-tiny-224-finetuned-eurosat-albumentations/resolve/main/highway.jpg&#39;</span>
</span><span id=__span-30-5><a id=__codelineno-30-5 name=__codelineno-30-5></a><a href=#__codelineno-30-5><span class=linenos data-linenos="5 "></span></a><span class=n>image</span> <span class=o>=</span> <span class=n>Image</span><span class=o>.</span><span class=n>open</span><span class=p>(</span><span class=n>requests</span><span class=o>.</span><span class=n>get</span><span class=p>(</span><span class=n>url</span><span class=p>,</span> <span class=n>stream</span><span class=o>=</span><span class=kc>True</span><span class=p>)</span><span class=o>.</span><span class=n>raw</span><span class=p>)</span>
</span><span id=__span-30-6><a id=__codelineno-30-6 name=__codelineno-30-6></a><a href=#__codelineno-30-6><span class=linenos data-linenos="6 "></span></a><span class=n>image</span>
</span></code></pre></div> <p><img alt=png src=/workspace/docs/src/docs/integrations/huggingface/image_classification_albumentations_67_0.png></p> <p>We'll load the image processor and model from the hub (here, we use the <a href=https://huggingface.co/docs/transformers/model_doc/auto#transformers.AutoModelForImageClassification>Auto Classes</a>, which will make sure the appropriate classes will be loaded automatically based on the <code>config.json</code> and <code>preprocessor_config.json</code> files of the repo on the hub):</p> <div class="language-python highlight"><span class=filename>Python</span><pre><span></span><code><span id=__span-31-1><a id=__codelineno-31-1 name=__codelineno-31-1></a><a href=#__codelineno-31-1><span class=linenos data-linenos="1 "></span></a><span class=kn>from</span><span class=w> </span><span class=nn>transformers</span><span class=w> </span><span class=kn>import</span> <span class=n>AutoModelForImageClassification</span><span class=p>,</span> <span class=n>AutoImageProcessor</span>
</span><span id=__span-31-2><a id=__codelineno-31-2 name=__codelineno-31-2></a><a href=#__codelineno-31-2><span class=linenos data-linenos="2 "></span></a>
</span><span id=__span-31-3><a id=__codelineno-31-3 name=__codelineno-31-3></a><a href=#__codelineno-31-3><span class=linenos data-linenos="3 "></span></a><span class=n>repo_name</span> <span class=o>=</span> <span class=s2>&quot;nielsr/convnext-tiny-224-finetuned-eurosat-albumentations&quot;</span>
</span><span id=__span-31-4><a id=__codelineno-31-4 name=__codelineno-31-4></a><a href=#__codelineno-31-4><span class=linenos data-linenos="4 "></span></a>
</span><span id=__span-31-5><a id=__codelineno-31-5 name=__codelineno-31-5></a><a href=#__codelineno-31-5><span class=linenos data-linenos="5 "></span></a><span class=n>image_processor</span> <span class=o>=</span> <span class=n>AutoImageProcessor</span><span class=o>.</span><span class=n>from_pretrained</span><span class=p>(</span><span class=n>repo_name</span><span class=p>)</span>
</span><span id=__span-31-6><a id=__codelineno-31-6 name=__codelineno-31-6></a><a href=#__codelineno-31-6><span class=linenos data-linenos="6 "></span></a><span class=n>model</span> <span class=o>=</span> <span class=n>AutoModelForImageClassification</span><span class=o>.</span><span class=n>from_pretrained</span><span class=p>(</span><span class=n>repo_name</span><span class=p>)</span>
</span></code></pre></div> <div class=codehilite><pre><span></span><code><span class=n>https</span><span class=p>:</span><span class=o>//</span><span class=n>huggingface</span><span class=o>.</span><span class=n>co</span><span class=o>/</span><span class=n>nielsr</span><span class=o>/</span><span class=n>convnext</span><span class=o>-</span><span class=n>tiny</span><span class=o>-</span><span class=mi>224</span><span class=o>-</span><span class=n>finetuned</span><span class=o>-</span><span class=n>eurosat</span><span class=o>-</span><span class=n>albumentations</span><span class=o>/</span><span class=n>resolve</span><span class=o>/</span><span class=n>main</span><span class=o>/</span><span class=n>preprocessor_config</span><span class=o>.</span><span class=n>json</span><span class=w> </span><span class=ow>not</span><span class=w> </span><span class=n>found</span><span class=w> </span><span class=ow>in</span><span class=w> </span><span class=n>cache</span><span class=w> </span><span class=ow>or</span><span class=w> </span><span class=n>force_download</span><span class=w> </span><span class=n>set</span><span class=w> </span><span class=n>to</span><span class=w> </span><span class=n>True</span><span class=p>,</span><span class=w> </span><span class=n>downloading</span><span class=w> </span><span class=n>to</span><span class=w> </span><span class=o>/</span><span class=n>root</span><span class=o>/.</span><span class=n>cache</span><span class=o>/</span><span class=n>huggingface</span><span class=o>/</span><span class=n>transformers</span><span class=o>/</span><span class=n>tmp04g0zg5n</span>



<span class=n>Downloading</span><span class=p>:</span><span class=w>   </span><span class=mi>0</span><span class=o>%|</span><span class=w>          </span><span class=o>|</span><span class=w> </span><span class=mf>0.00</span><span class=o>/</span><span class=mi>266</span><span class=w> </span><span class=p>[</span><span class=mi>00</span><span class=p>:</span><span class=mi>00</span><span class=o>&lt;</span><span class=err>?</span><span class=p>,</span><span class=w> </span><span class=err>?</span><span class=n>B</span><span class=o>/</span><span class=n>s</span><span class=p>]</span>


<span class=n>storing</span><span class=w> </span><span class=n>https</span><span class=p>:</span><span class=o>//</span><span class=n>huggingface</span><span class=o>.</span><span class=n>co</span><span class=o>/</span><span class=n>nielsr</span><span class=o>/</span><span class=n>convnext</span><span class=o>-</span><span class=n>tiny</span><span class=o>-</span><span class=mi>224</span><span class=o>-</span><span class=n>finetuned</span><span class=o>-</span><span class=n>eurosat</span><span class=o>-</span><span class=n>albumentations</span><span class=o>/</span><span class=n>resolve</span><span class=o>/</span><span class=n>main</span><span class=o>/</span><span class=n>preprocessor_config</span><span class=o>.</span><span class=n>json</span><span class=w> </span><span class=ow>in</span><span class=w> </span><span class=n>cache</span><span class=w> </span><span class=n>at</span><span class=w> </span><span class=o>/</span><span class=n>root</span><span class=o>/.</span><span class=n>cache</span><span class=o>/</span><span class=n>huggingface</span><span class=o>/</span><span class=n>transformers</span><span class=o>/</span><span class=mi>38</span><span class=n>b41a2c904b6ce5bb10403bf902ee4263144d862c5a602c83cd120c0c1ba0e6</span><span class=o>.</span><span class=mi>37</span><span class=n>be7274d6b5860aee104bb1fbaeb0722fec3850a85bb2557ae9491f17f89433</span>
<span class=n>creating</span><span class=w> </span><span class=n>metadata</span><span class=w> </span><span class=n>file</span><span class=w> </span><span class=k>for</span><span class=w> </span><span class=o>/</span><span class=n>root</span><span class=o>/.</span><span class=n>cache</span><span class=o>/</span><span class=n>huggingface</span><span class=o>/</span><span class=n>transformers</span><span class=o>/</span><span class=mi>38</span><span class=n>b41a2c904b6ce5bb10403bf902ee4263144d862c5a602c83cd120c0c1ba0e6</span><span class=o>.</span><span class=mi>37</span><span class=n>be7274d6b5860aee104bb1fbaeb0722fec3850a85bb2557ae9491f17f89433</span>
<span class=n>loading</span><span class=w> </span><span class=n>feature</span><span class=w> </span><span class=n>extractor</span><span class=w> </span><span class=n>configuration</span><span class=w> </span><span class=n>file</span><span class=w> </span><span class=n>https</span><span class=p>:</span><span class=o>//</span><span class=n>huggingface</span><span class=o>.</span><span class=n>co</span><span class=o>/</span><span class=n>nielsr</span><span class=o>/</span><span class=n>convnext</span><span class=o>-</span><span class=n>tiny</span><span class=o>-</span><span class=mi>224</span><span class=o>-</span><span class=n>finetuned</span><span class=o>-</span><span class=n>eurosat</span><span class=o>-</span><span class=n>albumentations</span><span class=o>/</span><span class=n>resolve</span><span class=o>/</span><span class=n>main</span><span class=o>/</span><span class=n>preprocessor_config</span><span class=o>.</span><span class=n>json</span><span class=w> </span><span class=n>from</span><span class=w> </span><span class=n>cache</span><span class=w> </span><span class=n>at</span><span class=w> </span><span class=o>/</span><span class=n>root</span><span class=o>/.</span><span class=n>cache</span><span class=o>/</span><span class=n>huggingface</span><span class=o>/</span><span class=n>transformers</span><span class=o>/</span><span class=mi>38</span><span class=n>b41a2c904b6ce5bb10403bf902ee4263144d862c5a602c83cd120c0c1ba0e6</span><span class=o>.</span><span class=mi>37</span><span class=n>be7274d6b5860aee104bb1fbaeb0722fec3850a85bb2557ae9491f17f89433</span>
<span class=n>Feature</span><span class=w> </span><span class=n>extractor</span><span class=w> </span><span class=n>ConvNextFeatureExtractor</span><span class=w> </span><span class=p>{</span>
<span class=w>  </span><span class=s2>&quot;crop_pct&quot;</span><span class=p>:</span><span class=w> </span><span class=mf>0.875</span><span class=p>,</span>
<span class=w>  </span><span class=s2>&quot;do_normalize&quot;</span><span class=p>:</span><span class=w> </span><span class=bp>true</span><span class=p>,</span>
<span class=w>  </span><span class=s2>&quot;do_resize&quot;</span><span class=p>:</span><span class=w> </span><span class=bp>true</span><span class=p>,</span>
<span class=w>  </span><span class=s2>&quot;feature_extractor_type&quot;</span><span class=p>:</span><span class=w> </span><span class=s2>&quot;ConvNextFeatureExtractor&quot;</span><span class=p>,</span>
<span class=w>  </span><span class=s2>&quot;image_mean&quot;</span><span class=p>:</span><span class=w> </span><span class=p>[</span>
<span class=w>    </span><span class=mf>0.485</span><span class=p>,</span>
<span class=w>    </span><span class=mf>0.456</span><span class=p>,</span>
<span class=w>    </span><span class=mf>0.406</span>
<span class=w>  </span><span class=p>],</span>
<span class=w>  </span><span class=s2>&quot;image_std&quot;</span><span class=p>:</span><span class=w> </span><span class=p>[</span>
<span class=w>    </span><span class=mf>0.229</span><span class=p>,</span>
<span class=w>    </span><span class=mf>0.224</span><span class=p>,</span>
<span class=w>    </span><span class=mf>0.225</span>
<span class=w>  </span><span class=p>],</span>
<span class=w>  </span><span class=s2>&quot;resample&quot;</span><span class=p>:</span><span class=w> </span><span class=mi>3</span><span class=p>,</span>
<span class=w>  </span><span class=s2>&quot;size&quot;</span><span class=p>:</span><span class=w> </span><span class=mi>224</span>
<span class=p>}</span>

<span class=n>https</span><span class=p>:</span><span class=o>//</span><span class=n>huggingface</span><span class=o>.</span><span class=n>co</span><span class=o>/</span><span class=n>nielsr</span><span class=o>/</span><span class=n>convnext</span><span class=o>-</span><span class=n>tiny</span><span class=o>-</span><span class=mi>224</span><span class=o>-</span><span class=n>finetuned</span><span class=o>-</span><span class=n>eurosat</span><span class=o>-</span><span class=n>albumentations</span><span class=o>/</span><span class=n>resolve</span><span class=o>/</span><span class=n>main</span><span class=o>/</span><span class=n>config</span><span class=o>.</span><span class=n>json</span><span class=w> </span><span class=ow>not</span><span class=w> </span><span class=n>found</span><span class=w> </span><span class=ow>in</span><span class=w> </span><span class=n>cache</span><span class=w> </span><span class=ow>or</span><span class=w> </span><span class=n>force_download</span><span class=w> </span><span class=n>set</span><span class=w> </span><span class=n>to</span><span class=w> </span><span class=n>True</span><span class=p>,</span><span class=w> </span><span class=n>downloading</span><span class=w> </span><span class=n>to</span><span class=w> </span><span class=o>/</span><span class=n>root</span><span class=o>/.</span><span class=n>cache</span><span class=o>/</span><span class=n>huggingface</span><span class=o>/</span><span class=n>transformers</span><span class=o>/</span><span class=n>tmpbf9y4q39</span>



<span class=n>Downloading</span><span class=p>:</span><span class=w>   </span><span class=mi>0</span><span class=o>%|</span><span class=w>          </span><span class=o>|</span><span class=w> </span><span class=mf>0.00</span><span class=o>/</span><span class=mf>1.03</span><span class=n>k</span><span class=w> </span><span class=p>[</span><span class=mi>00</span><span class=p>:</span><span class=mi>00</span><span class=o>&lt;</span><span class=err>?</span><span class=p>,</span><span class=w> </span><span class=err>?</span><span class=n>B</span><span class=o>/</span><span class=n>s</span><span class=p>]</span>


<span class=n>storing</span><span class=w> </span><span class=n>https</span><span class=p>:</span><span class=o>//</span><span class=n>huggingface</span><span class=o>.</span><span class=n>co</span><span class=o>/</span><span class=n>nielsr</span><span class=o>/</span><span class=n>convnext</span><span class=o>-</span><span class=n>tiny</span><span class=o>-</span><span class=mi>224</span><span class=o>-</span><span class=n>finetuned</span><span class=o>-</span><span class=n>eurosat</span><span class=o>-</span><span class=n>albumentations</span><span class=o>/</span><span class=n>resolve</span><span class=o>/</span><span class=n>main</span><span class=o>/</span><span class=n>config</span><span class=o>.</span><span class=n>json</span><span class=w> </span><span class=ow>in</span><span class=w> </span><span class=n>cache</span><span class=w> </span><span class=n>at</span><span class=w> </span><span class=o>/</span><span class=n>root</span><span class=o>/.</span><span class=n>cache</span><span class=o>/</span><span class=n>huggingface</span><span class=o>/</span><span class=n>transformers</span><span class=o>/</span><span class=mi>25088566</span><span class=n>ab29cf0ff360b05880b5f20cdc0c79ab995056a1fb4f98212d021154</span><span class=o>.</span><span class=mi>4637</span><span class=n>c3f271a8dfbcfe5c4ee777270112d841a5af95814f0fd086c3c2761e7370</span>
<span class=n>creating</span><span class=w> </span><span class=n>metadata</span><span class=w> </span><span class=n>file</span><span class=w> </span><span class=k>for</span><span class=w> </span><span class=o>/</span><span class=n>root</span><span class=o>/.</span><span class=n>cache</span><span class=o>/</span><span class=n>huggingface</span><span class=o>/</span><span class=n>transformers</span><span class=o>/</span><span class=mi>25088566</span><span class=n>ab29cf0ff360b05880b5f20cdc0c79ab995056a1fb4f98212d021154</span><span class=o>.</span><span class=mi>4637</span><span class=n>c3f271a8dfbcfe5c4ee777270112d841a5af95814f0fd086c3c2761e7370</span>
<span class=n>loading</span><span class=w> </span><span class=n>configuration</span><span class=w> </span><span class=n>file</span><span class=w> </span><span class=n>https</span><span class=p>:</span><span class=o>//</span><span class=n>huggingface</span><span class=o>.</span><span class=n>co</span><span class=o>/</span><span class=n>nielsr</span><span class=o>/</span><span class=n>convnext</span><span class=o>-</span><span class=n>tiny</span><span class=o>-</span><span class=mi>224</span><span class=o>-</span><span class=n>finetuned</span><span class=o>-</span><span class=n>eurosat</span><span class=o>-</span><span class=n>albumentations</span><span class=o>/</span><span class=n>resolve</span><span class=o>/</span><span class=n>main</span><span class=o>/</span><span class=n>config</span><span class=o>.</span><span class=n>json</span><span class=w> </span><span class=n>from</span><span class=w> </span><span class=n>cache</span><span class=w> </span><span class=n>at</span><span class=w> </span><span class=o>/</span><span class=n>root</span><span class=o>/.</span><span class=n>cache</span><span class=o>/</span><span class=n>huggingface</span><span class=o>/</span><span class=n>transformers</span><span class=o>/</span><span class=mi>25088566</span><span class=n>ab29cf0ff360b05880b5f20cdc0c79ab995056a1fb4f98212d021154</span><span class=o>.</span><span class=mi>4637</span><span class=n>c3f271a8dfbcfe5c4ee777270112d841a5af95814f0fd086c3c2761e7370</span>
<span class=n>Model</span><span class=w> </span><span class=n>config</span><span class=w> </span><span class=n>ConvNextConfig</span><span class=w> </span><span class=p>{</span>
<span class=w>  </span><span class=s2>&quot;_name_or_path&quot;</span><span class=p>:</span><span class=w> </span><span class=s2>&quot;nielsr/convnext-tiny-224-finetuned-eurosat-albumentations&quot;</span><span class=p>,</span>
<span class=w>  </span><span class=s2>&quot;architectures&quot;</span><span class=p>:</span><span class=w> </span><span class=p>[</span>
<span class=w>    </span><span class=s2>&quot;ConvNextForImageClassification&quot;</span>
<span class=w>  </span><span class=p>],</span>
<span class=w>  </span><span class=s2>&quot;depths&quot;</span><span class=p>:</span><span class=w> </span><span class=p>[</span>
<span class=w>    </span><span class=mi>3</span><span class=p>,</span>
<span class=w>    </span><span class=mi>3</span><span class=p>,</span>
<span class=w>    </span><span class=mi>9</span><span class=p>,</span>
<span class=w>    </span><span class=mi>3</span>
<span class=w>  </span><span class=p>],</span>
<span class=w>  </span><span class=s2>&quot;drop_path_rate&quot;</span><span class=p>:</span><span class=w> </span><span class=mf>0.0</span><span class=p>,</span>
<span class=w>  </span><span class=s2>&quot;hidden_act&quot;</span><span class=p>:</span><span class=w> </span><span class=s2>&quot;gelu&quot;</span><span class=p>,</span>
<span class=w>  </span><span class=s2>&quot;hidden_sizes&quot;</span><span class=p>:</span><span class=w> </span><span class=p>[</span>
<span class=w>    </span><span class=mi>96</span><span class=p>,</span>
<span class=w>    </span><span class=mi>192</span><span class=p>,</span>
<span class=w>    </span><span class=mi>384</span><span class=p>,</span>
<span class=w>    </span><span class=mi>768</span>
<span class=w>  </span><span class=p>],</span>
<span class=w>  </span><span class=s2>&quot;id2label&quot;</span><span class=p>:</span><span class=w> </span><span class=p>{</span>
<span class=w>    </span><span class=s2>&quot;0&quot;</span><span class=p>:</span><span class=w> </span><span class=s2>&quot;AnnualCrop&quot;</span><span class=p>,</span>
<span class=w>    </span><span class=s2>&quot;1&quot;</span><span class=p>:</span><span class=w> </span><span class=s2>&quot;Forest&quot;</span><span class=p>,</span>
<span class=w>    </span><span class=s2>&quot;2&quot;</span><span class=p>:</span><span class=w> </span><span class=s2>&quot;HerbaceousVegetation&quot;</span><span class=p>,</span>
<span class=w>    </span><span class=s2>&quot;3&quot;</span><span class=p>:</span><span class=w> </span><span class=s2>&quot;Highway&quot;</span><span class=p>,</span>
<span class=w>    </span><span class=s2>&quot;4&quot;</span><span class=p>:</span><span class=w> </span><span class=s2>&quot;Industrial&quot;</span><span class=p>,</span>
<span class=w>    </span><span class=s2>&quot;5&quot;</span><span class=p>:</span><span class=w> </span><span class=s2>&quot;Pasture&quot;</span><span class=p>,</span>
<span class=w>    </span><span class=s2>&quot;6&quot;</span><span class=p>:</span><span class=w> </span><span class=s2>&quot;PermanentCrop&quot;</span><span class=p>,</span>
<span class=w>    </span><span class=s2>&quot;7&quot;</span><span class=p>:</span><span class=w> </span><span class=s2>&quot;Residential&quot;</span><span class=p>,</span>
<span class=w>    </span><span class=s2>&quot;8&quot;</span><span class=p>:</span><span class=w> </span><span class=s2>&quot;River&quot;</span><span class=p>,</span>
<span class=w>    </span><span class=s2>&quot;9&quot;</span><span class=p>:</span><span class=w> </span><span class=s2>&quot;SeaLake&quot;</span>
<span class=w>  </span><span class=p>},</span>
<span class=w>  </span><span class=s2>&quot;image_size&quot;</span><span class=p>:</span><span class=w> </span><span class=mi>224</span><span class=p>,</span>
<span class=w>  </span><span class=s2>&quot;initializer_range&quot;</span><span class=p>:</span><span class=w> </span><span class=mf>0.02</span><span class=p>,</span>
<span class=w>  </span><span class=s2>&quot;label2id&quot;</span><span class=p>:</span><span class=w> </span><span class=p>{</span>
<span class=w>    </span><span class=s2>&quot;AnnualCrop&quot;</span><span class=p>:</span><span class=w> </span><span class=mi>0</span><span class=p>,</span>
<span class=w>    </span><span class=s2>&quot;Forest&quot;</span><span class=p>:</span><span class=w> </span><span class=mi>1</span><span class=p>,</span>
<span class=w>    </span><span class=s2>&quot;HerbaceousVegetation&quot;</span><span class=p>:</span><span class=w> </span><span class=mi>2</span><span class=p>,</span>
<span class=w>    </span><span class=s2>&quot;Highway&quot;</span><span class=p>:</span><span class=w> </span><span class=mi>3</span><span class=p>,</span>
<span class=w>    </span><span class=s2>&quot;Industrial&quot;</span><span class=p>:</span><span class=w> </span><span class=mi>4</span><span class=p>,</span>
<span class=w>    </span><span class=s2>&quot;Pasture&quot;</span><span class=p>:</span><span class=w> </span><span class=mi>5</span><span class=p>,</span>
<span class=w>    </span><span class=s2>&quot;PermanentCrop&quot;</span><span class=p>:</span><span class=w> </span><span class=mi>6</span><span class=p>,</span>
<span class=w>    </span><span class=s2>&quot;Residential&quot;</span><span class=p>:</span><span class=w> </span><span class=mi>7</span><span class=p>,</span>
<span class=w>    </span><span class=s2>&quot;River&quot;</span><span class=p>:</span><span class=w> </span><span class=mi>8</span><span class=p>,</span>
<span class=w>    </span><span class=s2>&quot;SeaLake&quot;</span><span class=p>:</span><span class=w> </span><span class=mi>9</span>
<span class=w>  </span><span class=p>},</span>
<span class=w>  </span><span class=s2>&quot;layer_norm_eps&quot;</span><span class=p>:</span><span class=w> </span><span class=mf>1e-12</span><span class=p>,</span>
<span class=w>  </span><span class=s2>&quot;layer_scale_init_value&quot;</span><span class=p>:</span><span class=w> </span><span class=mf>1e-06</span><span class=p>,</span>
<span class=w>  </span><span class=s2>&quot;model_type&quot;</span><span class=p>:</span><span class=w> </span><span class=s2>&quot;convnext&quot;</span><span class=p>,</span>
<span class=w>  </span><span class=s2>&quot;num_channels&quot;</span><span class=p>:</span><span class=w> </span><span class=mi>3</span><span class=p>,</span>
<span class=w>  </span><span class=s2>&quot;num_stages&quot;</span><span class=p>:</span><span class=w> </span><span class=mi>4</span><span class=p>,</span>
<span class=w>  </span><span class=s2>&quot;patch_size&quot;</span><span class=p>:</span><span class=w> </span><span class=mi>4</span><span class=p>,</span>
<span class=w>  </span><span class=s2>&quot;problem_type&quot;</span><span class=p>:</span><span class=w> </span><span class=s2>&quot;single_label_classification&quot;</span><span class=p>,</span>
<span class=w>  </span><span class=s2>&quot;torch_dtype&quot;</span><span class=p>:</span><span class=w> </span><span class=s2>&quot;float32&quot;</span><span class=p>,</span>
<span class=w>  </span><span class=s2>&quot;transformers_version&quot;</span><span class=p>:</span><span class=w> </span><span class=s2>&quot;4.18.0&quot;</span>
<span class=p>}</span>

<span class=n>https</span><span class=p>:</span><span class=o>//</span><span class=n>huggingface</span><span class=o>.</span><span class=n>co</span><span class=o>/</span><span class=n>nielsr</span><span class=o>/</span><span class=n>convnext</span><span class=o>-</span><span class=n>tiny</span><span class=o>-</span><span class=mi>224</span><span class=o>-</span><span class=n>finetuned</span><span class=o>-</span><span class=n>eurosat</span><span class=o>-</span><span class=n>albumentations</span><span class=o>/</span><span class=n>resolve</span><span class=o>/</span><span class=n>main</span><span class=o>/</span><span class=n>pytorch_model</span><span class=o>.</span><span class=n>bin</span><span class=w> </span><span class=ow>not</span><span class=w> </span><span class=n>found</span><span class=w> </span><span class=ow>in</span><span class=w> </span><span class=n>cache</span><span class=w> </span><span class=ow>or</span><span class=w> </span><span class=n>force_download</span><span class=w> </span><span class=n>set</span><span class=w> </span><span class=n>to</span><span class=w> </span><span class=n>True</span><span class=p>,</span><span class=w> </span><span class=n>downloading</span><span class=w> </span><span class=n>to</span><span class=w> </span><span class=o>/</span><span class=n>root</span><span class=o>/.</span><span class=n>cache</span><span class=o>/</span><span class=n>huggingface</span><span class=o>/</span><span class=n>transformers</span><span class=o>/</span><span class=n>tmpzr_9yxjo</span>



<span class=n>Downloading</span><span class=p>:</span><span class=w>   </span><span class=mi>0</span><span class=o>%|</span><span class=w>          </span><span class=o>|</span><span class=w> </span><span class=mf>0.00</span><span class=o>/</span><span class=mi>106</span><span class=n>M</span><span class=w> </span><span class=p>[</span><span class=mi>00</span><span class=p>:</span><span class=mi>00</span><span class=o>&lt;</span><span class=err>?</span><span class=p>,</span><span class=w> </span><span class=err>?</span><span class=n>B</span><span class=o>/</span><span class=n>s</span><span class=p>]</span>


<span class=n>storing</span><span class=w> </span><span class=n>https</span><span class=p>:</span><span class=o>//</span><span class=n>huggingface</span><span class=o>.</span><span class=n>co</span><span class=o>/</span><span class=n>nielsr</span><span class=o>/</span><span class=n>convnext</span><span class=o>-</span><span class=n>tiny</span><span class=o>-</span><span class=mi>224</span><span class=o>-</span><span class=n>finetuned</span><span class=o>-</span><span class=n>eurosat</span><span class=o>-</span><span class=n>albumentations</span><span class=o>/</span><span class=n>resolve</span><span class=o>/</span><span class=n>main</span><span class=o>/</span><span class=n>pytorch_model</span><span class=o>.</span><span class=n>bin</span><span class=w> </span><span class=ow>in</span><span class=w> </span><span class=n>cache</span><span class=w> </span><span class=n>at</span><span class=w> </span><span class=o>/</span><span class=n>root</span><span class=o>/.</span><span class=n>cache</span><span class=o>/</span><span class=n>huggingface</span><span class=o>/</span><span class=n>transformers</span><span class=o>/</span><span class=mi>3</span><span class=n>f4bcce35d3279d19b07fb762859d89bce636d8f0235685031ef6494800b9769</span><span class=o>.</span><span class=n>d611c768c0b0939188b05c3d505f0b36c97aa57649d4637e3384992d3c5c0b89</span>
<span class=n>creating</span><span class=w> </span><span class=n>metadata</span><span class=w> </span><span class=n>file</span><span class=w> </span><span class=k>for</span><span class=w> </span><span class=o>/</span><span class=n>root</span><span class=o>/.</span><span class=n>cache</span><span class=o>/</span><span class=n>huggingface</span><span class=o>/</span><span class=n>transformers</span><span class=o>/</span><span class=mi>3</span><span class=n>f4bcce35d3279d19b07fb762859d89bce636d8f0235685031ef6494800b9769</span><span class=o>.</span><span class=n>d611c768c0b0939188b05c3d505f0b36c97aa57649d4637e3384992d3c5c0b89</span>
<span class=n>loading</span><span class=w> </span><span class=n>weights</span><span class=w> </span><span class=n>file</span><span class=w> </span><span class=n>https</span><span class=p>:</span><span class=o>//</span><span class=n>huggingface</span><span class=o>.</span><span class=n>co</span><span class=o>/</span><span class=n>nielsr</span><span class=o>/</span><span class=n>convnext</span><span class=o>-</span><span class=n>tiny</span><span class=o>-</span><span class=mi>224</span><span class=o>-</span><span class=n>finetuned</span><span class=o>-</span><span class=n>eurosat</span><span class=o>-</span><span class=n>albumentations</span><span class=o>/</span><span class=n>resolve</span><span class=o>/</span><span class=n>main</span><span class=o>/</span><span class=n>pytorch_model</span><span class=o>.</span><span class=n>bin</span><span class=w> </span><span class=n>from</span><span class=w> </span><span class=n>cache</span><span class=w> </span><span class=n>at</span><span class=w> </span><span class=o>/</span><span class=n>root</span><span class=o>/.</span><span class=n>cache</span><span class=o>/</span><span class=n>huggingface</span><span class=o>/</span><span class=n>transformers</span><span class=o>/</span><span class=mi>3</span><span class=n>f4bcce35d3279d19b07fb762859d89bce636d8f0235685031ef6494800b9769</span><span class=o>.</span><span class=n>d611c768c0b0939188b05c3d505f0b36c97aa57649d4637e3384992d3c5c0b89</span>
<span class=n>All</span><span class=w> </span><span class=n>model</span><span class=w> </span><span class=n>checkpoint</span><span class=w> </span><span class=n>weights</span><span class=w> </span><span class=n>were</span><span class=w> </span><span class=n>used</span><span class=w> </span><span class=n>when</span><span class=w> </span><span class=n>initializing</span><span class=w> </span><span class=n>ConvNextForImageClassification</span><span class=o>.</span>

<span class=n>All</span><span class=w> </span><span class=n>the</span><span class=w> </span><span class=n>weights</span><span class=w> </span><span class=n>of</span><span class=w> </span><span class=n>ConvNextForImageClassification</span><span class=w> </span><span class=n>were</span><span class=w> </span><span class=n>initialized</span><span class=w> </span><span class=n>from</span><span class=w> </span><span class=n>the</span><span class=w> </span><span class=n>model</span><span class=w> </span><span class=n>checkpoint</span><span class=w> </span><span class=n>at</span><span class=w> </span><span class=n>nielsr</span><span class=o>/</span><span class=n>convnext</span><span class=o>-</span><span class=n>tiny</span><span class=o>-</span><span class=mi>224</span><span class=o>-</span><span class=n>finetuned</span><span class=o>-</span><span class=n>eurosat</span><span class=o>-</span><span class=n>albumentations</span><span class=o>.</span>
<span class=n>If</span><span class=w> </span><span class=n>your</span><span class=w> </span><span class=n>task</span><span class=w> </span><span class=k>is</span><span class=w> </span><span class=n>similar</span><span class=w> </span><span class=n>to</span><span class=w> </span><span class=n>the</span><span class=w> </span><span class=n>task</span><span class=w> </span><span class=n>the</span><span class=w> </span><span class=n>model</span><span class=w> </span><span class=n>of</span><span class=w> </span><span class=n>the</span><span class=w> </span><span class=n>checkpoint</span><span class=w> </span><span class=n>was</span><span class=w> </span><span class=n>trained</span><span class=w> </span><span class=n>on</span><span class=p>,</span><span class=w> </span><span class=n>you</span><span class=w> </span><span class=n>can</span><span class=w> </span><span class=n>already</span><span class=w> </span><span class=n>use</span><span class=w> </span><span class=n>ConvNextForImageClassification</span><span class=w> </span><span class=k>for</span><span class=w> </span><span class=n>predictions</span><span class=w> </span><span class=n>without</span><span class=w> </span><span class=n>further</span><span class=w> </span><span class=n>training</span><span class=o>.</span>
</code></pre></div> <div class="language-python highlight"><span class=filename>Python</span><pre><span></span><code><span id=__span-32-1><a id=__codelineno-32-1 name=__codelineno-32-1></a><a href=#__codelineno-32-1><span class=linenos data-linenos="1 "></span></a><span class=c1># prepare image for the model</span>
</span><span id=__span-32-2><a id=__codelineno-32-2 name=__codelineno-32-2></a><a href=#__codelineno-32-2><span class=linenos data-linenos="2 "></span></a><span class=n>encoding</span> <span class=o>=</span> <span class=n>image_processor</span><span class=p>(</span><span class=n>image</span><span class=o>.</span><span class=n>convert</span><span class=p>(</span><span class=s2>&quot;RGB&quot;</span><span class=p>),</span> <span class=n>return_tensors</span><span class=o>=</span><span class=s2>&quot;pt&quot;</span><span class=p>)</span>
</span><span id=__span-32-3><a id=__codelineno-32-3 name=__codelineno-32-3></a><a href=#__codelineno-32-3><span class=linenos data-linenos="3 "></span></a><span class=nb>print</span><span class=p>(</span><span class=n>encoding</span><span class=o>.</span><span class=n>pixel_values</span><span class=o>.</span><span class=n>shape</span><span class=p>)</span>
</span></code></pre></div> <div class=codehilite><pre><span></span><code>torch.Size([1, 3, 224, 224])
</code></pre></div> <div class="language-python highlight"><span class=filename>Python</span><pre><span></span><code><span id=__span-33-1><a id=__codelineno-33-1 name=__codelineno-33-1></a><a href=#__codelineno-33-1><span class=linenos data-linenos="1 "></span></a><span class=kn>import</span><span class=w> </span><span class=nn>torch</span>
</span><span id=__span-33-2><a id=__codelineno-33-2 name=__codelineno-33-2></a><a href=#__codelineno-33-2><span class=linenos data-linenos="2 "></span></a>
</span><span id=__span-33-3><a id=__codelineno-33-3 name=__codelineno-33-3></a><a href=#__codelineno-33-3><span class=linenos data-linenos="3 "></span></a><span class=c1># forward pass</span>
</span><span id=__span-33-4><a id=__codelineno-33-4 name=__codelineno-33-4></a><a href=#__codelineno-33-4><span class=linenos data-linenos="4 "></span></a><span class=k>with</span> <span class=n>torch</span><span class=o>.</span><span class=n>no_grad</span><span class=p>():</span>
</span><span id=__span-33-5><a id=__codelineno-33-5 name=__codelineno-33-5></a><a href=#__codelineno-33-5><span class=linenos data-linenos="5 "></span></a>    <span class=n>outputs</span> <span class=o>=</span> <span class=n>model</span><span class=p>(</span><span class=o>**</span><span class=n>encoding</span><span class=p>)</span>
</span><span id=__span-33-6><a id=__codelineno-33-6 name=__codelineno-33-6></a><a href=#__codelineno-33-6><span class=linenos data-linenos="6 "></span></a>    <span class=n>logits</span> <span class=o>=</span> <span class=n>outputs</span><span class=o>.</span><span class=n>logits</span>
</span></code></pre></div> <div class="language-python highlight"><span class=filename>Python</span><pre><span></span><code><span id=__span-34-1><a id=__codelineno-34-1 name=__codelineno-34-1></a><a href=#__codelineno-34-1><span class=linenos data-linenos="1 "></span></a><span class=n>predicted_class_idx</span> <span class=o>=</span> <span class=n>logits</span><span class=o>.</span><span class=n>argmax</span><span class=p>(</span><span class=o>-</span><span class=mi>1</span><span class=p>)</span><span class=o>.</span><span class=n>item</span><span class=p>()</span>
</span><span id=__span-34-2><a id=__codelineno-34-2 name=__codelineno-34-2></a><a href=#__codelineno-34-2><span class=linenos data-linenos="2 "></span></a><span class=nb>print</span><span class=p>(</span><span class=s2>&quot;Predicted class:&quot;</span><span class=p>,</span> <span class=n>model</span><span class=o>.</span><span class=n>config</span><span class=o>.</span><span class=n>id2label</span><span class=p>[</span><span class=n>predicted_class_idx</span><span class=p>])</span>
</span></code></pre></div> <div class=codehilite><pre><span></span><code>Predicted class: Highway
</code></pre></div> <p>Looks like our model got it correct! </p> <h2 id=pipeline-api>Pipeline API<a class=headerlink href=#pipeline-api title="Permanent link">&para;</a></h2> <p>An alternative way to quickly perform inference with any model on the hub is by leveraging the <a href=https://huggingface.co/docs/transformers/main_classes/pipelines>Pipeline API</a>, which abstracts away all the steps we did manually above for us. It will perform the preprocessing, forward pass and postprocessing all in a single object. </p> <p>Let's showcase this for our trained model:</p> <div class="language-python highlight"><span class=filename>Python</span><pre><span></span><code><span id=__span-35-1><a id=__codelineno-35-1 name=__codelineno-35-1></a><a href=#__codelineno-35-1><span class=linenos data-linenos="1 "></span></a><span class=kn>from</span><span class=w> </span><span class=nn>transformers</span><span class=w> </span><span class=kn>import</span> <span class=n>pipeline</span>
</span><span id=__span-35-2><a id=__codelineno-35-2 name=__codelineno-35-2></a><a href=#__codelineno-35-2><span class=linenos data-linenos="2 "></span></a>
</span><span id=__span-35-3><a id=__codelineno-35-3 name=__codelineno-35-3></a><a href=#__codelineno-35-3><span class=linenos data-linenos="3 "></span></a><span class=n>pipe</span> <span class=o>=</span> <span class=n>pipeline</span><span class=p>(</span><span class=s2>&quot;image-classification&quot;</span><span class=p>,</span> <span class=s2>&quot;nielsr/convnext-tiny-224-finetuned-eurosat-albumentations&quot;</span><span class=p>)</span>
</span></code></pre></div> <div class=codehilite><pre><span></span><code><span class=n>loading</span><span class=w> </span><span class=n>configuration</span><span class=w> </span><span class=n>file</span><span class=w> </span><span class=n>https</span><span class=p>:</span><span class=o>//</span><span class=n>huggingface</span><span class=o>.</span><span class=n>co</span><span class=o>/</span><span class=n>nielsr</span><span class=o>/</span><span class=n>convnext</span><span class=o>-</span><span class=n>tiny</span><span class=o>-</span><span class=mi>224</span><span class=o>-</span><span class=n>finetuned</span><span class=o>-</span><span class=n>eurosat</span><span class=o>-</span><span class=n>albumentations</span><span class=o>/</span><span class=n>resolve</span><span class=o>/</span><span class=n>main</span><span class=o>/</span><span class=n>config</span><span class=o>.</span><span class=n>json</span><span class=w> </span><span class=n>from</span><span class=w> </span><span class=n>cache</span><span class=w> </span><span class=n>at</span><span class=w> </span><span class=o>/</span><span class=n>root</span><span class=o>/.</span><span class=n>cache</span><span class=o>/</span><span class=n>huggingface</span><span class=o>/</span><span class=n>transformers</span><span class=o>/</span><span class=mi>25088566</span><span class=n>ab29cf0ff360b05880b5f20cdc0c79ab995056a1fb4f98212d021154</span><span class=o>.</span><span class=mi>4637</span><span class=n>c3f271a8dfbcfe5c4ee777270112d841a5af95814f0fd086c3c2761e7370</span>
<span class=n>Model</span><span class=w> </span><span class=n>config</span><span class=w> </span><span class=n>ConvNextConfig</span><span class=w> </span><span class=p>{</span>
<span class=w>  </span><span class=s2>&quot;_name_or_path&quot;</span><span class=p>:</span><span class=w> </span><span class=s2>&quot;nielsr/convnext-tiny-224-finetuned-eurosat-albumentations&quot;</span><span class=p>,</span>
<span class=w>  </span><span class=s2>&quot;architectures&quot;</span><span class=p>:</span><span class=w> </span><span class=p>[</span>
<span class=w>    </span><span class=s2>&quot;ConvNextForImageClassification&quot;</span>
<span class=w>  </span><span class=p>],</span>
<span class=w>  </span><span class=s2>&quot;depths&quot;</span><span class=p>:</span><span class=w> </span><span class=p>[</span>
<span class=w>    </span><span class=mi>3</span><span class=p>,</span>
<span class=w>    </span><span class=mi>3</span><span class=p>,</span>
<span class=w>    </span><span class=mi>9</span><span class=p>,</span>
<span class=w>    </span><span class=mi>3</span>
<span class=w>  </span><span class=p>],</span>
<span class=w>  </span><span class=s2>&quot;drop_path_rate&quot;</span><span class=p>:</span><span class=w> </span><span class=mf>0.0</span><span class=p>,</span>
<span class=w>  </span><span class=s2>&quot;hidden_act&quot;</span><span class=p>:</span><span class=w> </span><span class=s2>&quot;gelu&quot;</span><span class=p>,</span>
<span class=w>  </span><span class=s2>&quot;hidden_sizes&quot;</span><span class=p>:</span><span class=w> </span><span class=p>[</span>
<span class=w>    </span><span class=mi>96</span><span class=p>,</span>
<span class=w>    </span><span class=mi>192</span><span class=p>,</span>
<span class=w>    </span><span class=mi>384</span><span class=p>,</span>
<span class=w>    </span><span class=mi>768</span>
<span class=w>  </span><span class=p>],</span>
<span class=w>  </span><span class=s2>&quot;id2label&quot;</span><span class=p>:</span><span class=w> </span><span class=p>{</span>
<span class=w>    </span><span class=s2>&quot;0&quot;</span><span class=p>:</span><span class=w> </span><span class=s2>&quot;AnnualCrop&quot;</span><span class=p>,</span>
<span class=w>    </span><span class=s2>&quot;1&quot;</span><span class=p>:</span><span class=w> </span><span class=s2>&quot;Forest&quot;</span><span class=p>,</span>
<span class=w>    </span><span class=s2>&quot;2&quot;</span><span class=p>:</span><span class=w> </span><span class=s2>&quot;HerbaceousVegetation&quot;</span><span class=p>,</span>
<span class=w>    </span><span class=s2>&quot;3&quot;</span><span class=p>:</span><span class=w> </span><span class=s2>&quot;Highway&quot;</span><span class=p>,</span>
<span class=w>    </span><span class=s2>&quot;4&quot;</span><span class=p>:</span><span class=w> </span><span class=s2>&quot;Industrial&quot;</span><span class=p>,</span>
<span class=w>    </span><span class=s2>&quot;5&quot;</span><span class=p>:</span><span class=w> </span><span class=s2>&quot;Pasture&quot;</span><span class=p>,</span>
<span class=w>    </span><span class=s2>&quot;6&quot;</span><span class=p>:</span><span class=w> </span><span class=s2>&quot;PermanentCrop&quot;</span><span class=p>,</span>
<span class=w>    </span><span class=s2>&quot;7&quot;</span><span class=p>:</span><span class=w> </span><span class=s2>&quot;Residential&quot;</span><span class=p>,</span>
<span class=w>    </span><span class=s2>&quot;8&quot;</span><span class=p>:</span><span class=w> </span><span class=s2>&quot;River&quot;</span><span class=p>,</span>
<span class=w>    </span><span class=s2>&quot;9&quot;</span><span class=p>:</span><span class=w> </span><span class=s2>&quot;SeaLake&quot;</span>
<span class=w>  </span><span class=p>},</span>
<span class=w>  </span><span class=s2>&quot;image_size&quot;</span><span class=p>:</span><span class=w> </span><span class=mi>224</span><span class=p>,</span>
<span class=w>  </span><span class=s2>&quot;initializer_range&quot;</span><span class=p>:</span><span class=w> </span><span class=mf>0.02</span><span class=p>,</span>
<span class=w>  </span><span class=s2>&quot;label2id&quot;</span><span class=p>:</span><span class=w> </span><span class=p>{</span>
<span class=w>    </span><span class=s2>&quot;AnnualCrop&quot;</span><span class=p>:</span><span class=w> </span><span class=mi>0</span><span class=p>,</span>
<span class=w>    </span><span class=s2>&quot;Forest&quot;</span><span class=p>:</span><span class=w> </span><span class=mi>1</span><span class=p>,</span>
<span class=w>    </span><span class=s2>&quot;HerbaceousVegetation&quot;</span><span class=p>:</span><span class=w> </span><span class=mi>2</span><span class=p>,</span>
<span class=w>    </span><span class=s2>&quot;Highway&quot;</span><span class=p>:</span><span class=w> </span><span class=mi>3</span><span class=p>,</span>
<span class=w>    </span><span class=s2>&quot;Industrial&quot;</span><span class=p>:</span><span class=w> </span><span class=mi>4</span><span class=p>,</span>
<span class=w>    </span><span class=s2>&quot;Pasture&quot;</span><span class=p>:</span><span class=w> </span><span class=mi>5</span><span class=p>,</span>
<span class=w>    </span><span class=s2>&quot;PermanentCrop&quot;</span><span class=p>:</span><span class=w> </span><span class=mi>6</span><span class=p>,</span>
<span class=w>    </span><span class=s2>&quot;Residential&quot;</span><span class=p>:</span><span class=w> </span><span class=mi>7</span><span class=p>,</span>
<span class=w>    </span><span class=s2>&quot;River&quot;</span><span class=p>:</span><span class=w> </span><span class=mi>8</span><span class=p>,</span>
<span class=w>    </span><span class=s2>&quot;SeaLake&quot;</span><span class=p>:</span><span class=w> </span><span class=mi>9</span>
<span class=w>  </span><span class=p>},</span>
<span class=w>  </span><span class=s2>&quot;layer_norm_eps&quot;</span><span class=p>:</span><span class=w> </span><span class=mf>1e-12</span><span class=p>,</span>
<span class=w>  </span><span class=s2>&quot;layer_scale_init_value&quot;</span><span class=p>:</span><span class=w> </span><span class=mf>1e-06</span><span class=p>,</span>
<span class=w>  </span><span class=s2>&quot;model_type&quot;</span><span class=p>:</span><span class=w> </span><span class=s2>&quot;convnext&quot;</span><span class=p>,</span>
<span class=w>  </span><span class=s2>&quot;num_channels&quot;</span><span class=p>:</span><span class=w> </span><span class=mi>3</span><span class=p>,</span>
<span class=w>  </span><span class=s2>&quot;num_stages&quot;</span><span class=p>:</span><span class=w> </span><span class=mi>4</span><span class=p>,</span>
<span class=w>  </span><span class=s2>&quot;patch_size&quot;</span><span class=p>:</span><span class=w> </span><span class=mi>4</span><span class=p>,</span>
<span class=w>  </span><span class=s2>&quot;problem_type&quot;</span><span class=p>:</span><span class=w> </span><span class=s2>&quot;single_label_classification&quot;</span><span class=p>,</span>
<span class=w>  </span><span class=s2>&quot;torch_dtype&quot;</span><span class=p>:</span><span class=w> </span><span class=s2>&quot;float32&quot;</span><span class=p>,</span>
<span class=w>  </span><span class=s2>&quot;transformers_version&quot;</span><span class=p>:</span><span class=w> </span><span class=s2>&quot;4.18.0&quot;</span>
<span class=p>}</span>

<span class=n>loading</span><span class=w> </span><span class=n>configuration</span><span class=w> </span><span class=n>file</span><span class=w> </span><span class=n>https</span><span class=p>:</span><span class=o>//</span><span class=n>huggingface</span><span class=o>.</span><span class=n>co</span><span class=o>/</span><span class=n>nielsr</span><span class=o>/</span><span class=n>convnext</span><span class=o>-</span><span class=n>tiny</span><span class=o>-</span><span class=mi>224</span><span class=o>-</span><span class=n>finetuned</span><span class=o>-</span><span class=n>eurosat</span><span class=o>-</span><span class=n>albumentations</span><span class=o>/</span><span class=n>resolve</span><span class=o>/</span><span class=n>main</span><span class=o>/</span><span class=n>config</span><span class=o>.</span><span class=n>json</span><span class=w> </span><span class=n>from</span><span class=w> </span><span class=n>cache</span><span class=w> </span><span class=n>at</span><span class=w> </span><span class=o>/</span><span class=n>root</span><span class=o>/.</span><span class=n>cache</span><span class=o>/</span><span class=n>huggingface</span><span class=o>/</span><span class=n>transformers</span><span class=o>/</span><span class=mi>25088566</span><span class=n>ab29cf0ff360b05880b5f20cdc0c79ab995056a1fb4f98212d021154</span><span class=o>.</span><span class=mi>4637</span><span class=n>c3f271a8dfbcfe5c4ee777270112d841a5af95814f0fd086c3c2761e7370</span>
<span class=n>Model</span><span class=w> </span><span class=n>config</span><span class=w> </span><span class=n>ConvNextConfig</span><span class=w> </span><span class=p>{</span>
<span class=w>  </span><span class=s2>&quot;_name_or_path&quot;</span><span class=p>:</span><span class=w> </span><span class=s2>&quot;nielsr/convnext-tiny-224-finetuned-eurosat-albumentations&quot;</span><span class=p>,</span>
<span class=w>  </span><span class=s2>&quot;architectures&quot;</span><span class=p>:</span><span class=w> </span><span class=p>[</span>
<span class=w>    </span><span class=s2>&quot;ConvNextForImageClassification&quot;</span>
<span class=w>  </span><span class=p>],</span>
<span class=w>  </span><span class=s2>&quot;depths&quot;</span><span class=p>:</span><span class=w> </span><span class=p>[</span>
<span class=w>    </span><span class=mi>3</span><span class=p>,</span>
<span class=w>    </span><span class=mi>3</span><span class=p>,</span>
<span class=w>    </span><span class=mi>9</span><span class=p>,</span>
<span class=w>    </span><span class=mi>3</span>
<span class=w>  </span><span class=p>],</span>
<span class=w>  </span><span class=s2>&quot;drop_path_rate&quot;</span><span class=p>:</span><span class=w> </span><span class=mf>0.0</span><span class=p>,</span>
<span class=w>  </span><span class=s2>&quot;hidden_act&quot;</span><span class=p>:</span><span class=w> </span><span class=s2>&quot;gelu&quot;</span><span class=p>,</span>
<span class=w>  </span><span class=s2>&quot;hidden_sizes&quot;</span><span class=p>:</span><span class=w> </span><span class=p>[</span>
<span class=w>    </span><span class=mi>96</span><span class=p>,</span>
<span class=w>    </span><span class=mi>192</span><span class=p>,</span>
<span class=w>    </span><span class=mi>384</span><span class=p>,</span>
<span class=w>    </span><span class=mi>768</span>
<span class=w>  </span><span class=p>],</span>
<span class=w>  </span><span class=s2>&quot;id2label&quot;</span><span class=p>:</span><span class=w> </span><span class=p>{</span>
<span class=w>    </span><span class=s2>&quot;0&quot;</span><span class=p>:</span><span class=w> </span><span class=s2>&quot;AnnualCrop&quot;</span><span class=p>,</span>
<span class=w>    </span><span class=s2>&quot;1&quot;</span><span class=p>:</span><span class=w> </span><span class=s2>&quot;Forest&quot;</span><span class=p>,</span>
<span class=w>    </span><span class=s2>&quot;2&quot;</span><span class=p>:</span><span class=w> </span><span class=s2>&quot;HerbaceousVegetation&quot;</span><span class=p>,</span>
<span class=w>    </span><span class=s2>&quot;3&quot;</span><span class=p>:</span><span class=w> </span><span class=s2>&quot;Highway&quot;</span><span class=p>,</span>
<span class=w>    </span><span class=s2>&quot;4&quot;</span><span class=p>:</span><span class=w> </span><span class=s2>&quot;Industrial&quot;</span><span class=p>,</span>
<span class=w>    </span><span class=s2>&quot;5&quot;</span><span class=p>:</span><span class=w> </span><span class=s2>&quot;Pasture&quot;</span><span class=p>,</span>
<span class=w>    </span><span class=s2>&quot;6&quot;</span><span class=p>:</span><span class=w> </span><span class=s2>&quot;PermanentCrop&quot;</span><span class=p>,</span>
<span class=w>    </span><span class=s2>&quot;7&quot;</span><span class=p>:</span><span class=w> </span><span class=s2>&quot;Residential&quot;</span><span class=p>,</span>
<span class=w>    </span><span class=s2>&quot;8&quot;</span><span class=p>:</span><span class=w> </span><span class=s2>&quot;River&quot;</span><span class=p>,</span>
<span class=w>    </span><span class=s2>&quot;9&quot;</span><span class=p>:</span><span class=w> </span><span class=s2>&quot;SeaLake&quot;</span>
<span class=w>  </span><span class=p>},</span>
<span class=w>  </span><span class=s2>&quot;image_size&quot;</span><span class=p>:</span><span class=w> </span><span class=mi>224</span><span class=p>,</span>
<span class=w>  </span><span class=s2>&quot;initializer_range&quot;</span><span class=p>:</span><span class=w> </span><span class=mf>0.02</span><span class=p>,</span>
<span class=w>  </span><span class=s2>&quot;label2id&quot;</span><span class=p>:</span><span class=w> </span><span class=p>{</span>
<span class=w>    </span><span class=s2>&quot;AnnualCrop&quot;</span><span class=p>:</span><span class=w> </span><span class=mi>0</span><span class=p>,</span>
<span class=w>    </span><span class=s2>&quot;Forest&quot;</span><span class=p>:</span><span class=w> </span><span class=mi>1</span><span class=p>,</span>
<span class=w>    </span><span class=s2>&quot;HerbaceousVegetation&quot;</span><span class=p>:</span><span class=w> </span><span class=mi>2</span><span class=p>,</span>
<span class=w>    </span><span class=s2>&quot;Highway&quot;</span><span class=p>:</span><span class=w> </span><span class=mi>3</span><span class=p>,</span>
<span class=w>    </span><span class=s2>&quot;Industrial&quot;</span><span class=p>:</span><span class=w> </span><span class=mi>4</span><span class=p>,</span>
<span class=w>    </span><span class=s2>&quot;Pasture&quot;</span><span class=p>:</span><span class=w> </span><span class=mi>5</span><span class=p>,</span>
<span class=w>    </span><span class=s2>&quot;PermanentCrop&quot;</span><span class=p>:</span><span class=w> </span><span class=mi>6</span><span class=p>,</span>
<span class=w>    </span><span class=s2>&quot;Residential&quot;</span><span class=p>:</span><span class=w> </span><span class=mi>7</span><span class=p>,</span>
<span class=w>    </span><span class=s2>&quot;River&quot;</span><span class=p>:</span><span class=w> </span><span class=mi>8</span><span class=p>,</span>
<span class=w>    </span><span class=s2>&quot;SeaLake&quot;</span><span class=p>:</span><span class=w> </span><span class=mi>9</span>
<span class=w>  </span><span class=p>},</span>
<span class=w>  </span><span class=s2>&quot;layer_norm_eps&quot;</span><span class=p>:</span><span class=w> </span><span class=mf>1e-12</span><span class=p>,</span>
<span class=w>  </span><span class=s2>&quot;layer_scale_init_value&quot;</span><span class=p>:</span><span class=w> </span><span class=mf>1e-06</span><span class=p>,</span>
<span class=w>  </span><span class=s2>&quot;model_type&quot;</span><span class=p>:</span><span class=w> </span><span class=s2>&quot;convnext&quot;</span><span class=p>,</span>
<span class=w>  </span><span class=s2>&quot;num_channels&quot;</span><span class=p>:</span><span class=w> </span><span class=mi>3</span><span class=p>,</span>
<span class=w>  </span><span class=s2>&quot;num_stages&quot;</span><span class=p>:</span><span class=w> </span><span class=mi>4</span><span class=p>,</span>
<span class=w>  </span><span class=s2>&quot;patch_size&quot;</span><span class=p>:</span><span class=w> </span><span class=mi>4</span><span class=p>,</span>
<span class=w>  </span><span class=s2>&quot;problem_type&quot;</span><span class=p>:</span><span class=w> </span><span class=s2>&quot;single_label_classification&quot;</span><span class=p>,</span>
<span class=w>  </span><span class=s2>&quot;torch_dtype&quot;</span><span class=p>:</span><span class=w> </span><span class=s2>&quot;float32&quot;</span><span class=p>,</span>
<span class=w>  </span><span class=s2>&quot;transformers_version&quot;</span><span class=p>:</span><span class=w> </span><span class=s2>&quot;4.18.0&quot;</span>
<span class=p>}</span>

<span class=n>loading</span><span class=w> </span><span class=n>weights</span><span class=w> </span><span class=n>file</span><span class=w> </span><span class=n>https</span><span class=p>:</span><span class=o>//</span><span class=n>huggingface</span><span class=o>.</span><span class=n>co</span><span class=o>/</span><span class=n>nielsr</span><span class=o>/</span><span class=n>convnext</span><span class=o>-</span><span class=n>tiny</span><span class=o>-</span><span class=mi>224</span><span class=o>-</span><span class=n>finetuned</span><span class=o>-</span><span class=n>eurosat</span><span class=o>-</span><span class=n>albumentations</span><span class=o>/</span><span class=n>resolve</span><span class=o>/</span><span class=n>main</span><span class=o>/</span><span class=n>pytorch_model</span><span class=o>.</span><span class=n>bin</span><span class=w> </span><span class=n>from</span><span class=w> </span><span class=n>cache</span><span class=w> </span><span class=n>at</span><span class=w> </span><span class=o>/</span><span class=n>root</span><span class=o>/.</span><span class=n>cache</span><span class=o>/</span><span class=n>huggingface</span><span class=o>/</span><span class=n>transformers</span><span class=o>/</span><span class=mi>3</span><span class=n>f4bcce35d3279d19b07fb762859d89bce636d8f0235685031ef6494800b9769</span><span class=o>.</span><span class=n>d611c768c0b0939188b05c3d505f0b36c97aa57649d4637e3384992d3c5c0b89</span>
<span class=n>All</span><span class=w> </span><span class=n>model</span><span class=w> </span><span class=n>checkpoint</span><span class=w> </span><span class=n>weights</span><span class=w> </span><span class=n>were</span><span class=w> </span><span class=n>used</span><span class=w> </span><span class=n>when</span><span class=w> </span><span class=n>initializing</span><span class=w> </span><span class=n>ConvNextForImageClassification</span><span class=o>.</span>

<span class=n>All</span><span class=w> </span><span class=n>the</span><span class=w> </span><span class=n>weights</span><span class=w> </span><span class=n>of</span><span class=w> </span><span class=n>ConvNextForImageClassification</span><span class=w> </span><span class=n>were</span><span class=w> </span><span class=n>initialized</span><span class=w> </span><span class=n>from</span><span class=w> </span><span class=n>the</span><span class=w> </span><span class=n>model</span><span class=w> </span><span class=n>checkpoint</span><span class=w> </span><span class=n>at</span><span class=w> </span><span class=n>nielsr</span><span class=o>/</span><span class=n>convnext</span><span class=o>-</span><span class=n>tiny</span><span class=o>-</span><span class=mi>224</span><span class=o>-</span><span class=n>finetuned</span><span class=o>-</span><span class=n>eurosat</span><span class=o>-</span><span class=n>albumentations</span><span class=o>.</span>
<span class=n>If</span><span class=w> </span><span class=n>your</span><span class=w> </span><span class=n>task</span><span class=w> </span><span class=k>is</span><span class=w> </span><span class=n>similar</span><span class=w> </span><span class=n>to</span><span class=w> </span><span class=n>the</span><span class=w> </span><span class=n>task</span><span class=w> </span><span class=n>the</span><span class=w> </span><span class=n>model</span><span class=w> </span><span class=n>of</span><span class=w> </span><span class=n>the</span><span class=w> </span><span class=n>checkpoint</span><span class=w> </span><span class=n>was</span><span class=w> </span><span class=n>trained</span><span class=w> </span><span class=n>on</span><span class=p>,</span><span class=w> </span><span class=n>you</span><span class=w> </span><span class=n>can</span><span class=w> </span><span class=n>already</span><span class=w> </span><span class=n>use</span><span class=w> </span><span class=n>ConvNextForImageClassification</span><span class=w> </span><span class=k>for</span><span class=w> </span><span class=n>predictions</span><span class=w> </span><span class=n>without</span><span class=w> </span><span class=n>further</span><span class=w> </span><span class=n>training</span><span class=o>.</span>
<span class=n>loading</span><span class=w> </span><span class=n>feature</span><span class=w> </span><span class=n>extractor</span><span class=w> </span><span class=n>configuration</span><span class=w> </span><span class=n>file</span><span class=w> </span><span class=n>https</span><span class=p>:</span><span class=o>//</span><span class=n>huggingface</span><span class=o>.</span><span class=n>co</span><span class=o>/</span><span class=n>nielsr</span><span class=o>/</span><span class=n>convnext</span><span class=o>-</span><span class=n>tiny</span><span class=o>-</span><span class=mi>224</span><span class=o>-</span><span class=n>finetuned</span><span class=o>-</span><span class=n>eurosat</span><span class=o>-</span><span class=n>albumentations</span><span class=o>/</span><span class=n>resolve</span><span class=o>/</span><span class=n>main</span><span class=o>/</span><span class=n>preprocessor_config</span><span class=o>.</span><span class=n>json</span><span class=w> </span><span class=n>from</span><span class=w> </span><span class=n>cache</span><span class=w> </span><span class=n>at</span><span class=w> </span><span class=o>/</span><span class=n>root</span><span class=o>/.</span><span class=n>cache</span><span class=o>/</span><span class=n>huggingface</span><span class=o>/</span><span class=n>transformers</span><span class=o>/</span><span class=mi>38</span><span class=n>b41a2c904b6ce5bb10403bf902ee4263144d862c5a602c83cd120c0c1ba0e6</span><span class=o>.</span><span class=mi>37</span><span class=n>be7274d6b5860aee104bb1fbaeb0722fec3850a85bb2557ae9491f17f89433</span>
<span class=n>Feature</span><span class=w> </span><span class=n>extractor</span><span class=w> </span><span class=n>ConvNextFeatureExtractor</span><span class=w> </span><span class=p>{</span>
<span class=w>  </span><span class=s2>&quot;crop_pct&quot;</span><span class=p>:</span><span class=w> </span><span class=mf>0.875</span><span class=p>,</span>
<span class=w>  </span><span class=s2>&quot;do_normalize&quot;</span><span class=p>:</span><span class=w> </span><span class=bp>true</span><span class=p>,</span>
<span class=w>  </span><span class=s2>&quot;do_resize&quot;</span><span class=p>:</span><span class=w> </span><span class=bp>true</span><span class=p>,</span>
<span class=w>  </span><span class=s2>&quot;feature_extractor_type&quot;</span><span class=p>:</span><span class=w> </span><span class=s2>&quot;ConvNextFeatureExtractor&quot;</span><span class=p>,</span>
<span class=w>  </span><span class=s2>&quot;image_mean&quot;</span><span class=p>:</span><span class=w> </span><span class=p>[</span>
<span class=w>    </span><span class=mf>0.485</span><span class=p>,</span>
<span class=w>    </span><span class=mf>0.456</span><span class=p>,</span>
<span class=w>    </span><span class=mf>0.406</span>
<span class=w>  </span><span class=p>],</span>
<span class=w>  </span><span class=s2>&quot;image_std&quot;</span><span class=p>:</span><span class=w> </span><span class=p>[</span>
<span class=w>    </span><span class=mf>0.229</span><span class=p>,</span>
<span class=w>    </span><span class=mf>0.224</span><span class=p>,</span>
<span class=w>    </span><span class=mf>0.225</span>
<span class=w>  </span><span class=p>],</span>
<span class=w>  </span><span class=s2>&quot;resample&quot;</span><span class=p>:</span><span class=w> </span><span class=mi>3</span><span class=p>,</span>
<span class=w>  </span><span class=s2>&quot;size&quot;</span><span class=p>:</span><span class=w> </span><span class=mi>224</span>
<span class=p>}</span>
</code></pre></div> <div class="language-python highlight"><span class=filename>Python</span><pre><span></span><code><span id=__span-36-1><a id=__codelineno-36-1 name=__codelineno-36-1></a><a href=#__codelineno-36-1><span class=linenos data-linenos="1 "></span></a><span class=n>pipe</span><span class=p>(</span><span class=n>image</span><span class=p>)</span>
</span></code></pre></div> <div class=codehilite><pre><span></span><code>[{&#39;label&#39;: &#39;Highway&#39;, &#39;score&#39;: 0.5163754224777222},
 {&#39;label&#39;: &#39;River&#39;, &#39;score&#39;: 0.11824000626802444},
 {&#39;label&#39;: &#39;AnnualCrop&#39;, &#39;score&#39;: 0.05467210337519646},
 {&#39;label&#39;: &#39;PermanentCrop&#39;, &#39;score&#39;: 0.05066365748643875},
 {&#39;label&#39;: &#39;Industrial&#39;, &#39;score&#39;: 0.049283623695373535}]
</code></pre></div> <p>As we can see, it does not only show the class label with the highest probability, but does return the top 5 labels, with their corresponding scores. Note that the pipelines also work with local models and image_processor:</p> <div class="language-python highlight"><span class=filename>Python</span><pre><span></span><code><span id=__span-37-1><a id=__codelineno-37-1 name=__codelineno-37-1></a><a href=#__codelineno-37-1><span class=linenos data-linenos="1 "></span></a><span class=n>pipe</span> <span class=o>=</span> <span class=n>pipeline</span><span class=p>(</span><span class=s2>&quot;image-classification&quot;</span><span class=p>,</span> 
</span><span id=__span-37-2><a id=__codelineno-37-2 name=__codelineno-37-2></a><a href=#__codelineno-37-2><span class=linenos data-linenos="2 "></span></a>                <span class=n>model</span><span class=o>=</span><span class=n>model</span><span class=p>,</span>
</span><span id=__span-37-3><a id=__codelineno-37-3 name=__codelineno-37-3></a><a href=#__codelineno-37-3><span class=linenos data-linenos="3 "></span></a>                <span class=n>feature_extractor</span><span class=o>=</span><span class=n>image_processor</span><span class=p>)</span>
</span></code></pre></div> <div class="language-python highlight"><span class=filename>Python</span><pre><span></span><code><span id=__span-38-1><a id=__codelineno-38-1 name=__codelineno-38-1></a><a href=#__codelineno-38-1><span class=linenos data-linenos="1 "></span></a><span class=n>pipe</span><span class=p>(</span><span class=n>image</span><span class=p>)</span>
</span></code></pre></div> <div class=codehilite><pre><span></span><code>[{&#39;label&#39;: &#39;Highway&#39;, &#39;score&#39;: 0.5163754224777222},
 {&#39;label&#39;: &#39;River&#39;, &#39;score&#39;: 0.11824000626802444},
 {&#39;label&#39;: &#39;AnnualCrop&#39;, &#39;score&#39;: 0.05467210337519646},
 {&#39;label&#39;: &#39;PermanentCrop&#39;, &#39;score&#39;: 0.05066365748643875},
 {&#39;label&#39;: &#39;Industrial&#39;, &#39;score&#39;: 0.049283623695373535}]
</code></pre></div> <div class="language-python highlight"><span class=filename>Python</span><pre><span></span><code><span id=__span-39-1><a id=__codelineno-39-1 name=__codelineno-39-1></a><a href=#__codelineno-39-1><span class=linenos data-linenos="1 "></span></a>
</span></code></pre></div> </article> </div> <script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script> </div> <button type=button class="md-top md-icon" data-md-component=top hidden> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8z"/></svg> Back to top </button> </main> <footer class=md-footer> <nav class="md-footer__inner md-grid" aria-label=Footer> <a href=../ class="md-footer__link md-footer__link--prev" aria-label="Previous: Home"> <div class="md-footer__button md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg> </div> <div class=md-footer__title> <span class=md-footer__direction> Previous </span> <div class=md-ellipsis> Home </div> </div> </a> <a href=../object_detection/ class="md-footer__link md-footer__link--next" aria-label="Next: Object Detection"> <div class=md-footer__title> <span class=md-footer__direction> Next </span> <div class=md-ellipsis> Object Detection </div> </div> <div class="md-footer__button md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M4 11v2h12l-5.5 5.5 1.42 1.42L19.84 12l-7.92-7.92L10.5 5.5 16 11z"/></svg> </div> </a> </nav> <div class="md-footer-meta md-typeset"> <div class="md-footer-meta__inner md-grid"> <div class=md-copyright> </div> <div class=md-social> <a href=https://twitter.com/albumentations target=_blank rel=noopener title=twitter.com class=md-social__link> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 512 512"><!-- Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M389.2 48h70.6L305.6 224.2 487 464H345L233.7 318.6 106.5 464H35.8l164.9-188.5L26.8 48h145.6l100.5 132.9zm-24.8 373.8h39.1L151.1 88h-42z"/></svg> </a> <a href=https://www.linkedin.com/company/100504475/ target=_blank rel=noopener title=www.linkedin.com class=md-social__link> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 448 512"><!-- Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M416 32H31.9C14.3 32 0 46.5 0 64.3v383.4C0 465.5 14.3 480 31.9 480H416c17.6 0 32-14.5 32-32.3V64.3c0-17.8-14.4-32.3-32-32.3M135.4 416H69V202.2h66.5V416zm-33.2-243c-21.3 0-38.5-17.3-38.5-38.5S80.9 96 102.2 96c21.2 0 38.5 17.3 38.5 38.5 0 21.3-17.2 38.5-38.5 38.5m282.1 243h-66.4V312c0-24.8-.5-56.7-34.5-56.7-34.6 0-39.9 27-39.9 54.9V416h-66.4V202.2h63.7v29.2h.9c8.9-16.8 30.6-34.5 62.9-34.5 67.2 0 79.7 44.3 79.7 101.9z"/></svg> </a> <a href=https://discord.com/invite/AKPrrDYNAt target=_blank rel=noopener title=discord.com class=md-social__link> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 640 512"><!-- Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M524.531 69.836a1.5 1.5 0 0 0-.764-.7A485 485 0 0 0 404.081 32.03a1.82 1.82 0 0 0-1.923.91 338 338 0 0 0-14.9 30.6 447.9 447.9 0 0 0-134.426 0 310 310 0 0 0-15.135-30.6 1.89 1.89 0 0 0-1.924-.91 483.7 483.7 0 0 0-119.688 37.107 1.7 1.7 0 0 0-.788.676C39.068 183.651 18.186 294.69 28.43 404.354a2.02 2.02 0 0 0 .765 1.375 487.7 487.7 0 0 0 146.825 74.189 1.9 1.9 0 0 0 2.063-.676A348 348 0 0 0 208.12 430.4a1.86 1.86 0 0 0-1.019-2.588 321 321 0 0 1-45.868-21.853 1.885 1.885 0 0 1-.185-3.126 251 251 0 0 0 9.109-7.137 1.82 1.82 0 0 1 1.9-.256c96.229 43.917 200.41 43.917 295.5 0a1.81 1.81 0 0 1 1.924.233 235 235 0 0 0 9.132 7.16 1.884 1.884 0 0 1-.162 3.126 301.4 301.4 0 0 1-45.89 21.83 1.875 1.875 0 0 0-1 2.611 391 391 0 0 0 30.014 48.815 1.86 1.86 0 0 0 2.063.7A486 486 0 0 0 610.7 405.729a1.88 1.88 0 0 0 .765-1.352c12.264-126.783-20.532-236.912-86.934-334.541M222.491 337.58c-28.972 0-52.844-26.587-52.844-59.239s23.409-59.241 52.844-59.241c29.665 0 53.306 26.82 52.843 59.239 0 32.654-23.41 59.241-52.843 59.241m195.38 0c-28.971 0-52.843-26.587-52.843-59.239s23.409-59.241 52.843-59.241c29.667 0 53.307 26.82 52.844 59.239 0 32.654-23.177 59.241-52.844 59.241"/></svg> </a> </div> </div> </div> </footer> </div> <div class=md-dialog data-md-component=dialog> <div class="md-dialog__inner md-typeset"></div> </div> <script id=__config type=application/json>{"base": "../../..", "features": ["navigation.sections", "navigation.indexes", "navigation.top", "navigation.footer", "navigation.path", "navigation.prune", "search.suggest", "search.highlight", "search.share", "toc.follow", "toc.integrate"], "search": "../../../assets/javascripts/workers/search.f8cc74c7.min.js", "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}}</script> <script src=../../../assets/javascripts/bundle.f1b6f286.min.js></script> <script src=https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js></script> <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/3.2.2/MathJax.js?config=TeX-MML-AM_CHTML"></script> <script src=../../../js/extra.js></script> </body> </html>