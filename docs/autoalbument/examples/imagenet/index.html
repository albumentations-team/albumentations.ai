
<!DOCTYPE html>

<html class="no-js" lang="en">
<head>
<meta charset="utf-8"/>
<meta content="width=device-width,initial-scale=1" name="viewport"/>
<meta content="Albumentations: fast and flexible image augmentations" name="description"/>
<link href="https://albumentations.ai/docs/autoalbument/examples/imagenet/" rel="canonical"/>
<link href="../../../images/logo.png" rel="shortcut icon"/>
<meta content="mkdocs-1.1.2, mkdocs-material-5.5.0" name="generator"/>
<title>Image classification on the ImageNet dataset - Albumentations Documentation</title>
<link href="../../../assets/stylesheets/main.b5d04df8.min.css" rel="stylesheet"/>
<link href="../../../assets/stylesheets/palette.9ab2c1f8.min.css" rel="stylesheet"/>
<meta content="" name="theme-color"/>
<link crossorigin="" href="https://fonts.gstatic.com" rel="preconnect"/>
<link href="https://fonts.googleapis.com/css?family=Roboto:300,400,400i,700%7CRoboto+Mono&amp;display=fallback" rel="stylesheet"/>
<style>body,input{font-family:"Roboto",-apple-system,BlinkMacSystemFont,Helvetica,Arial,sans-serif}code,kbd,pre{font-family:"Roboto Mono",SFMono-Regular,Consolas,Menlo,monospace}</style>
<link href="https://cdn.jsdelivr.net/npm/docsearch.js@2/dist/cdn/docsearch.min.css" rel="stylesheet"/>
<link href="../../../css/extra.css" rel="stylesheet"/>
<link href="../../../css/ansi-colours.css" rel="stylesheet"/>
<script>window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)},ga.l=+new Date,ga("create","UA-158065353-1","auto"),ga("set","anonymizeIp",!0),ga("send","pageview"),document.addEventListener("DOMContentLoaded",function(){document.forms.search&&document.forms.search.query.addEventListener("blur",function(){if(this.value){var e=document.location.pathname;ga("send","pageview",e+"?q="+this.value)}})}),document.addEventListener("DOMContentSwitch",function(){ga("send","pageview",document.location.pathname)})</script>
<script async="" src="https://www.google-analytics.com/analytics.js"></script>
<meta content="website" property="og:type"/>
<meta content="Albumentations Documentation - Image classification on the ImageNet dataset" property="og:title"/>
<meta content="Albumentations: fast and flexible image augmentations" property="og:description"/>
<meta content="https://albumentations.ai/docs/autoalbument/examples/imagenet/" property="og:url"/>
<meta content="https://albumentations.ai/docs/images/albumentations_card.png" property="og:image"/>
<meta content="image/png" property="og:image:type"/>
<meta content="summary_large_image" name="twitter:card"/>
<meta content="Albumentations Documentation - Image classification on the ImageNet dataset" name="twitter:title"/>
<meta content="Albumentations: fast and flexible image augmentations" name="twitter:description"/>
<meta content="https://albumentations.ai/docs/images/albumentations_card.png" name="twitter:image"/>
</head>
<body data-md-color-accent="white" data-md-color-primary="white" data-md-color-scheme="" dir="ltr">
<input autocomplete="off" class="md-toggle" data-md-toggle="drawer" id="__drawer" type="checkbox"/>
<input autocomplete="off" class="md-toggle" data-md-toggle="search" id="__search" type="checkbox"/>
<label class="md-overlay" for="__drawer"></label>
<div data-md-component="skip">
<a class="md-skip" href="#image-classification-on-the-imagenet-dataset">
          Skip to content
        </a>
</div>
<div data-md-component="announce">
</div>
<header class="md-header" data-md-component="header">
<nav aria-label="Header" class="md-header-nav md-grid">
<a aria-label="Albumentations Documentation" class="md-header-nav__button md-logo" href="https://albumentations.ai" title="Albumentations Documentation">
<img alt="logo" src="../../../images/logo.png"/>
</a>
<label class="md-header-nav__button md-icon" for="__drawer">
<svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M3 6h18v2H3V6m0 5h18v2H3v-2m0 5h18v2H3v-2z"></path></svg>
</label>
<div class="md-header-nav__title">
<div class="header-menu-item">
<a href="https://albumentations.ai">Home</a>
</div>
<div class="header-menu-item header-menu-item-selected">
<a href="https://albumentations.ai/docs/">Documentation</a>
</div>
<div class="header-menu-item header-large-menu-item">
<a href="https://albumentations.ai/whos_using">Who's using</a>
</div>
<div class="header-menu-item header-large-menu-item">
<a href="https://albumentations-demo.herokuapp.com/" target="_blank">Demo</a>
</div>
<div class="header-menu-item header-large-menu-item">
<a href="https://albumentations.ai/team">Team</a>
</div>
</div>
<label class="md-header-nav__button md-icon" for="__search">
<svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M9.5 3A6.5 6.5 0 0116 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 019.5 16 6.5 6.5 0 013 9.5 6.5 6.5 0 019.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5z"></path></svg>
</label>
<div class="md-search" data-md-component="search" role="dialog">
<label class="md-search__overlay" for="__search"></label>
<div class="md-search__inner" role="search">
<form class="md-search__form" name="search">
<input aria-label="Search" autocapitalize="off" autocomplete="off" autocorrect="off" class="md-search__input" data-md-state="active" name="query" placeholder="Search" spellcheck="false" type="text"/>
<label class="md-search__icon md-icon" for="__search">
<svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M9.5 3A6.5 6.5 0 0116 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 019.5 16 6.5 6.5 0 013 9.5 6.5 6.5 0 019.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5z"></path></svg>
<svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12z"></path></svg>
</label>
</form>
</div>
</div>
<div class="md-header-nav__source">
<!--
  Copyright (c) 2016-2020 Martin Donath <martin.donath@squidfunk.com>
  Permission is hereby granted, free of charge, to any person obtaining a copy
  of this software and associated documentation files (the "Software"), to
  deal in the Software without restriction, including without limitation the
  rights to use, copy, modify, merge, publish, distribute, sublicense, and/or
  sell copies of the Software, and to permit persons to whom the Software is
  furnished to do so, subject to the following conditions:
  The above copyright notice and this permission notice shall be included in
  all copies or substantial portions of the Software.
  THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
  IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
  FITNESS FOR A PARTICULAR PURPOSE AND NON-INFRINGEMENT. IN NO EVENT SHALL THE
  AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
  LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING
  FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS
  IN THE SOFTWARE.
-->
<!-- Repository containing source -->
<a class="md-source" href="https://github.com/albumentations-team/albumentations/" target="_blank" title="Go to repository">
<div class="md-source__icon md-icon">
<svg viewbox="0 0 496 512" xmlns="http://www.w3.org/2000/svg"><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6 0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2z"></path></svg>
</div>
<div class="md-source__repository">
    albumentations
  </div>
</a>
</div>
</nav>
</header>
<div class="md-container" data-md-component="container">
<main class="md-main" data-md-component="main">
<div class="md-main__inner md-grid">
<div class="md-sidebar md-sidebar--primary" data-md-component="navigation">
<div class="md-sidebar__scrollwrap">
<div class="md-sidebar__inner">
<nav aria-label="Navigation" class="md-nav md-nav--primary" data-md-level="0">
<label class="md-nav__title" for="__drawer">
<a aria-label="Albumentations Documentation" class="md-nav__button md-logo" href="https://albumentations.ai/docs/" title="Albumentations Documentation">
<img alt="logo" src="../../../images/logo.png"/>
</a>
    Albumentations Documentation
  </label>
<div class="md-nav__source">
<!--
  Copyright (c) 2016-2020 Martin Donath <martin.donath@squidfunk.com>
  Permission is hereby granted, free of charge, to any person obtaining a copy
  of this software and associated documentation files (the "Software"), to
  deal in the Software without restriction, including without limitation the
  rights to use, copy, modify, merge, publish, distribute, sublicense, and/or
  sell copies of the Software, and to permit persons to whom the Software is
  furnished to do so, subject to the following conditions:
  The above copyright notice and this permission notice shall be included in
  all copies or substantial portions of the Software.
  THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
  IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
  FITNESS FOR A PARTICULAR PURPOSE AND NON-INFRINGEMENT. IN NO EVENT SHALL THE
  AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
  LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING
  FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS
  IN THE SOFTWARE.
-->
<!-- Repository containing source -->
<a class="md-source" href="https://github.com/albumentations-team/albumentations/" target="_blank" title="Go to repository">
<div class="md-source__icon md-icon">
<svg viewbox="0 0 496 512" xmlns="http://www.w3.org/2000/svg"><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6 0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2z"></path></svg>
</div>
<div class="md-source__repository">
    albumentations
  </div>
</a>
</div>
<ul class="md-nav__list" data-md-scrollfix="">
<li class="md-nav__item">
<a class="md-nav__link" href="../../.." title="Welcome to Albumentations documentation">
      Welcome to Albumentations documentation
    </a>
</li>
<li class="md-nav__item md-nav__item--nested">
<input class="md-nav__toggle md-toggle" data-md-toggle="nav-2" id="nav-2" type="checkbox"/>
<label class="md-nav__link" for="nav-2">
      Introduction to image augmentation
      <span class="md-nav__icon md-icon">
<svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M8.59 16.58L13.17 12 8.59 7.41 10 6l6 6-6 6-1.41-1.42z"></path></svg>
</span>
</label>
<nav aria-label="Introduction to image augmentation" class="md-nav" data-md-level="1">
<label class="md-nav__title" for="nav-2">
<span class="md-nav__icon md-icon">
<svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12z"></path></svg>
</span>
        Introduction to image augmentation
      </label>
<ul class="md-nav__list" data-md-scrollfix="">
<li class="md-nav__item">
<a class="md-nav__link" href="../../../introduction/image_augmentation/" title="What is image augmentation and how it can improve the performance of deep neural networks">
      What is image augmentation and how it can improve the performance of deep neural networks
    </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../../introduction/why_you_need_a_dedicated_library_for_image_augmentation/" title="Why you need a dedicated library for image augmentation">
      Why you need a dedicated library for image augmentation
    </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../../introduction/why_albumentations/" title="Why Albumentations">
      Why Albumentations
    </a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item md-nav__item--nested">
<input class="md-nav__toggle md-toggle" data-md-toggle="nav-3" id="nav-3" type="checkbox"/>
<label class="md-nav__link" for="nav-3">
      Getting started with Albumentations
      <span class="md-nav__icon md-icon">
<svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M8.59 16.58L13.17 12 8.59 7.41 10 6l6 6-6 6-1.41-1.42z"></path></svg>
</span>
</label>
<nav aria-label="Getting started with Albumentations" class="md-nav" data-md-level="1">
<label class="md-nav__title" for="nav-3">
<span class="md-nav__icon md-icon">
<svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12z"></path></svg>
</span>
        Getting started with Albumentations
      </label>
<ul class="md-nav__list" data-md-scrollfix="">
<li class="md-nav__item">
<a class="md-nav__link" href="../../../getting_started/installation/" title="Installation">
      Installation
    </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../../getting_started/image_augmentation/" title="Image augmentation for classification">
      Image augmentation for classification
    </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../../getting_started/mask_augmentation/" title="Mask augmentation for segmentation">
      Mask augmentation for segmentation
    </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../../getting_started/bounding_boxes_augmentation/" title="Bounding boxes augmentation for object detection">
      Bounding boxes augmentation for object detection
    </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../../getting_started/keypoints_augmentation/" title="Keypoints augmentation">
      Keypoints augmentation
    </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../../getting_started/simultaneous_augmentation/" title="Simultaneous augmentation of multiple targets: masks, bounding boxes, keypoints">
      Simultaneous augmentation of multiple targets: masks, bounding boxes, keypoints
    </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../../getting_started/transforms_and_targets/" title="A list of transforms and their supported targets">
      A list of transforms and their supported targets
    </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../../getting_started/setting_probabilities/" title="Setting probabilities for transforms in an augmentation pipeline">
      Setting probabilities for transforms in an augmentation pipeline
    </a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item md-nav__item--nested">
<input class="md-nav__toggle md-toggle" data-md-toggle="nav-4" id="nav-4" type="checkbox"/>
<label class="md-nav__link" for="nav-4">
      Examples
      <span class="md-nav__icon md-icon">
<svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M8.59 16.58L13.17 12 8.59 7.41 10 6l6 6-6 6-1.41-1.42z"></path></svg>
</span>
</label>
<nav aria-label="Examples" class="md-nav" data-md-level="1">
<label class="md-nav__title" for="nav-4">
<span class="md-nav__icon md-icon">
<svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12z"></path></svg>
</span>
        Examples
      </label>
<ul class="md-nav__list" data-md-scrollfix="">
<li class="md-nav__item">
<a class="md-nav__link" href="../../../examples/" title="List of examples">
      List of examples
    </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../../examples/example/" title="Defining a simple augmentation pipeline for image augmentation">
      Defining a simple augmentation pipeline for image augmentation
    </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../../examples/example_16_bit_tiff/" title="Working with non-8-bit images">
      Working with non-8-bit images
    </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../../examples/example_bboxes/" title="Using Albumentations to augment bounding boxes for object detection tasks">
      Using Albumentations to augment bounding boxes for object detection tasks
    </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../../examples/example_bboxes2/" title="How to use Albumentations for detection tasks if you need to keep all bounding boxes">
      How to use Albumentations for detection tasks if you need to keep all bounding boxes
    </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../../examples/example_kaggle_salt/" title="Using Albumentations for a semantic segmentation task">
      Using Albumentations for a semantic segmentation task
    </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../../examples/example_keypoints/" title="Using Albumentations to augment keypoints">
      Using Albumentations to augment keypoints
    </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../../examples/example_multi_target/" title="Applying the same augmentation with the same parameters to multiple images, masks, bounding boxes, or keypoints">
      Applying the same augmentation with the same parameters to multiple images, masks, bounding boxes, or keypoints
    </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../../examples/example_weather_transforms/" title="Weather augmentations in Albumentations">
      Weather augmentations in Albumentations
    </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../../examples/migrating_from_torchvision_to_albumentations/" title="Migrating from torchvision to Albumentations">
      Migrating from torchvision to Albumentations
    </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../../examples/pytorch_classification/" title="PyTorch and Albumentations for image classification">
      PyTorch and Albumentations for image classification
    </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../../examples/pytorch_semantic_segmentation/" title="PyTorch and Albumentations for semantic segmentation">
      PyTorch and Albumentations for semantic segmentation
    </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../../examples/replay/" title="Debugging an augmentation pipeline with ReplayCompose">
      Debugging an augmentation pipeline with ReplayCompose
    </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../../examples/serialization/" title="How to save and load parameters of an augmentation pipeline">
      How to save and load parameters of an augmentation pipeline
    </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../../examples/showcase/" title="Showcase. Cool augmentation examples on diverse set of images from various real-world tasks.">
      Showcase. Cool augmentation examples on diverse set of images from various real-world tasks.
    </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../../examples/tensorflow-example/" title="Using Albumentations with Tensorflow">
      Using Albumentations with Tensorflow
    </a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../../faq/" title="Frequently Asked Questions">
      Frequently Asked Questions
    </a>
</li>
<li class="md-nav__item md-nav__item--active md-nav__item--nested">
<input checked="" class="md-nav__toggle md-toggle" data-md-toggle="nav-6" id="nav-6" type="checkbox"/>
<label class="md-nav__link" for="nav-6">
      AutoAlbument - AutoML for Image Augmentation
      <span class="md-nav__icon md-icon">
<svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M8.59 16.58L13.17 12 8.59 7.41 10 6l6 6-6 6-1.41-1.42z"></path></svg>
</span>
</label>
<nav aria-label="AutoAlbument - AutoML for Image Augmentation" class="md-nav" data-md-level="1">
<label class="md-nav__title" for="nav-6">
<span class="md-nav__icon md-icon">
<svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12z"></path></svg>
</span>
        AutoAlbument - AutoML for Image Augmentation
      </label>
<ul class="md-nav__list" data-md-scrollfix="">
<li class="md-nav__item">
<a class="md-nav__link" href="../../" title="AutoAlbument Overview">
      AutoAlbument Overview
    </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../benchmarks/" title="Benchmarks and a comparison with baseline augmentation strategies">
      Benchmarks and a comparison with baseline augmentation strategies
    </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../installation/" title="Installation">
      Installation
    </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../how_to_use/" title="How to use AutoAlbument">
      How to use AutoAlbument
    </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../docker/" title="How to use an AutoAlbument Docker image">
      How to use an AutoAlbument Docker image
    </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../custom_model/" title="How to use a custom classification or semantic segmentation model">
      How to use a custom classification or semantic segmentation model
    </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../metrics/" title="Metrics and their meaning">
      Metrics and their meaning
    </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../tuning_parameters/" title="Tuning the search parameters">
      Tuning the search parameters
    </a>
</li>
<li class="md-nav__item md-nav__item--active md-nav__item--nested">
<input checked="" class="md-nav__toggle md-toggle" data-md-toggle="nav-6-9" id="nav-6-9" type="checkbox"/>
<label class="md-nav__link" for="nav-6-9">
      Examples
      <span class="md-nav__icon md-icon">
<svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M8.59 16.58L13.17 12 8.59 7.41 10 6l6 6-6 6-1.41-1.42z"></path></svg>
</span>
</label>
<nav aria-label="Examples" class="md-nav" data-md-level="2">
<label class="md-nav__title" for="nav-6-9">
<span class="md-nav__icon md-icon">
<svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12z"></path></svg>
</span>
        Examples
      </label>
<ul class="md-nav__list" data-md-scrollfix="">
<li class="md-nav__item">
<a class="md-nav__link" href="../list/" title="List of examples">
      List of examples
    </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../cifar10/" title="Image classification on the CIFAR10 dataset">
      Image classification on the CIFAR10 dataset
    </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../svhn/" title="Image classification on the SVHN dataset">
      Image classification on the SVHN dataset
    </a>
</li>
<li class="md-nav__item md-nav__item--active">
<input class="md-nav__toggle md-toggle" data-md-toggle="toc" id="__toc" type="checkbox"/>
<label class="md-nav__link md-nav__link--active" for="__toc">
        Image classification on the ImageNet dataset
        <span class="md-nav__icon md-icon">
<svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M3 9h14V7H3v2m0 4h14v-2H3v2m0 4h14v-2H3v2m16 0h2v-2h-2v2m0-10v2h2V7h-2m0 6h2v-2h-2v2z"></path></svg>
</span>
</label>
<a class="md-nav__link md-nav__link--active" href="./" title="Image classification on the ImageNet dataset">
      Image classification on the ImageNet dataset
    </a>
<nav aria-label="Table of contents" class="md-nav md-nav--secondary">
<label class="md-nav__title" for="__toc">
<span class="md-nav__icon md-icon">
<svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12z"></path></svg>
</span>
      Table of contents
    </label>
<ul class="md-nav__list" data-md-scrollfix="">
<li class="md-nav__item">
<a class="md-nav__link" href="#datasetpy">
    dataset.py
  </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="#searchyaml">
    search.yaml
  </a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../pascal_voc/" title="Semantic segmentation on the Pascal VOC dataset">
      Semantic segmentation on the Pascal VOC dataset
    </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../cityscapes/" title="Semantic segmentation on the Pascal VOC dataset">
      Semantic segmentation on the Pascal VOC dataset
    </a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../search_algorithms/" title="Search algorithms">
      Search algorithms
    </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../faq/" title="FAQ">
      FAQ
    </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../introduction/" title="AutoAlbument introduction and core concepts">
      AutoAlbument introduction and core concepts
    </a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item md-nav__item--nested">
<input class="md-nav__toggle md-toggle" data-md-toggle="nav-7" id="nav-7" type="checkbox"/>
<label class="md-nav__link" for="nav-7">
      Albumentations Experimental
      <span class="md-nav__icon md-icon">
<svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M8.59 16.58L13.17 12 8.59 7.41 10 6l6 6-6 6-1.41-1.42z"></path></svg>
</span>
</label>
<nav aria-label="Albumentations Experimental" class="md-nav" data-md-level="1">
<label class="md-nav__title" for="nav-7">
<span class="md-nav__icon md-icon">
<svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12z"></path></svg>
</span>
        Albumentations Experimental
      </label>
<ul class="md-nav__list" data-md-scrollfix="">
<li class="md-nav__item">
<a class="md-nav__link" href="../../../experimental/overview/" title="Albumentations Experimental Overview">
      Albumentations Experimental Overview
    </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../../experimental/installation/" title="Installation">
      Installation
    </a>
</li>
<li class="md-nav__item md-nav__item--nested">
<input class="md-nav__toggle md-toggle" data-md-toggle="nav-7-3" id="nav-7-3" type="checkbox"/>
<label class="md-nav__link" for="nav-7-3">
      API Reference
      <span class="md-nav__icon md-icon">
<svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M8.59 16.58L13.17 12 8.59 7.41 10 6l6 6-6 6-1.41-1.42z"></path></svg>
</span>
</label>
<nav aria-label="API Reference" class="md-nav" data-md-level="2">
<label class="md-nav__title" for="nav-7-3">
<span class="md-nav__icon md-icon">
<svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12z"></path></svg>
</span>
        API Reference
      </label>
<ul class="md-nav__list" data-md-scrollfix="">
<li class="md-nav__item md-nav__item--nested">
<input class="md-nav__toggle md-toggle" data-md-toggle="nav-7-3-1" id="nav-7-3-1" type="checkbox"/>
<label class="md-nav__link" for="nav-7-3-1">
      Augmentations
      <span class="md-nav__icon md-icon">
<svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M8.59 16.58L13.17 12 8.59 7.41 10 6l6 6-6 6-1.41-1.42z"></path></svg>
</span>
</label>
<nav aria-label="Augmentations" class="md-nav" data-md-level="3">
<label class="md-nav__title" for="nav-7-3-1">
<span class="md-nav__icon md-icon">
<svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12z"></path></svg>
</span>
        Augmentations
      </label>
<ul class="md-nav__list" data-md-scrollfix="">
<li class="md-nav__item">
<a class="md-nav__link" href="../../../experimental/api_reference/augmentations/transforms/" title="Albumentations Experimental Transforms (augmentations.transforms)">
      Albumentations Experimental Transforms (augmentations.transforms)
    </a>
</li>
</ul>
</nav>
</li>
</ul>
</nav>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item md-nav__item--nested">
<input class="md-nav__toggle md-toggle" data-md-toggle="nav-8" id="nav-8" type="checkbox"/>
<label class="md-nav__link" for="nav-8">
      External resources
      <span class="md-nav__icon md-icon">
<svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M8.59 16.58L13.17 12 8.59 7.41 10 6l6 6-6 6-1.41-1.42z"></path></svg>
</span>
</label>
<nav aria-label="External resources" class="md-nav" data-md-level="1">
<label class="md-nav__title" for="nav-8">
<span class="md-nav__icon md-icon">
<svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12z"></path></svg>
</span>
        External resources
      </label>
<ul class="md-nav__list" data-md-scrollfix="">
<li class="md-nav__item">
<a class="md-nav__link" href="../../../external_resources/blog_posts_podcasts_talks/" title="Blog posts, podcasts, talks, and videos about Albumentations">
      Blog posts, podcasts, talks, and videos about Albumentations
    </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../../external_resources/books/" title="Books that mention Albumentations">
      Books that mention Albumentations
    </a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item md-nav__item--nested">
<input class="md-nav__toggle md-toggle" data-md-toggle="nav-9" id="nav-9" type="checkbox"/>
<label class="md-nav__link" for="nav-9">
      API Reference
      <span class="md-nav__icon md-icon">
<svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M8.59 16.58L13.17 12 8.59 7.41 10 6l6 6-6 6-1.41-1.42z"></path></svg>
</span>
</label>
<nav aria-label="API Reference" class="md-nav" data-md-level="1">
<label class="md-nav__title" for="nav-9">
<span class="md-nav__icon md-icon">
<svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12z"></path></svg>
</span>
        API Reference
      </label>
<ul class="md-nav__list" data-md-scrollfix="">
<li class="md-nav__item md-nav__item--nested">
<input class="md-nav__toggle md-toggle" data-md-toggle="nav-9-2" id="nav-9-2" type="checkbox"/>
<label class="md-nav__link" for="nav-9-2">
      Core API
      <span class="md-nav__icon md-icon">
<svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M8.59 16.58L13.17 12 8.59 7.41 10 6l6 6-6 6-1.41-1.42z"></path></svg>
</span>
</label>
<nav aria-label="Core API" class="md-nav" data-md-level="2">
<label class="md-nav__title" for="nav-9-2">
<span class="md-nav__icon md-icon">
<svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12z"></path></svg>
</span>
        Core API
      </label>
<ul class="md-nav__list" data-md-scrollfix="">
<li class="md-nav__item">
<a class="md-nav__link" href="../../../api_reference/core/composition/" title="Composition API (core.composition)">
      Composition API (core.composition)
    </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../../api_reference/core/transforms_interface/" title="Transforms Interface (core.transforms_interface)">
      Transforms Interface (core.transforms_interface)
    </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../../api_reference/core/serialization/" title="Serialization API (core.serialization)">
      Serialization API (core.serialization)
    </a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item md-nav__item--nested">
<input class="md-nav__toggle md-toggle" data-md-toggle="nav-9-3" id="nav-9-3" type="checkbox"/>
<label class="md-nav__link" for="nav-9-3">
      Augmentations
      <span class="md-nav__icon md-icon">
<svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M8.59 16.58L13.17 12 8.59 7.41 10 6l6 6-6 6-1.41-1.42z"></path></svg>
</span>
</label>
<nav aria-label="Augmentations" class="md-nav" data-md-level="2">
<label class="md-nav__title" for="nav-9-3">
<span class="md-nav__icon md-icon">
<svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12z"></path></svg>
</span>
        Augmentations
      </label>
<ul class="md-nav__list" data-md-scrollfix="">
<li class="md-nav__item">
<a class="md-nav__link" href="../../../api_reference/augmentations/transforms/" title="Transforms (augmentations.transforms)">
      Transforms (augmentations.transforms)
    </a>
</li>
<li class="md-nav__item md-nav__item--nested">
<input class="md-nav__toggle md-toggle" data-md-toggle="nav-9-3-3" id="nav-9-3-3" type="checkbox"/>
<label class="md-nav__link" for="nav-9-3-3">
      Crop transforms
      <span class="md-nav__icon md-icon">
<svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M8.59 16.58L13.17 12 8.59 7.41 10 6l6 6-6 6-1.41-1.42z"></path></svg>
</span>
</label>
<nav aria-label="Crop transforms" class="md-nav" data-md-level="3">
<label class="md-nav__title" for="nav-9-3-3">
<span class="md-nav__icon md-icon">
<svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12z"></path></svg>
</span>
        Crop transforms
      </label>
<ul class="md-nav__list" data-md-scrollfix="">
<li class="md-nav__item">
<a class="md-nav__link" href="../../../api_reference/augmentations/crops/functional/" title="Crop functional transforms (augmentations.crops.functional)">
      Crop functional transforms (augmentations.crops.functional)
    </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../../api_reference/augmentations/crops/transforms/" title="Crop transforms (augmentations.crops.transforms)">
      Crop transforms (augmentations.crops.transforms)
    </a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item md-nav__item--nested">
<input class="md-nav__toggle md-toggle" data-md-toggle="nav-9-3-4" id="nav-9-3-4" type="checkbox"/>
<label class="md-nav__link" for="nav-9-3-4">
      Geometric transforms
      <span class="md-nav__icon md-icon">
<svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M8.59 16.58L13.17 12 8.59 7.41 10 6l6 6-6 6-1.41-1.42z"></path></svg>
</span>
</label>
<nav aria-label="Geometric transforms" class="md-nav" data-md-level="3">
<label class="md-nav__title" for="nav-9-3-4">
<span class="md-nav__icon md-icon">
<svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12z"></path></svg>
</span>
        Geometric transforms
      </label>
<ul class="md-nav__list" data-md-scrollfix="">
<li class="md-nav__item">
<a class="md-nav__link" href="../../../api_reference/augmentations/geometric/functional/" title="Geometric functional transforms (augmentations.geometric.functional)">
      Geometric functional transforms (augmentations.geometric.functional)
    </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../../api_reference/augmentations/geometric/resize/" title="Resizing transforms (augmentations.geometric.resize)">
      Resizing transforms (augmentations.geometric.resize)
    </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../../api_reference/augmentations/geometric/rotate/" title="Rotation transforms (augmentations.geometric.functional)">
      Rotation transforms (augmentations.geometric.functional)
    </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../../api_reference/augmentations/geometric/transforms/" title="Geometric transforms (augmentations.geometric.transforms)">
      Geometric transforms (augmentations.geometric.transforms)
    </a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../../api_reference/augmentations/domain_adaptation/" title="Domain adaptation transforms (augmentations.domain_adaptation)">
      Domain adaptation transforms (augmentations.domain_adaptation)
    </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../../api_reference/augmentations/functional/" title="Functional transforms (augmentations.functional)">
      Functional transforms (augmentations.functional)
    </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../../api_reference/augmentations/bbox_utils/" title="Helper functions for working with bounding boxes (augmentations.bbox_utils)">
      Helper functions for working with bounding boxes (augmentations.bbox_utils)
    </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../../api_reference/augmentations/keypoints_utils/" title="Helper functions for working with keypoints (augmentations.keypoints_utils)">
      Helper functions for working with keypoints (augmentations.keypoints_utils)
    </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../../api_reference/augmentations/geometric/" title="Geometric augmentations (augmentations.geometric)">
      Geometric augmentations (augmentations.geometric)
    </a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item md-nav__item--nested">
<input class="md-nav__toggle md-toggle" data-md-toggle="nav-9-4" id="nav-9-4" type="checkbox"/>
<label class="md-nav__link" for="nav-9-4">
      ImgAug Helpers
      <span class="md-nav__icon md-icon">
<svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M8.59 16.58L13.17 12 8.59 7.41 10 6l6 6-6 6-1.41-1.42z"></path></svg>
</span>
</label>
<nav aria-label="ImgAug Helpers" class="md-nav" data-md-level="2">
<label class="md-nav__title" for="nav-9-4">
<span class="md-nav__icon md-icon">
<svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12z"></path></svg>
</span>
        ImgAug Helpers
      </label>
<ul class="md-nav__list" data-md-scrollfix="">
<li class="md-nav__item">
<a class="md-nav__link" href="../../../api_reference/imgaug/transforms/" title="Transforms (imgaug.transforms)">
      Transforms (imgaug.transforms)
    </a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item md-nav__item--nested">
<input class="md-nav__toggle md-toggle" data-md-toggle="nav-9-5" id="nav-9-5" type="checkbox"/>
<label class="md-nav__link" for="nav-9-5">
      PyTorch Helpers
      <span class="md-nav__icon md-icon">
<svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M8.59 16.58L13.17 12 8.59 7.41 10 6l6 6-6 6-1.41-1.42z"></path></svg>
</span>
</label>
<nav aria-label="PyTorch Helpers" class="md-nav" data-md-level="2">
<label class="md-nav__title" for="nav-9-5">
<span class="md-nav__icon md-icon">
<svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12z"></path></svg>
</span>
        PyTorch Helpers
      </label>
<ul class="md-nav__list" data-md-scrollfix="">
<li class="md-nav__item">
<a class="md-nav__link" href="../../../api_reference/pytorch/transforms/" title="Transforms (pytorch.transforms)">
      Transforms (pytorch.transforms)
    </a>
</li>
</ul>
</nav>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../../release_notes/" title="Release notes">
      Release notes
    </a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../../contributing/" title="Contributing">
      Contributing
    </a>
</li>
</ul>
</nav>
</div>
</div>
</div>
<div class="md-content">
<article class="md-content__inner md-typeset">
<a class="md-content__button md-icon" href="https://github.com/albumentations-team/albumentations.ai/tree/master/mkdocs/src/docs/autoalbument/examples/imagenet.md" title="Edit this page">
<svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M20.71 7.04c.39-.39.39-1.04 0-1.41l-2.34-2.34c-.37-.39-1.02-.39-1.41 0l-1.84 1.83 3.75 3.75M3 17.25V21h3.75L17.81 9.93l-3.75-3.75L3 17.25z"></path></svg>
</a>
<h1 id="image-classification-on-the-imagenet-dataset">Image classification on the ImageNet dataset<a class="headerlink" href="#image-classification-on-the-imagenet-dataset" title="Permanent link">¶</a></h1>
<p>The following files are also available on GitHub - <a href="https://github.com/albumentations-team/autoalbument/tree/master/examples/imagenet" target="_blank">https://github.com/albumentations-team/autoalbument/tree/master/examples/imagenet</a></p>
<h2 id="datasetpy">dataset.py<a class="headerlink" href="#datasetpy" title="Permanent link">¶</a></h2>
<div class="highlight"><pre><span></span><code><span class="kn">import</span> <span class="nn">cv2</span>
<span class="kn">import</span> <span class="nn">torchvision</span>

<span class="n">cv2</span><span class="o">.</span><span class="n">setNumThreads</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
<span class="n">cv2</span><span class="o">.</span><span class="n">ocl</span><span class="o">.</span><span class="n">setUseOpenCL</span><span class="p">(</span><span class="kc">False</span><span class="p">)</span>


<span class="k">class</span> <span class="nc">ImageNetSearchDataset</span><span class="p">(</span><span class="n">torchvision</span><span class="o">.</span><span class="n">datasets</span><span class="o">.</span><span class="n">ImageNet</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__getitem__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">index</span><span class="p">):</span>
        <span class="n">path</span><span class="p">,</span> <span class="n">label</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">samples</span><span class="p">[</span><span class="n">index</span><span class="p">]</span>
        <span class="n">image</span> <span class="o">=</span> <span class="n">cv2</span><span class="o">.</span><span class="n">imread</span><span class="p">(</span><span class="n">path</span><span class="p">)</span>
        <span class="n">image</span> <span class="o">=</span> <span class="n">cv2</span><span class="o">.</span><span class="n">cvtColor</span><span class="p">(</span><span class="n">image</span><span class="p">,</span> <span class="n">cv2</span><span class="o">.</span><span class="n">COLOR_BGR2RGB</span><span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">transform</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">transformed</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">image</span><span class="o">=</span><span class="n">image</span><span class="p">)</span>
            <span class="n">image</span> <span class="o">=</span> <span class="n">transformed</span><span class="p">[</span><span class="s2">"image"</span><span class="p">]</span>

        <span class="k">return</span> <span class="n">image</span><span class="p">,</span> <span class="n">label</span>
</code></pre></div>
<h2 id="searchyaml">search.yaml<a class="headerlink" href="#searchyaml" title="Permanent link">¶</a></h2>
<div class="highlight"><pre><span></span><code><span class="c1"># @package _global_</span>

<span class="nt">_version</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">2</span>  <span class="c1"># An internal value that indicates a version of the config schema. This value is used by</span>
<span class="c1"># `autoalbument-search` and `autoalbument-migrate` to upgrade the config to the latest version if necessary.</span>
<span class="c1"># Please do not change it manually.</span>


<span class="nt">task</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">classification</span> <span class="c1"># Deep learning task. Should either be `classification` or `semantic_segmentation`.</span>


<span class="nt">policy_model</span><span class="p">:</span>
  <span class="c1"># Settings for Policy Model that searches augmentation policies.</span>

  <span class="nt">task_factor</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">0.1</span>
  <span class="c1"># Multiplier for classification loss of a model. Faster AutoAugment uses classification loss to prevent augmentations</span>
  <span class="c1"># from transforming images of a particular class to another class. The authors of Faster AutoAugment use 0.1 as</span>
  <span class="c1"># default value.</span>

  <span class="nt">gp_factor</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">10</span>
  <span class="c1"># Multiplier for the gradient penalty for WGAN-GP training. 10 is the default value that was proposed in</span>
  <span class="c1"># `Improved Training of Wasserstein GANs`.</span>

  <span class="nt">temperature</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">0.05</span>
  <span class="c1"># Temperature for Relaxed Bernoulli distribution. The probability of applying a certain augmentation is sampled from</span>
  <span class="c1"># Relaxed Bernoulli distribution (because Bernoulli distribution is not differentiable). With lower values of</span>
  <span class="c1"># `temperature` Relaxed Bernoulli distribution behaves like Bernoulli distribution. In the paper, the authors</span>
  <span class="c1"># of Faster AutoAugment used 0.05 as a default value for `temperature`.</span>

  <span class="nt">num_sub_policies</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">100</span>
  <span class="c1"># Number of augmentation sub-policies. When an image passes through an augmentation pipeline, Faster AutoAugment</span>
  <span class="c1"># randomly chooses one sub-policy and uses augmentations from that sub-policy to transform an input image. A larger</span>
  <span class="c1"># number of sub-policies leads to a more diverse set of augmentations and better performance of a model trained on</span>
  <span class="c1"># augmented images. However, an increase in the number of sub-policies leads to the exponential growth of a search</span>
  <span class="c1"># space of augmentations, so you need more training data for Policy Model to find good augmentation policies.</span>

  <span class="nt">num_chunks</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">6</span>
  <span class="c1"># Number of chunks in a batch. Faster AutoAugment splits each batch of images into `num_chunks` chunks. Then it</span>
  <span class="c1"># applies the same sub-policy with the same parameters to each image in a chunk. This parameter controls the tradeoff</span>
  <span class="c1"># between the speed of augmentation search and diversity of augmentations. Larger `num_chunks` values will lead to</span>
  <span class="c1"># faster searching but less diverse set of augmentations. Note that this parameter is used only in the searching</span>
  <span class="c1"># phase. When you train a model with found sub-policies, Albumentations will apply a distinct set of transformations</span>
  <span class="c1"># to each image separately.</span>

  <span class="nt">operation_count</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">4</span>
  <span class="c1"># Number of consecutive augmentations in each sub-policy. Faster AutoAugment will sequentially apply `operation_count`</span>
  <span class="c1"># augmentations from a sub-policy to an image. Larger values of `operation_count` lead to better performance of</span>
  <span class="c1"># a model trained on augmented images. Simultaneously, larger values of `operation_count` affect the speed of search</span>
  <span class="c1"># and increase the searching time.</span>

<span class="nt">classification_model</span><span class="p">:</span>
  <span class="c1"># Settings for Classification Model that is used for two purposes:</span>
  <span class="c1"># 1. As a model that performs classification of input images.</span>
  <span class="c1"># 2. As a Discriminator for Policy Model.</span>

  <span class="nt">num_classes</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">1000</span>
  <span class="c1"># Number of classes in the dataset. The dataset implementation should return an integer in the range</span>
  <span class="c1"># [0, num_classes - 1] as a class label of an image.</span>

  <span class="nt">architecture</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">resnet50</span>
  <span class="c1"># The architecture of Classification Model. AutoAlbument uses models from</span>
  <span class="c1"># https://github.com/rwightman/pytorch-image-models/. Please refer to its documentation to get a list of available</span>
  <span class="c1"># models - https://rwightman.github.io/pytorch-image-models/#list-models-with-pretrained-weights.</span>

  <span class="nt">pretrained</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">false</span>
  <span class="c1"># Boolean flag that indicates whether the selected model architecture should load pretrained weights or use randomly</span>
  <span class="c1"># initialized weights.</span>

<span class="nt">data</span><span class="p">:</span>
  <span class="nt">dataset</span><span class="p">:</span>
    <span class="nt">_target_</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">dataset.ImageNetSearchDataset</span>
    <span class="nt">root</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">~/data/imagenet</span>
    <span class="nt">split</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">train</span>
  <span class="c1"># Class for the PyTorch Dataset and arguments to it. AutoAlbument will create an object of this class using</span>
  <span class="c1"># the `instantiate` method from Hydra - https://hydra.cc/docs/next/patterns/instantiate_objects/overview/.</span>
  <span class="c1">#</span>
  <span class="c1"># Note that the target class value in the `_target_` argument should be located inside PYTHONPATH so Hydra could</span>
  <span class="c1"># find it. The directory with the config file is automatically added to PYTHONPATH, so the default value</span>
  <span class="c1"># `dataset.SearchDataset` points to the class `SearchDataset` from the `dataset.py` file. This `dataset.py` file is</span>
  <span class="c1"># located along with the `search.yaml` file in the same directory provided by `--config-dir`.</span>
  <span class="c1">#</span>
  <span class="c1"># As an alternative, you could provide a path to a Python file with the dataset using the `dataset_file` parameter</span>
  <span class="c1"># instead of the `dataset` parameter. The Python file should contain the implementation of a PyTorch dataset for</span>
  <span class="c1"># augmentation search. The dataset class should have named `SearchDataset`. The value in `dataset_file` could either</span>
  <span class="c1"># be a relative or an absolute path ; in the case of a relative path, the path should be relative to this config</span>
  <span class="c1"># file's location.</span>
  <span class="c1">#</span>
  <span class="c1"># - Example of a relative path:</span>
  <span class="c1"># dataset_file: dataset.py</span>
  <span class="c1">#</span>
  <span class="c1"># - Example of an absolute path:</span>
  <span class="c1"># dataset_file: /projects/pytorch/dataset.py</span>
  <span class="c1">#</span>

  <span class="nt">input_dtype</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">uint8</span>
  <span class="c1"># The data type of input images. Two values are supported:</span>
  <span class="c1"># - uint8. In that case, all input images should be NumPy arrays with the np.uint8 data type and values in the range</span>
  <span class="c1">#   [0, 255].</span>
  <span class="c1"># - float32. In that case, all input images should be NumPy arrays with the np.float32 data type and values in the</span>
  <span class="c1">#   range [0.0, 1.0].</span>

  <span class="nt">preprocessing</span><span class="p">:</span>
  <span class="p p-Indicator">-</span> <span class="nt">Resize</span><span class="p">:</span>
      <span class="nt">height</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">256</span>
      <span class="nt">width</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">256</span>
  <span class="p p-Indicator">-</span> <span class="nt">RandomCrop</span><span class="p">:</span>
      <span class="nt">height</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">224</span>
      <span class="nt">width</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">224</span>
  <span class="c1"># A list of preprocessing augmentations that will be applied to each image before applying augmentations from</span>
  <span class="c1"># a policy. A preprocessing augmentation should be defined as `key`: `value`, where `key` is the name of augmentation</span>
  <span class="c1"># from Albumentations, and `value` is a dictionary with augmentation parameters. The found policy will also apply</span>
  <span class="c1"># those preprocessing augmentations before applying the main augmentations.</span>
  <span class="c1">#</span>
  <span class="c1"># Here is an example of an augmentation pipeline that first pads an image to the size 512x512 pixels, then resizes</span>
  <span class="c1"># the resulting image to the size 256x256 pixels and finally crops a random patch with the size 224x224 pixels.</span>
  <span class="c1">#</span>
  <span class="c1">#  preprocessing:</span>
  <span class="c1">#    - PadIfNeeded:</span>
  <span class="c1">#        min_height: 512</span>
  <span class="c1">#        min_width: 512</span>
  <span class="c1">#    - Resize:</span>
  <span class="c1">#        height: 256</span>
  <span class="c1">#        width: 256</span>
  <span class="c1">#    - RandomCrop:</span>
  <span class="c1">#        height: 224</span>
  <span class="c1">#        width: 224</span>
  <span class="c1">#</span>

  <span class="nt">normalization</span><span class="p">:</span>
    <span class="nt">mean</span><span class="p">:</span> <span class="p p-Indicator">[</span><span class="nv">0.485</span><span class="p p-Indicator">,</span> <span class="nv">0.456</span><span class="p p-Indicator">,</span> <span class="nv">0.406</span><span class="p p-Indicator">]</span>
    <span class="nt">std</span><span class="p">:</span> <span class="p p-Indicator">[</span><span class="nv">0.229</span><span class="p p-Indicator">,</span> <span class="nv">0.224</span><span class="p p-Indicator">,</span> <span class="nv">0.225</span><span class="p p-Indicator">]</span>
  <span class="c1"># Normalization values for images. For each image, the search pipeline will subtract `mean` and divide by `std`.</span>
  <span class="c1"># Normalization is applied after transforms defined in `preprocessing`. Note that regardless of `input_dtype`,</span>
  <span class="c1"># the normalization function will always receive a `float32` input with values in the range [0.0, 1.0], so you should</span>
  <span class="c1"># define `mean` and `std` values accordingly.</span>

  <span class="nt">dataloader</span><span class="p">:</span>
    <span class="nt">_target_</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">torch.utils.data.DataLoader</span>
    <span class="nt">batch_size</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">96</span>
    <span class="nt">shuffle</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">true</span>
    <span class="nt">num_workers</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">8</span>
    <span class="nt">pin_memory</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">true</span>
    <span class="nt">drop_last</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">true</span>
  <span class="c1"># Parameters for the PyTorch DataLoader. Please refer to the PyTorch documentation for the description of parameters -</span>
  <span class="c1"># https://pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader.</span>

<span class="nt">optim</span><span class="p">:</span>
  <span class="nt">main</span><span class="p">:</span>
    <span class="nt">_target_</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">torch.optim.Adam</span>
    <span class="nt">lr</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">1e-3</span>
    <span class="nt">betas</span><span class="p">:</span> <span class="p p-Indicator">[</span><span class="nv">0</span><span class="p p-Indicator">,</span> <span class="nv">0.999</span><span class="p p-Indicator">]</span>
  <span class="c1"># Optimizer configuration for the main (either Classification or Semantic Segmentation) Model</span>


  <span class="nt">policy</span><span class="p">:</span>
    <span class="nt">_target_</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">torch.optim.Adam</span>
    <span class="nt">lr</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">1e-3</span>
    <span class="nt">betas</span><span class="p">:</span> <span class="p p-Indicator">[</span><span class="nv">0</span><span class="p p-Indicator">,</span> <span class="nv">0.999</span><span class="p p-Indicator">]</span>
  <span class="c1"># Optimizer configuration for Policy Model</span>


<span class="nt">seed</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">42</span> <span class="c1"># Random seed. If the value is not null, it will be passed to `seed_everything` -</span>
<span class="c1"># https://pytorch-lightning.readthedocs.io/en/stable/api/pytorch_lightning.utilities.seed.html?highlight=seed_everything</span>

<span class="nt">hydra</span><span class="p">:</span>
  <span class="nt">run</span><span class="p">:</span>
    <span class="nt">dir</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">${config_dir:}/outputs/${now:%Y-%m-%d}/${now:%H-%M-%S}</span>
    <span class="c1"># Path to the directory that will contain all outputs produced by the search algorithm. `${config_dir:}` contains</span>
    <span class="c1"># path to the directory with the `search.yaml` config file. Please refer to the Hydra documentation for more</span>
    <span class="c1"># information - https://hydra.cc/docs/configure_hydra/workdir.</span>

<span class="nt">trainer</span><span class="p">:</span>
  <span class="c1"># Configuration for PyTorch Lightning Trainer. You can read more about Trainer and its arguments at</span>
  <span class="c1"># https://pytorch-lightning.readthedocs.io/en/stable/common/trainer.html.</span>
  <span class="nt">max_epochs</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">1</span>
  <span class="c1"># Number of epochs to search for augmentation parameters.</span>
  <span class="c1"># More detailed description - https://pytorch-lightning.readthedocs.io/en/stable/common/trainer.html#max-epochs</span>

  <span class="nt">benchmark</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">true</span>
  <span class="c1"># If true enables cudnn.benchmark.</span>
  <span class="c1"># More detailed description - https://pytorch-lightning.readthedocs.io/en/stable/common/trainer.html#benchmark</span>

  <span class="nt">gpus</span><span class="p">:</span> <span class="l l-Scalar l-Scalar-Plain">1</span>
  <span class="c1"># Number of GPUs to train on. Set to `0` or None` to use CPU for training.</span>
  <span class="c1"># More detailed description - https://pytorch-lightning.readthedocs.io/en/stable/common/trainer.html#gpus</span>
</code></pre></div>
</article>
</div>
</div>
</main>
<!--
  Copyright (c) 2016-2020 Martin Donath <martin.donath@squidfunk.com>

  Permission is hereby granted, free of charge, to any person obtaining a copy
  of this software and associated documentation files (the "Software"), to
  deal in the Software without restriction, including without limitation the
  rights to use, copy, modify, merge, publish, distribute, sublicense, and/or
  sell copies of the Software, and to permit persons to whom the Software is
  furnished to do so, subject to the following conditions:

  The above copyright notice and this permission notice shall be included in
  all copies or substantial portions of the Software.

  THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
  IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
  FITNESS FOR A PARTICULAR PURPOSE AND NON-INFRINGEMENT. IN NO EVENT SHALL THE
  AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
  LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING
  FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS
  IN THE SOFTWARE.
-->
<!-- Application footer -->
<footer class="md-footer">
<!-- Link to previous and/or next page -->
<div class="md-footer-nav">
<nav aria-label="Footer" class="md-footer-nav__inner md-grid">
<!-- Link to previous page -->
<a class="md-footer-nav__link md-footer-nav__link--prev" href="../svhn/" rel="prev" title="Image classification on the SVHN dataset">
<div class="md-footer-nav__button md-icon">
<svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12z"></path></svg>
</div>
<div class="md-footer-nav__title">
<div class="md-ellipsis">
<span class="md-footer-nav__direction">
                  Previous
                </span>
                Image classification on the SVHN dataset
              </div>
</div>
</a>
<!-- Link to next page -->
<a class="md-footer-nav__link md-footer-nav__link--next" href="../pascal_voc/" rel="next" title="Semantic segmentation on the Pascal VOC dataset">
<div class="md-footer-nav__title">
<div class="md-ellipsis">
<span class="md-footer-nav__direction">
                  Next
                </span>
                Semantic segmentation on the Pascal VOC dataset
              </div>
</div>
<div class="md-footer-nav__button md-icon">
<svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M4 11v2h12l-5.5 5.5 1.42 1.42L19.84 12l-7.92-7.92L10.5 5.5 16 11H4z"></path></svg>
</div>
</a>
</nav>
</div>
<!-- Further information -->
<div class="md-footer-meta md-typeset">
<div class="md-footer-meta__inner md-grid">
<!-- Copyright and theme information -->
<div class="md-footer-copyright">
</div>
<!-- Social links -->
</div>
</div>
</footer>
</div>
<script src="../../../assets/javascripts/vendor.92ffa368.min.js"></script>
<script src="../../../assets/javascripts/bundle.5123e3d4.min.js"></script><script id="__lang" type="application/json">{"clipboard.copy": "Copy to clipboard", "clipboard.copied": "Copied to clipboard", "search.config.lang": "en", "search.config.pipeline": "trimmer, stopWordFilter", "search.config.separator": "[\\s\\-]+", "search.result.placeholder": "Type to start searching", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents"}</script>
<script>
        app = initialize({
          base: "../../..",
          features: [],
          search: Object.assign({
            worker: "../../../assets/javascripts/worker/search.a68abb33.min.js"
          }, typeof search !== "undefined" && search)
        })
      </script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.1.10/require.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-MML-AM_CHTML"></script>
<script src="../../../js/extra.js"></script>
</body>
</html>