
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
        <meta name="description" content="Albumentations provides a comprehensive, high-performance framework for augmenting images to improve machine learning models. Ideal for computer vision applications, supporting a wide range of augmentations.">
      
      
      
        <link rel="canonical" href="https://albumentations.ai/docs/api_reference/augmentations/domain_adaptation/">
      
      
        <link rel="prev" href="../mixing/functional/">
      
      
        <link rel="next" href="../functional/">
      
      
      <link rel="icon" href="../../../images/logo.png">
      <meta name="generator" content="mkdocs-1.5.3, mkdocs-material-9.5.12">
    
    
      
        <title>Domain adaptation transforms (augmentations.domain_adaptation) - Albumentations Documentation</title>
      
    
    
      <link rel="stylesheet" href="../../../assets/stylesheets/main.7e359304.min.css">
      
        
        <link rel="stylesheet" href="../../../assets/stylesheets/palette.06af60db.min.css">
      
      


    
    
      
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
    
      <link rel="stylesheet" href="../../../assets/_mkdocstrings.css">
    
      <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/docsearch.js@2/dist/cdn/docsearch.min.css">
    
      <link rel="stylesheet" href="../../../css/extra.css">
    
    <script>__md_scope=new URL("../../..",location),__md_hash=e=>[...e].reduce((e,_)=>(e<<5)-e+_.charCodeAt(0),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      
  


  
  

<script id="__analytics">function __md_analytics(){function n(){dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],n("js",new Date),n("config","G-DCXRDR9HJ0"),document.addEventListener("DOMContentLoaded",function(){document.forms.search&&document.forms.search.query.addEventListener("blur",function(){this.value&&n("event","search",{search_term:this.value})}),document$.subscribe(function(){var a=document.forms.feedback;if(void 0!==a)for(var e of a.querySelectorAll("[type=submit]"))e.addEventListener("click",function(e){e.preventDefault();var t=document.location.pathname,e=this.getAttribute("data-md-value");n("event","feedback",{page:t,data:e}),a.firstElementChild.disabled=!0;e=a.querySelector(".md-feedback__note [data-md-value='"+e+"']");e&&(e.hidden=!1)}),a.hidden=!1}),location$.subscribe(function(e){n("config","G-DCXRDR9HJ0",{page_path:e.pathname})})});var e=document.createElement("script");e.async=!0,e.src="https://www.googletagmanager.com/gtag/js?id=G-DCXRDR9HJ0",document.getElementById("__analytics").insertAdjacentElement("afterEnd",e)}</script>
  
    <script>"undefined"!=typeof __md_analytics&&__md_analytics()</script>
  

    
    
    





<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta property="og:title" content="Albumentations Documentation - Domain adaptation transforms (augmentations.domain_adaptation)">
<meta property="og:description" content="Albumentations provides a comprehensive, high-performance framework for augmenting images to improve machine learning models. Ideal for computer vision applications, supporting a wide range of augmentations.">
<meta property="og:image" content="https://albumentations.ai/docs/images/albumentations_card.png">
<meta property="og:image:type" content="image/png">
<meta property="og:type" content="website">
<meta property="og:url" content="https://albumentations.ai/docs/api_reference/augmentations/domain_adaptation/">
<meta name="twitter:card" content="summary_large_image">
<meta name="twitter:site" content="@albumentations">
<meta name="twitter:creator" content="@viglovikov">
<meta name="twitter:title" content="Albumentations Documentation - Domain adaptation transforms (augmentations.domain_adaptation)">
<meta name="twitter:description" content="Albumentations provides a comprehensive, high-performance framework for augmenting images to improve machine learning models. Ideal for computer vision applications, supporting a wide range of augmentations.">
<meta name="twitter:image" content="https://albumentations.ai/docs/images/albumentations_card.png">
<meta name="description" content="Albumentations provides a comprehensive, high-performance framework for augmenting images to improve machine learning models. Ideal for computer vision applications, supporting a wide range of augmentations.">
<meta name="keywords"
  content="Albumentations, image augmentation, machine learning, computer vision, data augmentation, image processing, deep learning, AI, artificial intelligence, Python">


  </head>
  
  
    
    
    
    
    
    <body dir="ltr" data-md-color-scheme="default" data-md-color-primary="white" data-md-color-accent="white">
  
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#domain-adaptation-transforms-augmentationsdomain_adaptation" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      <header class="md-header" data-md-component="header">

  <nav class="md-header__inner md-grid" aria-label="header.title">
    <a href="../../.." title="Albumentations Documentation"
      class="md-header__button md-logo" aria-label="Albumentations Documentation" data-md-component="logo">
      
  <img src="../../../images/logo.png" alt="logo">

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3V6m0 5h18v2H3v-2m0 5h18v2H3v-2Z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">

    </div>

    <div class="md-header-nav__title">
      <div class="header-menu-item">
        <a href="https://albumentations.ai">Home</a>
      </div>
      <div class="header-menu-item header-menu-item-selected">
        <a href="https://albumentations.ai/docs/">Documentation</a>
      </div>
      <div class="header-menu-item header-large-menu-item">
        <a href="https://albumentations.ai/whos_using">Who's using</a>
      </div>
      <div class="header-menu-item header-large-menu-item">
        <a href="https://demo.albumentations.ai" target="_blank">Demo</a>
      </div>
      <div class="header-menu-item header-large-menu-item">
        <a href="https://albumentations.ai/people">People</a>
      </div>
    </div>

    
<div class="md-search" data-md-component="search-query" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-state="active">
      <label class="md-search__icon md-icon" for="__search">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5Z"/></svg>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12Z"/></svg>
      </label>
    </form>
  </div>
</div>

    
    <div class="md-header__source">
      <a href="https://github.com/albumentations-team/albumentations" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 496 512"><!--! Font Awesome Free 6.5.1 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2023 Fonticons, Inc.--><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6 0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2z"/></svg>
  </div>
  <div class="md-source__repository">
    albumentations
  </div>
</a>
    </div>
    
  </nav>
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          


<div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
  <div class="md-sidebar__scrollwrap">
    <div class="md-sidebar__inner">
    </div>
  </div>
</div>


          
            <div class="md-content" data-md-component="content">
              <article class="md-content__inner md-typeset">
                
<style>
  .highlight-ipynb {
    font-size: 0.7rem;
  }

  .jupyter-wrapper .jp-MarkdownOutput.jp-RenderedHTMLCommon {
    font-size: 0.8rem;
  }
</style>


<a href="https://github.com/albumentations-team/albumentations.ai/tree/main/mkdocs/src/docs/api_reference/augmentations/domain_adaptation.md"
  title="edit.link.title" class="md-content__button md-icon">
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20.71 7.04c.39-.39.39-1.04 0-1.41l-2.34-2.34c-.37-.39-1.02-.39-1.41 0l-1.84 1.83 3.75 3.75M3 17.25V21h3.75L17.81 9.93l-3.75-3.75L3 17.25Z"/></svg>
</a>








<h1 id="domain-adaptation-transforms-augmentationsdomain_adaptation">Domain adaptation transforms (augmentations.domain_adaptation)<a class="headerlink" href="#domain-adaptation-transforms-augmentationsdomain_adaptation" title="Permanent link">¶</a></h1>
<div class="doc doc-object doc-module">
<a id="albumentations.augmentations.domain_adaptation"></a>
<div class="doc doc-contents first">
<div class="doc doc-children">
<div class="doc doc-object doc-class">
<h2 class="doc doc-heading" data-toc-label="FDA" id="albumentations.augmentations.domain_adaptation.FDA">
<code>class <strong>
FDA</strong></code>
<code>


    (reference_images, beta_limit=0.1, read_fn=&lt;function read_rgb_image at 0x7fb014b7d550&gt;, always_apply=False, p=0.5)


                </code> <span class="doc-github-link">
<a href="https://github.com/albumentations-team/albumentations/blob/master/albumentations/augmentations/domain_adaptation.py#L123" target="_blank">[view source on GitHub]</a>
</span><a class="headerlink" href="#albumentations.augmentations.domain_adaptation.FDA" title="Permanent link">¶</a>
</h2>
<div class="class-signature">
</div>
<div class="doc doc-contents">
<p>Fourier Domain Adaptation from <a href="https://github.com/YanchaoYang/FDA" target="_blank">https://github.com/YanchaoYang/FDA</a>
Simple "style transfer".</p>
<p><strong>Parameters:</strong></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>reference_images</code></td>
<td><code>Sequence[Any]</code></td>
<td><p>Sequence of objects that will be converted to images by <code>read_fn</code>. By default,</p></td>
</tr>
<tr>
<td><code>beta_limit</code></td>
<td><code>float or tuple of float</code></td>
<td><p>coefficient beta from paper. Recommended less 0.3.</p></td>
</tr>
<tr>
<td><code>read_fn</code></td>
<td><code>Callable</code></td>
<td><p>Used-defined function to read image. Function should get an element of <code>reference_images</code></p></td>
</tr>
<tr>
<td><code>and</code></td>
<td><code>return numpy array of image pixels. Default</code></td>
<td><p>takes as input a path to an image and returns a numpy array.</p></td>
</tr>
</tbody>
</table> <div class="admonition targets">
<p class="admonition-title">Targets</p>
<p>image</p>
</div>
<p>Image types:
    uint8, float32</p>
<div class="admonition reference">
<p class="admonition-title">Reference</p>
<p><a href="https://github.com/YanchaoYang/FDA" target="_blank">https://github.com/YanchaoYang/FDA</a>
<a href="https://openaccess.thecvf.com/content_CVPR_2020/papers/Yang_FDA_Fourier_Domain_Adaptation_for_Semantic_Segmentation_CVPR_2020_paper.pdf" target="_blank">https://openaccess.thecvf.com/content_CVPR_2020/papers/Yang_FDA_Fourier_Domain_Adaptation_for_Semantic_Segmentation_CVPR_2020_paper.pdf</a></p>
</div>
<p><strong>Examples:</strong></p>
<div class="codehilite"><pre><span></span><code><span class="o">&gt;&gt;&gt;</span> <span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="o">&gt;&gt;&gt;</span> <span class="kn">import</span> <span class="nn">albumentations</span> <span class="k">as</span> <span class="nn">A</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">image</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">256</span><span class="p">,</span> <span class="p">[</span><span class="mi">100</span><span class="p">,</span> <span class="mi">100</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">uint8</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">target_image</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">256</span><span class="p">,</span> <span class="p">[</span><span class="mi">100</span><span class="p">,</span> <span class="mi">100</span><span class="p">,</span> <span class="mi">3</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">uint8</span><span class="p">)</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">aug</span> <span class="o">=</span> <span class="n">A</span><span class="o">.</span><span class="n">Compose</span><span class="p">([</span><span class="n">A</span><span class="o">.</span><span class="n">FDA</span><span class="p">([</span><span class="n">target_image</span><span class="p">],</span> <span class="n">p</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">read_fn</span><span class="o">=</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="p">)])</span>
<span class="o">&gt;&gt;&gt;</span> <span class="n">result</span> <span class="o">=</span> <span class="n">aug</span><span class="p">(</span><span class="n">image</span><span class="o">=</span><span class="n">image</span><span class="p">)</span>
</code></pre></div>
<details class="quote">
<summary>Source code in <code>albumentations/augmentations/domain_adaptation.py</code></summary>
<div class="codehilite"><pre><span></span><code><span class="k">class</span> <span class="nc">FDA</span><span class="p">(</span><span class="n">ImageOnlyTransform</span><span class="p">):</span>
<span class="w">    </span><span class="sd">"""Fourier Domain Adaptation from https://github.com/YanchaoYang/FDA</span>
<span class="sd">    Simple "style transfer".</span>

<span class="sd">    Args:</span>
<span class="sd">        reference_images (Sequence[Any]): Sequence of objects that will be converted to images by `read_fn`. By default,</span>
<span class="sd">        it expects a sequence of paths to images.</span>
<span class="sd">        beta_limit (float or tuple of float): coefficient beta from paper. Recommended less 0.3.</span>
<span class="sd">        read_fn (Callable): Used-defined function to read image. Function should get an element of `reference_images`</span>
<span class="sd">        and return numpy array of image pixels. Default: takes as input a path to an image and returns a numpy array.</span>

<span class="sd">    Targets:</span>
<span class="sd">        image</span>

<span class="sd">    Image types:</span>
<span class="sd">        uint8, float32</span>

<span class="sd">    Reference:</span>
<span class="sd">        https://github.com/YanchaoYang/FDA</span>
<span class="sd">        https://openaccess.thecvf.com/content_CVPR_2020/papers/Yang_FDA_Fourier_Domain_Adaptation_for_Semantic_Segmentation_CVPR_2020_paper.pdf</span>

<span class="sd">    Example:</span>
<span class="sd">        &gt;&gt;&gt; import numpy as np</span>
<span class="sd">        &gt;&gt;&gt; import albumentations as A</span>
<span class="sd">        &gt;&gt;&gt; image = np.random.randint(0, 256, [100, 100, 3], dtype=np.uint8)</span>
<span class="sd">        &gt;&gt;&gt; target_image = np.random.randint(0, 256, [100, 100, 3], dtype=np.uint8)</span>
<span class="sd">        &gt;&gt;&gt; aug = A.Compose([A.FDA([target_image], p=1, read_fn=lambda x: x)])</span>
<span class="sd">        &gt;&gt;&gt; result = aug(image=image)</span>

<span class="sd">    """</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">reference_images</span><span class="p">:</span> <span class="n">Sequence</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">],</span>
        <span class="n">beta_limit</span><span class="p">:</span> <span class="n">ScaleFloatType</span> <span class="o">=</span> <span class="mf">0.1</span><span class="p">,</span>
        <span class="n">read_fn</span><span class="p">:</span> <span class="n">Callable</span><span class="p">[[</span><span class="n">Any</span><span class="p">],</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">]</span> <span class="o">=</span> <span class="n">read_rgb_image</span><span class="p">,</span>
        <span class="n">always_apply</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="n">p</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.5</span><span class="p">,</span>
    <span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">always_apply</span><span class="o">=</span><span class="n">always_apply</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="n">p</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">reference_images</span> <span class="o">=</span> <span class="n">reference_images</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">read_fn</span> <span class="o">=</span> <span class="n">read_fn</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">beta_limit</span> <span class="o">=</span> <span class="n">to_tuple</span><span class="p">(</span><span class="n">beta_limit</span><span class="p">,</span> <span class="n">low</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">apply</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">img</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">target_image</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> <span class="n">beta</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.1</span><span class="p">,</span> <span class="o">**</span><span class="n">params</span><span class="p">:</span> <span class="n">Any</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">fourier_domain_adaptation</span><span class="p">(</span><span class="n">img</span><span class="p">,</span> <span class="n">target_image</span><span class="p">,</span> <span class="n">beta</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">get_params_dependent_on_targets</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">params</span><span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">]:</span>
        <span class="n">img</span> <span class="o">=</span> <span class="n">params</span><span class="p">[</span><span class="s2">"image"</span><span class="p">]</span>
        <span class="n">target_img</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">read_fn</span><span class="p">(</span><span class="n">random</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">reference_images</span><span class="p">))</span>
        <span class="n">target_img</span> <span class="o">=</span> <span class="n">cv2</span><span class="o">.</span><span class="n">resize</span><span class="p">(</span><span class="n">target_img</span><span class="p">,</span> <span class="n">dsize</span><span class="o">=</span><span class="p">(</span><span class="n">img</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">img</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]))</span>

        <span class="k">return</span> <span class="p">{</span><span class="s2">"target_image"</span><span class="p">:</span> <span class="n">target_img</span><span class="p">}</span>

    <span class="k">def</span> <span class="nf">get_params</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">float</span><span class="p">]:</span>
        <span class="k">return</span> <span class="p">{</span><span class="s2">"beta"</span><span class="p">:</span> <span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">beta_limit</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="bp">self</span><span class="o">.</span><span class="n">beta_limit</span><span class="p">[</span><span class="mi">1</span><span class="p">])}</span>

    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">targets_as_params</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]:</span>
        <span class="k">return</span> <span class="p">[</span><span class="s2">"image"</span><span class="p">]</span>

    <span class="k">def</span> <span class="nf">get_transform_init_args_names</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">str</span><span class="p">,</span> <span class="nb">str</span><span class="p">]:</span>
        <span class="k">return</span> <span class="s2">"reference_images"</span><span class="p">,</span> <span class="s2">"beta_limit"</span><span class="p">,</span> <span class="s2">"read_fn"</span>

    <span class="k">def</span> <span class="nf">to_dict_private</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]:</span>
        <span class="n">msg</span> <span class="o">=</span> <span class="s2">"FDA can not be serialized."</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span><span class="n">msg</span><span class="p">)</span>
</code></pre></div>
</details>
<div class="doc doc-children">
</div>
</div>
</div>
<div class="doc doc-object doc-class">
<h2 class="doc doc-heading" data-toc-label="HistogramMatching" id="albumentations.augmentations.domain_adaptation.HistogramMatching">
<code>class <strong>
HistogramMatching</strong></code>
<code>


    (reference_images, blend_ratio=(0.5, 1.0), read_fn=&lt;function read_rgb_image at 0x7fb014b7d550&gt;, always_apply=False, p=0.5)


                </code> <span class="doc-github-link">
<a href="https://github.com/albumentations-team/albumentations/blob/master/albumentations/augmentations/domain_adaptation.py#L56" target="_blank">[view source on GitHub]</a>
</span><a class="headerlink" href="#albumentations.augmentations.domain_adaptation.HistogramMatching" title="Permanent link">¶</a>
</h2>
<div class="class-signature">
</div>
<div class="doc doc-contents">
<p>Apply histogram matching. It manipulates the pixels of an input image so that its histogram matches
the histogram of the reference image. If the images have multiple channels, the matching is done independently
for each channel, as long as the number of channels is equal in the input image and the reference.</p>
<p>Histogram matching can be used as a lightweight normalization for image processing,
such as feature matching, especially in circumstances where the images have been taken from different
sources or in different conditions (i.e. lighting).</p>
<div class="admonition see">
<p class="admonition-title">See</p>
<p><a href="https://scikit-image.org/docs/dev/auto_examples/color_exposure/plot_histogram_matching.html" target="_blank">https://scikit-image.org/docs/dev/auto_examples/color_exposure/plot_histogram_matching.html</a></p>
</div>
<p><strong>Parameters:</strong></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>reference_images</code></td>
<td><code>Sequence[Any]</code></td>
<td><p>Sequence of objects that will be converted to images by <code>read_fn</code>. By default,</p></td>
</tr>
<tr>
<td><code>blend_ratio</code></td>
<td><code>Tuple[float, float]</code></td>
<td><p>Tuple of min and max blend ratio. Matched image will be blended with original
with random blend factor for increased diversity of generated images.</p></td>
</tr>
<tr>
<td><code>read_fn</code></td>
<td><code>Callable</code></td>
<td><p>Used-defined function to read image. Function should get an element of <code>reference_images</code></p></td>
</tr>
<tr>
<td><code>and</code></td>
<td><code>return numpy array of image pixels. Default</code></td>
<td><p>takes as input a path to an image and returns a numpy array.</p></td>
</tr>
<tr>
<td><code>p</code></td>
<td><code>float</code></td>
<td><p>probability of applying the transform. Default: 1.0.</p></td>
</tr>
</tbody>
</table> <div class="admonition targets">
<p class="admonition-title">Targets</p>
<p>image</p>
</div>
<p>Image types:
    uint8, uint16, float32</p>
<details class="quote">
<summary>Source code in <code>albumentations/augmentations/domain_adaptation.py</code></summary>
<div class="codehilite"><pre><span></span><code><span class="k">class</span> <span class="nc">HistogramMatching</span><span class="p">(</span><span class="n">ImageOnlyTransform</span><span class="p">):</span>
<span class="w">    </span><span class="sd">"""Apply histogram matching. It manipulates the pixels of an input image so that its histogram matches</span>
<span class="sd">    the histogram of the reference image. If the images have multiple channels, the matching is done independently</span>
<span class="sd">    for each channel, as long as the number of channels is equal in the input image and the reference.</span>

<span class="sd">    Histogram matching can be used as a lightweight normalization for image processing,</span>
<span class="sd">    such as feature matching, especially in circumstances where the images have been taken from different</span>
<span class="sd">    sources or in different conditions (i.e. lighting).</span>

<span class="sd">    See:</span>
<span class="sd">        https://scikit-image.org/docs/dev/auto_examples/color_exposure/plot_histogram_matching.html</span>

<span class="sd">    Args:</span>
<span class="sd">        reference_images (Sequence[Any]): Sequence of objects that will be converted to images by `read_fn`. By default,</span>
<span class="sd">        it expects a sequence of paths to images.</span>
<span class="sd">        blend_ratio: Tuple of min and max blend ratio. Matched image will be blended with original</span>
<span class="sd">            with random blend factor for increased diversity of generated images.</span>
<span class="sd">        read_fn (Callable): Used-defined function to read image. Function should get an element of `reference_images`</span>
<span class="sd">        and return numpy array of image pixels. Default: takes as input a path to an image and returns a numpy array.</span>
<span class="sd">        p: probability of applying the transform. Default: 1.0.</span>

<span class="sd">    Targets:</span>
<span class="sd">        image</span>

<span class="sd">    Image types:</span>
<span class="sd">        uint8, uint16, float32</span>

<span class="sd">    """</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">reference_images</span><span class="p">:</span> <span class="n">Sequence</span><span class="p">[</span><span class="n">Any</span><span class="p">],</span>
        <span class="n">blend_ratio</span><span class="p">:</span> <span class="n">Tuple</span><span class="p">[</span><span class="nb">float</span><span class="p">,</span> <span class="nb">float</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="mf">0.5</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">),</span>
        <span class="n">read_fn</span><span class="p">:</span> <span class="n">Callable</span><span class="p">[[</span><span class="n">Any</span><span class="p">],</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">]</span> <span class="o">=</span> <span class="n">read_rgb_image</span><span class="p">,</span>
        <span class="n">always_apply</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="n">p</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.5</span><span class="p">,</span>
    <span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">always_apply</span><span class="o">=</span><span class="n">always_apply</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="n">p</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">reference_images</span> <span class="o">=</span> <span class="n">reference_images</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">read_fn</span> <span class="o">=</span> <span class="n">read_fn</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">blend_ratio</span> <span class="o">=</span> <span class="n">blend_ratio</span>

    <span class="k">def</span> <span class="nf">apply</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span>
        <span class="n">img</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span>
        <span class="n">reference_image</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">blend_ratio</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.5</span><span class="p">,</span>
        <span class="o">**</span><span class="n">params</span><span class="p">:</span> <span class="n">Any</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">apply_histogram</span><span class="p">(</span><span class="n">img</span><span class="p">,</span> <span class="n">reference_image</span><span class="p">,</span> <span class="n">blend_ratio</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">get_params</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">]:</span>
        <span class="k">return</span> <span class="p">{</span>
            <span class="s2">"reference_image"</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">read_fn</span><span class="p">(</span><span class="n">random</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">reference_images</span><span class="p">)),</span>
            <span class="s2">"blend_ratio"</span><span class="p">:</span> <span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">blend_ratio</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="bp">self</span><span class="o">.</span><span class="n">blend_ratio</span><span class="p">[</span><span class="mi">1</span><span class="p">]),</span>
        <span class="p">}</span>

    <span class="k">def</span> <span class="nf">get_transform_init_args_names</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">str</span><span class="p">,</span> <span class="nb">str</span><span class="p">]:</span>
        <span class="k">return</span> <span class="p">(</span><span class="s2">"reference_images"</span><span class="p">,</span> <span class="s2">"blend_ratio"</span><span class="p">,</span> <span class="s2">"read_fn"</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">to_dict_private</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]:</span>
        <span class="n">msg</span> <span class="o">=</span> <span class="s2">"HistogramMatching can not be serialized."</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span><span class="n">msg</span><span class="p">)</span>
</code></pre></div>
</details>
<div class="doc doc-children">
</div>
</div>
</div>
<div class="doc doc-object doc-class">
<h2 class="doc doc-heading" data-toc-label="PixelDistributionAdaptation" id="albumentations.augmentations.domain_adaptation.PixelDistributionAdaptation">
<code>class <strong>
PixelDistributionAdaptation</strong></code>
<code>


    (reference_images, blend_ratio=(0.25, 1.0), read_fn=&lt;function read_rgb_image at 0x7fb014b7d550&gt;, transform_type='pca', always_apply=False, p=0.5)


                </code> <span class="doc-github-link">
<a href="https://github.com/albumentations-team/albumentations/blob/master/albumentations/augmentations/domain_adaptation.py#L188" target="_blank">[view source on GitHub]</a>
</span><a class="headerlink" href="#albumentations.augmentations.domain_adaptation.PixelDistributionAdaptation" title="Permanent link">¶</a>
</h2>
<div class="class-signature">
</div>
<div class="doc doc-contents">
<p>Another naive and quick pixel-level domain adaptation. It fits a simple transform (such as PCA, StandardScaler
or MinMaxScaler) on both original and reference image, transforms original image with transform trained on this
image and then performs inverse transformation using transform fitted on reference image.</p>
<p><strong>Parameters:</strong></p>
<table>
<thead>
<tr>
<th>Name</th>
<th>Type</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>reference_images</code></td>
<td><code>Sequence[Any]</code></td>
<td><p>Sequence of objects that will be converted to images by <code>read_fn</code>. By default,</p></td>
</tr>
<tr>
<td><code>blend_ratio</code></td>
<td><code>float, float</code></td>
<td><p>Tuple of min and max blend ratio. Matched image will be blended with original
with random blend factor for increased diversity of generated images.</p></td>
</tr>
<tr>
<td><code>read_fn</code></td>
<td><code>Callable</code></td>
<td><p>Used-defined function to read image. Function should get an element of <code>reference_images</code></p></td>
</tr>
<tr>
<td><code>and</code></td>
<td><code>return numpy array of image pixels. Default</code></td>
<td><p>takes as input a path to an image and returns a numpy array.</p></td>
</tr>
<tr>
<td><code>transform_type</code></td>
<td><code>str</code></td>
<td><p>type of transform; "pca", "standard", "minmax" are allowed.</p></td>
</tr>
<tr>
<td><code>p</code></td>
<td><code>float</code></td>
<td><p>probability of applying the transform. Default: 1.0.</p></td>
</tr>
</tbody>
</table> <div class="admonition targets">
<p class="admonition-title">Targets</p>
<p>image</p>
</div>
<p>Image types:
    uint8, float32</p>
<p>See also: <a href="https://github.com/arsenyinfo/qudida" target="_blank">https://github.com/arsenyinfo/qudida</a></p>
<details class="quote">
<summary>Source code in <code>albumentations/augmentations/domain_adaptation.py</code></summary>
<div class="codehilite"><pre><span></span><code><span class="k">class</span> <span class="nc">PixelDistributionAdaptation</span><span class="p">(</span><span class="n">ImageOnlyTransform</span><span class="p">):</span>
<span class="w">    </span><span class="sd">"""Another naive and quick pixel-level domain adaptation. It fits a simple transform (such as PCA, StandardScaler</span>
<span class="sd">    or MinMaxScaler) on both original and reference image, transforms original image with transform trained on this</span>
<span class="sd">    image and then performs inverse transformation using transform fitted on reference image.</span>

<span class="sd">    Args:</span>
<span class="sd">        reference_images (Sequence[Any]): Sequence of objects that will be converted to images by `read_fn`. By default,</span>
<span class="sd">        it expects a sequence of paths to images.</span>
<span class="sd">        blend_ratio (float, float): Tuple of min and max blend ratio. Matched image will be blended with original</span>
<span class="sd">            with random blend factor for increased diversity of generated images.</span>
<span class="sd">        read_fn (Callable): Used-defined function to read image. Function should get an element of `reference_images`</span>
<span class="sd">        and return numpy array of image pixels. Default: takes as input a path to an image and returns a numpy array.</span>
<span class="sd">        transform_type (str): type of transform; "pca", "standard", "minmax" are allowed.</span>
<span class="sd">        p (float): probability of applying the transform. Default: 1.0.</span>

<span class="sd">    Targets:</span>
<span class="sd">        image</span>

<span class="sd">    Image types:</span>
<span class="sd">        uint8, float32</span>

<span class="sd">    See also: https://github.com/arsenyinfo/qudida</span>

<span class="sd">    """</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">reference_images</span><span class="p">:</span> <span class="n">Sequence</span><span class="p">[</span><span class="n">Any</span><span class="p">],</span>
        <span class="n">blend_ratio</span><span class="p">:</span> <span class="n">Tuple</span><span class="p">[</span><span class="nb">float</span><span class="p">,</span> <span class="nb">float</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="mf">0.25</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">),</span>
        <span class="n">read_fn</span><span class="p">:</span> <span class="n">Callable</span><span class="p">[[</span><span class="n">Any</span><span class="p">],</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">]</span> <span class="o">=</span> <span class="n">read_rgb_image</span><span class="p">,</span>
        <span class="n">transform_type</span><span class="p">:</span> <span class="n">Literal</span><span class="p">[</span><span class="s2">"pca"</span><span class="p">,</span> <span class="s2">"standard"</span><span class="p">,</span> <span class="s2">"minmax"</span><span class="p">]</span> <span class="o">=</span> <span class="s2">"pca"</span><span class="p">,</span>
        <span class="n">always_apply</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="n">p</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.5</span><span class="p">,</span>
    <span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">always_apply</span><span class="o">=</span><span class="n">always_apply</span><span class="p">,</span> <span class="n">p</span><span class="o">=</span><span class="n">p</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">reference_images</span> <span class="o">=</span> <span class="n">reference_images</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">read_fn</span> <span class="o">=</span> <span class="n">read_fn</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">blend_ratio</span> <span class="o">=</span> <span class="n">blend_ratio</span>
        <span class="n">expected_transformers</span> <span class="o">=</span> <span class="p">(</span><span class="s2">"pca"</span><span class="p">,</span> <span class="s2">"standard"</span><span class="p">,</span> <span class="s2">"minmax"</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">transform_type</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">expected_transformers</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">"Got unexpected transform_type </span><span class="si">{</span><span class="n">transform_type</span><span class="si">}</span><span class="s2">. Expected one of </span><span class="si">{</span><span class="n">expected_transformers</span><span class="si">}</span><span class="s2">"</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">transform_type</span> <span class="o">=</span> <span class="n">transform_type</span>

    <span class="nd">@staticmethod</span>
    <span class="k">def</span> <span class="nf">_validate_shape</span><span class="p">(</span><span class="n">img</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">is_grayscale_image</span><span class="p">(</span><span class="n">img</span><span class="p">)</span> <span class="ow">or</span> <span class="n">is_multispectral_image</span><span class="p">(</span><span class="n">img</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">"Unexpected image shape: expected 3 dimensions, got </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">img</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span><span class="si">}</span><span class="s2">."</span>
                <span class="sa">f</span><span class="s2">"Is it a grayscale or multispectral image? It's not supported for now."</span>
            <span class="p">)</span>

    <span class="k">def</span> <span class="nf">ensure_uint8</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">img</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="nb">bool</span><span class="p">]:</span>
        <span class="k">if</span> <span class="n">img</span><span class="o">.</span><span class="n">dtype</span> <span class="o">==</span> <span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">img</span><span class="o">.</span><span class="n">min</span><span class="p">()</span> <span class="o">&lt;</span> <span class="mi">0</span> <span class="ow">or</span> <span class="n">img</span><span class="o">.</span><span class="n">max</span><span class="p">()</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
                <span class="n">message</span> <span class="o">=</span> <span class="p">(</span>
                    <span class="s2">"PixelDistributionAdaptation uses uint8 under the hood, so float32 should be converted,"</span>
                    <span class="s2">"Can not do it automatically when the image is out of [0..1] range."</span>
                <span class="p">)</span>
                <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span><span class="n">message</span><span class="p">)</span>
            <span class="k">return</span> <span class="p">(</span><span class="n">img</span> <span class="o">*</span> <span class="mi">255</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="s2">"uint8"</span><span class="p">),</span> <span class="kc">True</span>
        <span class="k">return</span> <span class="n">img</span><span class="p">,</span> <span class="kc">False</span>

    <span class="k">def</span> <span class="nf">apply</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">img</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">reference_image</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">blend_ratio</span><span class="p">:</span> <span class="nb">float</span><span class="p">,</span> <span class="o">**</span><span class="n">params</span><span class="p">:</span> <span class="n">Any</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">_validate_shape</span><span class="p">(</span><span class="n">img</span><span class="p">)</span>
        <span class="n">reference_image</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">ensure_uint8</span><span class="p">(</span><span class="n">reference_image</span><span class="p">)</span>
        <span class="n">img</span><span class="p">,</span> <span class="n">needs_reconvert</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">ensure_uint8</span><span class="p">(</span><span class="n">img</span><span class="p">)</span>

        <span class="n">adapted</span> <span class="o">=</span> <span class="n">adapt_pixel_distribution</span><span class="p">(</span>
            <span class="n">img</span><span class="p">,</span>
            <span class="n">ref</span><span class="o">=</span><span class="n">reference_image</span><span class="p">,</span>
            <span class="n">weight</span><span class="o">=</span><span class="n">blend_ratio</span><span class="p">,</span>
            <span class="n">transform_type</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">transform_type</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="k">if</span> <span class="n">needs_reconvert</span><span class="p">:</span>
            <span class="n">adapted</span> <span class="o">=</span> <span class="n">adapted</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="s2">"float32"</span><span class="p">)</span> <span class="o">*</span> <span class="p">(</span><span class="mi">1</span> <span class="o">/</span> <span class="mi">255</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">adapted</span>

    <span class="k">def</span> <span class="nf">get_params</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]:</span>
        <span class="k">return</span> <span class="p">{</span>
            <span class="s2">"reference_image"</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">read_fn</span><span class="p">(</span><span class="n">random</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">reference_images</span><span class="p">)),</span>
            <span class="s2">"blend_ratio"</span><span class="p">:</span> <span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">blend_ratio</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="bp">self</span><span class="o">.</span><span class="n">blend_ratio</span><span class="p">[</span><span class="mi">1</span><span class="p">]),</span>
        <span class="p">}</span>

    <span class="k">def</span> <span class="nf">get_transform_init_args_names</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">str</span><span class="p">,</span> <span class="nb">str</span><span class="p">,</span> <span class="nb">str</span><span class="p">]:</span>
        <span class="k">return</span> <span class="s2">"reference_images"</span><span class="p">,</span> <span class="s2">"blend_ratio"</span><span class="p">,</span> <span class="s2">"read_fn"</span><span class="p">,</span> <span class="s2">"transform_type"</span>

    <span class="k">def</span> <span class="nf">to_dict_private</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">]:</span>
        <span class="n">msg</span> <span class="o">=</span> <span class="s2">"PixelDistributionAdaptation can not be serialized."</span>
        <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span><span class="n">msg</span><span class="p">)</span>
</code></pre></div>
</details>
<div class="doc doc-children">
</div>
</div>
</div>
</div>
</div>
</div>


              </article>
            </div>
          
          
<script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script>
        </div>
        
          <button type="button" class="md-top md-icon" data-md-component="top" hidden>
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8v12Z"/></svg>
  Back to top
</button>
        
      </main>
      
        
<footer class="md-footer">
  
    <nav class="md-footer__inner md-grid" aria-label="footer.title">
      
        <a href="../mixing/functional/" class="md-footer__link md-footer__link--prev" rel="prev">
          <div class="md-footer__button md-icon">
            <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12Z"/></svg>
          </div>
          <div class="md-footer__title">
            <div class="md-ellipsis">
              <span class="md-footer__direction">
                Previous
              </span>
              Mixing functional transforms (augmentations.mixing.functional)
            </div>
          </div>
        </a>
      
      
        <a href="../functional/" class="md-footer__link md-footer__link--next" rel="next">
          <div class="md-footer__title">
            <div class="md-ellipsis">
              <span class="md-footer__direction">
                Next
              </span>
              Functional transforms (augmentations.functional)
            </div>
          </div>
          <div class="md-footer__button md-icon">
            <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M4 11v2h12l-5.5 5.5 1.42 1.42L19.84 12l-7.92-7.92L10.5 5.5 16 11H4Z"/></svg>
          </div>
        </a>
      
    </nav>
  

</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    
    <script id="__config" type="application/json">{"base": "../../..", "features": ["navigation.instant", "navigation.top", "navigation.sections"], "search": "../../../assets/javascripts/workers/search.b8dbb3d2.min.js", "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}}</script>
    
    
      <script src="../../../assets/javascripts/bundle.c8d2eff1.min.js"></script>
      
        <script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.1.10/require.min.js"></script>
      
        <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-MML-AM_CHTML"></script>
      
        <script src="../../../js/extra.js"></script>
      
    
  </body>
</html>